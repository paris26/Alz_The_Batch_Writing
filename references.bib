@article{aelchetelatEarlyDiagnosisAlzheimers2003,
  title = {Early Diagnosis of {{Alzheimer}}'s Disease: Contribution of Structural Neuroimaging},
  shorttitle = {Early Diagnosis of {{Alzheimer}}'s Disease},
  author = {A{\"e}l Chetelat, G. and Baron, Jean-Claude},
  year = 2003,
  journal = {Neuroimage},
  volume = {18},
  number = {2},
  pages = {525--541},
  publisher = {Elsevier},
  urldate = {2024-12-17}
}

@article{aelchetelatEarlyDiagnosisAlzheimers2003b,
  title = {Early Diagnosis of {{Alzheimer}}'s Disease: Contribution of Structural Neuroimaging},
  shorttitle = {Early Diagnosis of {{Alzheimer}}'s Disease},
  author = {A{\"e}l Chetelat, G. and Baron, Jean-Claude},
  year = 2003,
  journal = {Neuroimage},
  volume = {18},
  number = {2},
  pages = {525--541},
  publisher = {Elsevier},
  urldate = {2024-11-09},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Aël Chetelat and Baron - 2003 - Early diagnosis of Alzheimer’s disease contribution of structural neuroimaging.pdf}
}

@book{affairsWorldPopulationAgeing2020,
  title = {World {{Population Ageing}} 2019},
  author = {Affairs, United Nations Department of Economic {and} Social},
  year = 2020,
  month = oct,
  publisher = {United Nations},
  doi = {10.18356/6a8968ef-en},
  urldate = {2026-01-17},
  abstract = {Drawing on the 2019 revision of World Population Prospects, the World Population Ageing 2019 (Highlights) documents global and regional trends in population ageing, including consideration of the implications of these trends for the implementation of the 2030 Agenda. The report also presents various concepts and indicators related to population ageing and discusses related fiscal and economic implications.},
  isbn = {978-92-1-004554-4},
  langid = {english},
  file = {/home/paris/Zotero/storage/AQEQINY9/9789210045544.html}
}

@article{agostaRestingStateFMRI2012,
  title = {Resting State {{fMRI}} in {{Alzheimer}}'s Disease: Beyond the Default Mode Network},
  shorttitle = {Resting State {{fMRI}} in {{Alzheimer}}'s Disease},
  author = {Agosta, Federica and Pievani, Michela and Geroldi, Cristina and Copetti, Massimiliano and Frisoni, Giovanni B. and Filippi, Massimo},
  year = 2012,
  month = aug,
  journal = {Neurobiology of Aging},
  volume = {33},
  number = {8},
  pages = {1564--1578},
  issn = {0197-4580},
  doi = {10.1016/j.neurobiolaging.2011.06.007},
  urldate = {2025-04-15},
  abstract = {Using resting state (RS) functional magnetic resonance imaging (fMRI), the connectivity patterns of the default mode (DMN), frontoparietal, executive, and salience networks were explored in 13 Alzheimer's disease (AD) patients, 12 amnestic mild cognitive impairment (aMCI) patients, and 13 healthy controls. Compared with controls and aMCI, AD was associated with opposing connectivity effects in the DMN (decreased) and frontal networks (enhanced). The only RS abnormality found in aMCI patients compared with controls was a precuneus connectivity reduction in the DMN. RS fMRI group differences were only partly related to gray matter atrophy. In AD patients, the mean executive network connectivity was positively associated with frontal-executive and language neuropsychological scores. These results suggest that AD is associated with an alteration of large-scale functional brain networks, which extends well beyond the DMN. In AD, the limited resources of the DMN may be paralleled, in an attempt to maintain cognitive efficiency, by an increased prefrontal connectivity. A medial parietal RS fMRI signal change seems to be present since the early phase of AD.},
  keywords = {Alzheimer's disease,Functional MRI (fMRI),Mild cognitive impairment,Resting state fMRI}
}

@article{aja-fernandezReviewStatisticalNoise,
  title = {A Review on Statistical Noise Models for {{Magnetic Resonance Imaging}}},
  author = {{Aja-Fernandez}, Santiago and {Tristan-Vega}, Antonio},
  abstract = {Many image processing applications within MRI are grounded on stochastic methods based on the prior knowledge on the statistics of noise. The ubiquitous Gaussian model provides a poor fitting for mediumlow SNRs, yielding to the use of Rician statistics: the noise in MRI has been traditionally modeled as a stationary process governed by a Rician distribution with constant noise power at each voxel. Modern MRI systems turn this model questionable, making it necessary to develop into more complex patterns. We aim at comprehensively reviewing the main statistical rationales and formulations for the noise in MRI lately found in the literature. We attend to three different criteria: the first-order, voxel-wise probability law, the possible spatial variability of the parameters of such distribution, and the possible noise interdependences between neighboring voxels. Several applications using statistical methods are overviewed, discussing the implications each of the models has on them. Finally, we explore the applicability of the surveyed models to some MRI protocols commonly used. Whereas many parallel and nonparallel acquisitions like GRAPPA and SENSE may be fitted into one of the existing models, other nonlinear reconstruction procedures are lacking a proper noise characterization.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Denosing/Aja-Fernandez and Tristan-Vega - A review on statistical noise models for Magnetic Resonance Imaging.pdf}
}

@article{al-bakriHybridExplainableAI2025,
  title = {A {{Hybrid Explainable AI Framework}} ({{HXAI}}) for {{Accurate}} and {{Interpretable Diagnosis}} of {{Alzheimer}}'s {{Disease}}},
  author = {{Al-bakri}, Fatima Hasan and Bejuri, Wan Mohd Yaakob Wan and {Al-Andoli}, Mohamed Nasser and Ikram, Raja Rina Raja and Khor, Hui Min and Mispan, Mohd Syafiq and Yunos, Norhazwani Md and Yusof, Noor Fazilla Abd and Fauadi, Muhammad Hafidz Fazli Md and Jaya, Abdul Syukor Mohamad and Moketar, Nor Aiza and Yusop, Noorrezam and Burhanudin, Kharismi and Marindah, Tyanita Puti and Bustamin, Anugrayani and Zainuddin, Zahir and Wahyuni, Deasy and Ariffin, Umi Kalsom},
  year = 2025,
  month = dec,
  journal = {Diagnostics},
  volume = {15},
  number = {24},
  pages = {3118},
  issn = {2075-4418},
  doi = {10.3390/diagnostics15243118},
  urldate = {2026-01-14},
  abstract = {Background/Objectives: In clinical practice, Explainable AI (XAI) enables non-specialists and general practitioners to make precise diagnoses. Current XAI approaches are limited, as many rely solely on either presenting explanations of clinical data or presenting explanations of MRI, or presenting explanations in unclear ways, reducing their clinical utility. Methods: In this paper, we propose a novel Hybrid Explainable AI (HXAI) framework. This framework uniquely integrates both model-agnostic (SHAP) and model-specific (Grad-CAM) explanation methods within a unified structure for the diagnosis of Alzheimer's disease. The dual-layer explainability constitutes the main originality of this study, as it provides the possibility of interpreting quantitative (at the feature level) and spatial (at the region level) data within a single diagnostic framework. Clinical features (e.g., Mini-Mental State Examination (MMSE), normalized Whole Brain Volume (nWBV), Socioeconomic Status (SES), age) are combined with MRI-derived features extracted via ResNet50, and these features are integrated using ensemble learning with a logistic regression meta-model. Results: The corresponding validation reflects the explainability accuracy of these feature-based explanations, with removal-based tests achieving 83.61\% explainability accuracy, confirming the importance of these features. Model-specific information was used to explain MRI predictions, achieving 58.16\% explainability accuracy of visual explanations. Conclusions: Our HXAI framework integrates both model-agnostic and model-specific approaches in a structured manner, supported by quantitative metrics. This dual-layer interpretability enhances transparency, improves explainability accuracy, and provides an accurate and interpretable framework for AD diagnosis, bridging the gap between model accuracy and clinical trust.},
  pmcid = {PMC12732132},
  pmid = {41464118},
  file = {/home/paris/Zotero/storage/I3J4LCWA/Al-bakri et al. - 2025 - A Hybrid Explainable AI Framework (HXAI) for Accurate and Interpretable Diagnosis of Alzheimer’s Dis.pdf}
}

@article{albertComparisonImageNormalization2023,
  title = {Comparison of {{Image Normalization Methods}} for {{Multi-Site Deep Learning}}},
  author = {Albert, Steffen and Wichtmann, Barbara D. and Zhao, Wenzhao and Maurer, Angelika and Hesser, J{\"u}rgen and Attenberger, Ulrike I. and Schad, Lothar R. and Z{\"o}llner, Frank G.},
  year = 2023,
  month = jan,
  journal = {Applied Sciences},
  volume = {13},
  number = {15},
  pages = {8923},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13158923},
  urldate = {2025-06-15},
  abstract = {In this study, we evaluate the influence of normalization on the performance of deep learning networks for tumor segmentation and the prediction of the pathological response of locally advanced rectal cancer to neoadjuvant chemoradiotherapy. The techniques were applied to a multicenter and multimodal magnet resonance imaging data set consisting of 201 patients recorded at six centers. We implemented and investigated six different normalization methods (setting the mean and standard deviation, histogram matching, percentiles, combining percentiles and histogram matching, fixed window and an auto-encoder with adversarial loss using the imaging parameters) and evaluated their impact on four deep learning tasks: tumor segmentation, prediction of treatment outcome, and prediction of sex and age. The latter two tasks were implemented as a reference test. We trained a modified U-Net with different normalization methods in multiple configurations: on all images, images from all centers except one, and images from a single center. Our results show that normalization only plays a minor role in segmentation, with a difference in Dice of less than 0.02 between the best and worst performing networks. For the prediction of sex and treatment outcomes, the percentile method combined with histogram matching works best for all scenarios. The biggest difference in performance, depending on the normalization method, occurs for classification. In conclusion, normalization is especially important for small data sets or for generalizing to different data distributions. The deep learning method was superior to the classical methods only in a minority of cases, probably due to the limited amount of training data.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {medical imaging,MRI,normalization},
  annotation = {GSCC: 0000013 2025-06-16T09:13:44.131Z 0},
  file = {/home/paris/Zotero/storage/NM5N8JSK/Albert et al. - 2023 - Comparison of Image Normalization Methods for Multi-Site Deep Learning.pdf}
}

@article{alexkrizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  author = {{Alex Krizhevsky} and Krizhevsky, Alex and {Ilya Sutskever} and Sutskever, Ilya and {Geoffrey E. Hinton} and Hinton, Geoffrey E.},
  year = 2012,
  month = dec,
  volume = {25},
  pages = {1097--1105},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  annotation = {MAG ID: 2163605009}
}

@article{aliEnhancingAlzheimersDisease2024,
  title = {Enhancing {{Alzheimer}}'s Disease Diagnosis and Staging: A Multistage {{CNN}} Framework Using {{MRI}}},
  shorttitle = {Enhancing {{Alzheimer}}'s Disease Diagnosis and Staging},
  author = {Ali, Muhammad Umair and Kim, Kwang Su and Khalid, Majdi and Farrash, Majed and Zafar, Amad and Lee, Seung Won},
  year = 2024,
  month = jun,
  journal = {Frontiers in Psychiatry},
  volume = {15},
  publisher = {Frontiers},
  issn = {1664-0640},
  doi = {10.3389/fpsyt.2024.1395563},
  urldate = {2025-08-16},
  abstract = {This study addresses the pervasive and debilitating impact of Alzheimer's disease (AD) on individuals and society, emphasizing the crucial need for timely diagnosis. We present a multistage convolutional neural network (CNN)-based framework for AD detection and sub-classification using brain magnetic resonance imaging (MRI). After preprocessing, a 26-layer CNN model was designed to differentiate between healthy individuals and patients with dementia. After detecting dementia, the 26-layer CNN model was reutilized using the concept of transfer learning to further subclassify dementia into mild, moderate, and severe dementia. Leveraging the frozen weights of the developed CNN on correlated medical images facilitated the transfer learning process for sub-classifying dementia classes. An online AD dataset is used to verify the performance of the proposed multistage CNN-based framework. The proposed approach yielded a noteworthy accuracy of 98.24\% in identifying dementia classes, whereas it achieved 99.70\% accuracy in dementia subclassification. Another dataset was used to further validate the proposed framework, resulting in 100\% performance. Comparative evaluations against pre-trained models and the current literature were also conducted, highlighting the usefulness and superiority of the proposed framework and presenting it as a robust and effective AD detection and subclassification method.},
  langid = {english},
  keywords = {Alzheimer's disease,Convolutional Neural Network,Dementia,MRI,Neuroimaging},
  file = {/home/paris/gdrive/Zotero/Ali et al. - 2024 - Enhancing Alzheimer’s disease diagnosis and staging a multistage CNN framework using MRI.pdf}
}

@article{aljuhaniUseArtificialIntelligence2024,
  title = {Use of {{Artificial Intelligence}} in {{Imaging Dementia}}},
  author = {Aljuhani, Manal and Ashraf, Azhaar and Edison, Paul},
  year = 2024,
  month = nov,
  journal = {Cells},
  volume = {13},
  number = {23},
  pages = {1965},
  issn = {2073-4409},
  doi = {10.3390/cells13231965},
  urldate = {2025-10-15},
  abstract = {Alzheimer's disease is the most common cause of dementia in the elderly population (aged 65 years and over), followed by vascular dementia, Lewy body dementia, and rare types of neurodegenerative diseases, including frontotemporal dementia. There is an unmet need to improve diagnosis and prognosis for patients with dementia, as cycles of misdiagnosis and diagnostic delays are challenging scenarios in neurodegenerative diseases. Neuroimaging is routinely used in clinical practice to support the diagnosis of neurodegenerative diseases. Clinical neuroimaging is amenable to errors owing to varying human judgement as the imaging data are complex and multidimensional. Artificial intelligence algorithms (machine learning and deep learning) enable automation of neuroimaging interpretation and may reduce potential bias and ameliorate clinical decision-making. Graph convolutional network-based frameworks implicitly provide multimodal sparse interpretability to support the detection of Alzheimer's disease and its prodromal stage, mild cognitive impairment. In patients with amyloid-related imaging abnormalities, radiologists had significantly better detection performances with both ARIA-E (sensitivity higher in the assisted/deep learning method [87\%] compared to unassisted [71\%]) and for ARIA-H signs (sensitivity was higher in assisted [79\%] compared to unassisted [69\%]). A convolutional neural network method was developed, and external validation predicted final clinical diagnoses of Alzheimer's disease, dementia with Lewy bodies, mild cognitive impairment due to Alzheimer's disease, or cognitively normal with FDG-PET. The translation of artificial intelligence to clinical practice is plagued with technical, disease-related, and institutional challenges. The implementation of artificial intelligence methods in clinical practice has the potential to transform the diagnostic and treatment landscape and improve patient health and outcomes.},
  pmcid = {PMC11640381},
  pmid = {39682713},
  file = {/home/paris/Zotero/storage/9YFK575I/Aljuhani et al. - 2024 - Use of Artificial Intelligence in Imaging Dementia.pdf}
}

@article{allenPromiseExplainableAI2024,
  title = {The {{Promise}} of {{Explainable AI}} in {{Digital Health}} for {{Precision Medicine}}: {{A Systematic Review}}},
  shorttitle = {The {{Promise}} of {{Explainable AI}} in {{Digital Health}} for {{Precision Medicine}}},
  author = {Allen, Ben},
  year = 2024,
  month = mar,
  journal = {Journal of Personalized Medicine},
  volume = {14},
  number = {3},
  pages = {277},
  issn = {2075-4426},
  doi = {10.3390/jpm14030277},
  urldate = {2025-10-27},
  abstract = {This review synthesizes the literature on explaining machine-learning models for digital health data in precision medicine. As healthcare increasingly tailors treatments to individual characteristics, the integration of artificial intelligence with digital health data becomes crucial. Leveraging a topic-modeling approach, this paper distills the key themes of 27 journal articles. We included peer-reviewed journal articles written in English, with no time constraints on the search. A Google Scholar search, conducted up to 19 September 2023, yielded 27 journal articles. Through a topic-modeling approach, the identified topics encompassed optimizing patient healthcare through data-driven medicine, predictive modeling with data and algorithms, predicting diseases with deep learning of biomedical data, and machine learning in medicine. This review delves into specific applications of explainable artificial intelligence, emphasizing its role in fostering transparency, accountability, and trust within the healthcare domain. Our review highlights the necessity for further development and validation of explanation methods to advance precision healthcare delivery.},
  pmcid = {PMC10971237},
  pmid = {38541019},
  file = {/home/paris/Zotero/storage/6D57XXCK/Allen - 2024 - The Promise of Explainable AI in Digital Health for Precision Medicine A Systematic Review.pdf}
}

@article{alzheimersassociation2016AlzheimersDisease2016,
  title = {2016 {{Alzheimer}}'s Disease Facts and Figures},
  author = {{Alzheimer's Association}},
  year = 2016,
  month = apr,
  journal = {Alzheimer's \& Dementia},
  volume = {12},
  number = {4},
  pages = {459--509},
  issn = {1552-5260, 1552-5279},
  doi = {10.1016/j.jalz.2016.03.001},
  urldate = {2024-11-13},
  abstract = {Abstract                                           This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs of care, and the overall impact on caregivers and society. It also examines in detail the financial impact of Alzheimer's on families, including annual costs to families and the difficult decisions families must often make to pay those costs. An estimated 5.4 million Americans have Alzheimer's disease. By mid-century, the number of people living with Alzheimer's disease in the United States is projected to grow to 13.8 million, fueled in large part by the aging baby boom generation. Today, someone in the country develops Alzheimer's disease every 66 seconds. By 2050, one new case of Alzheimer's is expected to develop every 33 seconds, resulting in nearly 1 million new cases per year. In 2013, official death certificates recorded 84,767 deaths from Alzheimer's disease, making it the sixth leading cause of death in the United States and the fifth leading cause of death in Americans age {$\geq$}65 years. Between 2000 and 2013, deaths resulting from stroke, heart disease, and prostate cancer decreased 23\%, 14\%, and 11\%, respectively, whereas deaths from Alzheimer's disease increased 71\%. The actual number of deaths to which Alzheimer's disease contributes is likely much larger than the number of deaths from Alzheimer's disease recorded on death certificates. In 2016, an estimated 700,000 Americans age {$\geq$}65 years will die with Alzheimer's disease, and many of them will die because of the complications caused by Alzheimer's disease. In 2015, more than 15 million family members and other unpaid caregivers provided an estimated 18.1 billion hours of care to people with Alzheimer's and other dementias, a contribution valued at more than \$221 billion. Average per-person Medicare payments for services to beneficiaries age {$\geq$}65 years with Alzheimer's disease and other dementias are more than two and a half times as great as payments for all beneficiaries without these conditions, and Medicaid payments are 19 times as great. Total payments in 2016 for health care, long-term care and hospice services for people age {$\geq$}65 years with dementia are estimated to be \$236 billion. The costs of Alzheimer's care may place a substantial financial burden on families, who often have to take money out of their retirement savings, cut back on buying food, and reduce their own trips to the doctor. In addition, many family members incorrectly believe that Medicare pays for nursing home care and other types of long-term care. Such findings highlight the need for solutions to prevent dementia-related costs from jeopardizing the health and financial security of the families of people with Alzheimer's and other dementias.},
  langid = {english}
}

@article{alzheimersassociation2019AlzheimersDisease2019,
  title = {2019 {{Alzheimer}}'s Disease Facts and Figures},
  author = {{Alzheimer's Association}},
  year = 2019,
  month = mar,
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  number = {3},
  pages = {321--387},
  issn = {1552-5260, 1552-5279},
  doi = {10.1016/j.jalz.2019.01.010},
  urldate = {2024-11-13},
  abstract = {Abstract                                           This article describes the public health impact of Alzheimer's disease (AD), including incidence and prevalence, mortality and morbidity, use and costs of care, and the overall impact on caregivers and society. The Special Report examines the use of brief cognitive assessments by primary care physicians as a tool for improving early detection of dementia. An estimated 5.8 million Americans have Alzheimer's dementia. By mid-century, the number of people living with Alzheimer's dementia in the United States may grow to 13.8 million, fueled in large part by the aging baby boom generation. In 2017, official death certificates recorded 121,404 deaths from AD, making AD the sixth leading cause of death in the United States and the fifth leading cause of death among Americans age {$\geq$}65~years. Between 2000 and 2017, deaths resulting from stroke, heart disease, and prostate cancer decreased, whereas reported deaths from AD increased 145\%. In 2018, more than 16 million family members and other unpaid caregivers provided an estimated 18.5 billion hours of care to people with Alzheimer's or other dementias. This care is valued at nearly \$234 billion, but its costs extend to family caregivers' increased risk for emotional distress and negative mental and physical health outcomes. Average per-person Medicare payments for services to beneficiaries age {$\geq$}65~years with Alzheimer's or other dementias are more than three times as great as payments for beneficiaries without these conditions. Total payments in 2019 for health care, long-term care and hospice services for people age {$\geq$}65~years with dementia are estimated to be \$290 billion. Early detection of Alzheimer's offers numerous medical, emotional and financial benefits---benefits that accrue to affected individuals and their families as well as to society at large. Alzheimer's Association surveys regarding brief cognitive assessments for detection of dementia found that while a large majority of seniors and primary care physicians say the assessments are important, only half of seniors have received an assessment, and only 16 percent of seniors receive regular cognitive assessments. Many educational opportunities exist to facilitate increased use of brief cognitive assessments in the primary care setting.},
  langid = {english}
}

@article{AlzheimersAssociation2025,
  title = {Alzheimer's {{Association}} 2025 {{Alzheimer}}'s {{Disease Facts}} and {{Figures}}},
  langid = {english},
  file = {/home/paris/Zotero/storage/TAULDAXZ/Alzheimer's Association 2025 Alzheimer's Disease Facts and Figures.pdf}
}

@article{AlzheimersDiseaseDiagnosis2021,
  title = {Alzheimer's Disease Diagnosis Framework from Incomplete Multimodal Data Using Convolutional Neural Networks},
  year = 2021,
  month = sep,
  journal = {Journal of Biomedical Informatics},
  volume = {121},
  pages = {103863},
  publisher = {Academic Press},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2021.103863},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease (AD) is a severe irreversible neurodegenerative disease that has great sufferings on patients and eventually leads to death. Early\dots},
  langid = {american},
  file = {/home/paris/Zotero/storage/CRF2UHPH/S1532046421001921.html}
}

@article{angelovExplainableDeepNeural2020,
  title = {Towards Explainable Deep Neural Networks ({{xDNN}})},
  author = {Angelov, Plamen and Soares, Eduardo},
  year = 2020,
  journal = {Neural Networks},
  volume = {130},
  pages = {185--194},
  publisher = {Elsevier},
  urldate = {2025-06-24}
}

@article{apostolovaMappingProgressiveBrain2008,
  title = {Mapping {{Progressive Brain Structural Changes}} in {{Early Alzheimer}}'s {{Disease}} and {{Mild Cognitive Impairment}}},
  author = {Apostolova, Liana G. and Thompson, Paul M.},
  year = 2008,
  journal = {Neuropsychologia},
  volume = {46},
  number = {6},
  pages = {1597--1612},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2007.10.026},
  urldate = {2025-07-25},
  abstract = {Alzheimer's disease (AD), the most common neurodegenerative disorder of the elderly, ranks third in health care cost after heart disease and cancer. Given the disproportionate aging of the population in all developed countries, the socio-economic impact of AD will continue to rise. Mild cognitive impairment (MCI), a transitional state between normal aging and dementia, carries a 4--6-fold increased risk of future diagnosis of dementia. As complete drug-induced reversal of AD symptoms seems unlikely, researchers are now focusing on the earliest stages of AD where a therapeutic intervention is likely to realize the greatest impact. Recently neuroimaging has received significant scientific consideration as a promising in vivo disease-tracking modality that can also provide potential surrogate biomarkers for therapeutic trials. While several volumetric techniques laid the foundation of the neuroimaging research in AD and MCI, more precise computational anatomy techniques have recently become available. This new technology detects and visualizes discrete changes in cortical and hippocampal integrity and tracks the spread of AD pathology throughout the living brain. Related methods can visualize regionally specific correlations between brain atrophy and important proxy measures of disease such as neuropsychological tests, age of onset or factors that may influence disease progression. We describe extensively validated cortical and hippocampal mapping techniques that are sensitive to clinically relevant changes even in the single individual, and can identify group differences in epidemiological studies or clinical treatment trials. We give an overview of some recent neuroimaging advances in AD and MCI and discuss strengths and weaknesses of the various analytic approaches.},
  pmcid = {PMC2713100},
  pmid = {18395760},
  file = {/home/paris/gdrive/Zotero/Apostolova and Thompson - 2008 - Mapping Progressive Brain Structural Changes in Early Alzheimer’s Disease and Mild Cognitive Impairm.pdf}
}

@inproceedings{aroraExplainableArtificialIntelligence2025,
  title = {Explainable {{Artificial Intelligence Techniques}} for {{Software Development Lifecycle}}: {{A Phase-specific Survey}}},
  shorttitle = {Explainable {{Artificial Intelligence Techniques}} for {{Software Development Lifecycle}}},
  booktitle = {2025 {{IEEE}} 49th {{Annual Computers}}, {{Software}}, and {{Applications Conference}} ({{COMPSAC}})},
  author = {Arora, Lakshit and Girija, Sanjay Surendranath and Kapoor, Shashank and Raj, Aman and Pradhan, Dipen and Shetgaonkar, Ankit},
  year = 2025,
  month = jul,
  pages = {2281--2288},
  issn = {2836-3795},
  doi = {10.1109/COMPSAC65507.2025.00321},
  urldate = {2025-10-27},
  abstract = {Artificial Intelligence (AI) is rapidly expanding and integrating more into daily life to automate tasks, guide decision-making, and enhance efficiency. However, complex AI models, which make decisions without providing clear explanations (known as the "black-box problem"), currently restrict trust and widespread adoption of AI.Explainable Artificial Intelligence (XAI) has emerged to address the black-box problem of making AI systems more interpretable and transparent so stakeholders can trust, verify, and act upon AI-based outcomes. Researchers have developed various techniques to foster XAI in the Software Development Lifecycle. However, there are gaps in applying XAI techniques in the Software Engineering phases. Literature review shows that 68\% of XAI in Software Engineering research is focused on maintenance as opposed to 8\% on software management and requirements.In this paper, we present a comprehensive survey of the applications of XAI methods such as concept-based explanations, Local Interpretable Model-agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), rule extraction, attention mechanisms, counterfactual explanations, and example-based explanations to the different phases of the Software Development Life Cycle (SDLC), including requirements elicitation, design and development, testing and deployment, and evolution.To the best of our knowledge, this paper presents the first comprehensive survey of XAI techniques for every phase of the Software Development Life Cycle (SDLC). This survey aims to promote explainable AI in Software Engineering and facilitate the practical application of complex AI models in AI-driven software development.},
  keywords = {Artificial intelligence,Closed box,Decision making,Ethical Artificial Intelligence,Ethics,Explainable AI,Explainable Artificial Intelligence,Software development management,Software engineering,Software Engineering,Standards,Surveys,Systematic literature review,Transparency,Trust},
  file = {/home/paris/Zotero/storage/CPPD8JQA/Arora et al. - 2025 - Explainable Artificial Intelligence Techniques for Software Development Lifecycle A Phase-specific.pdf}
}

@article{ashburnerVoxelBasedMorphometryMethods2000,
  title = {Voxel-{{Based Morphometry}}---{{The Methods}}},
  author = {Ashburner, John and Friston, Karl J.},
  year = 2000,
  month = jun,
  journal = {NeuroImage},
  volume = {11},
  number = {6},
  pages = {805--821},
  issn = {1053-8119},
  doi = {10.1006/nimg.2000.0582},
  urldate = {2025-07-19},
  abstract = {At its simplest, voxel-based morphometry (VBM) involves a voxel-wise comparison of the local concentration of gray matter between two groups of subjects. The procedure is relatively straightforward and involves spatially normalizing high-resolution images from all the subjects in the study into the same stereotactic space. This is followed by segmenting the gray matter from the spatially normalized images and smoothing the gray-matter segments. Voxel-wise parametric statistical tests which compare the smoothed gray-matter images from the two groups are performed. Corrections for multiple comparisons are made using the theory of Gaussian random fields. This paper describes the steps involved in VBM, with particular emphasis on segmenting gray matter from MR images with nonuniformity artifact. We provide evaluations of the assumptions that underpin the method, including the accuracy of the segmentation and the assumptions made about the statistical distribution of the data.},
  file = {/home/paris/gdrive/Zotero/Ashburner and Friston - 2000 - Voxel-Based Morphometry—The Methods.pdf;/home/paris/Zotero/storage/DHCHYZD5/S1053811900905822.html}
}

@article{aurangzebIntroducingPneumNetGroundbreaking2024,
  title = {Introducing {{PneumNet}}---{{A Groundbreaking Dual Version Deep Learning Model}} for {{Pneumonia Disease Detection}}},
  author = {Aurangzeb, Khursheed and Jamil, Sonain and Alhussein, Musaed},
  year = 2024,
  journal = {International Journal of Imaging Systems and Technology},
  volume = {34},
  number = {4},
  pages = {e23116},
  issn = {1098-1098},
  doi = {10.1002/ima.23116},
  urldate = {2025-06-24},
  abstract = {The Internet of Medical Things (IoMT) has revolutionized healthcare, particularly in ambient assisted living (AAL). Deep learning has emerged as a powerful tool for identifying disorders and making health-related decisions. Pneumonia, a dangerous and contagious disease, has a significant global impact. Prompt and accurate diagnosis is crucial, but traditional methods are time-consuming and require specialized expertise. This research introduces PneumNet, a novel deep-learning model. PneumNet consists of two versions: PneumNet v1.0 and PneumNet v2.0. The comparative analysis demonstrates PneumNet's exceptional performance. The top model achieves 99.84\% accuracy, 99.87\% F1-score, 99.74\% sensitivity, 100\% specificity, 100\% positive predictive value (PPV), and 99.58\% negative predictive value (NPV). PneumNet outperforms other methods, accurately diagnosing pneumonia and improving treatment outcomes. By leveraging deep convolutional neural networks (D-CNNs), PneumNet provides an efficient and accurate solution for pneumonia detection. These findings highlight the significance of D-CNNs, particularly the proposed PneumNet model, in enhancing pneumonia detection accuracy and reducing mortality rates. IoMT and deep learning pave the way for transformative advancements in healthcare.},
  copyright = {\copyright{} 2024 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {contagious illness,diagnosis,digital system,pneumonia detection,spatial feature extraction}
}

@article{Autoencoder2025,
  title = {Autoencoder},
  year = 2025,
  month = may,
  journal = {Wikipedia},
  urldate = {2025-06-22},
  abstract = {An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation. The autoencoder learns an efficient representation (encoding) for a set of data, typically for dimensionality reduction, to generate lower-dimensional embeddings for subsequent use by other machine learning algorithms. Variants exist which aim to make the learned representations assume useful properties. Examples are regularized autoencoders (sparse, denoising and contractive autoencoders), which are effective in learning representations for subsequent classification tasks, and variational autoencoders, which can be used as generative models. Autoencoders are applied to many problems, including facial recognition, feature detection, anomaly detection, and learning the meaning of words. In terms of data synthesis, autoencoders can also be used to randomly generate new data that is similar to the input (training) data.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1289602244}
}

@article{bagciRoleIntensityStandardization2010,
  title = {The Role of Intensity Standardization in Medical Image Registration},
  author = {Ba{\u g}c{\i}, Ula{\c s} and Udupa, Jayaram K. and Bai, Li},
  year = 2010,
  month = mar,
  journal = {Pattern Recognition Letters},
  series = {20th {{SIBGRAPI}}: {{Advances}} in {{Image Processing}} and {{Computer Vision}}},
  volume = {31},
  number = {4},
  pages = {315--323},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2009.09.010},
  urldate = {2025-06-04},
  abstract = {Acquisition-to-acquisition signal intensity variations (non-standardness) are inherent in MR images. Standardization is a post processing method for correcting inter-subject intensity variations through transforming all images from the given image gray scale into a standard gray scale wherein similar intensities achieve similar tissue meanings. The lack of a standard image intensity scale in MRI leads to many difficulties in tissue characterizability, image display, and analysis, including image segmentation. The influence of standardization on these tasks has been documented well; however, effects of standardization on medical image registration have not been studied yet. In this paper, we investigate the role of intensity standardization in registration tasks with systematic and analytic evaluations involving clinical MR images. We conducted nearly 20,000 clinical MR image registration experiments and evaluated the quality of registrations both quantitatively and qualitatively. The evaluations show that intensity variations between images degrades the accuracy of registration performance. The results imply that the accuracy of image registration not only depends on spatial and geometric similarity but also on the similarity of the intensity values for the same tissues in different images.},
  keywords = {Image registration,Inhomogeneity correction,Intensity standardization,Non-standardness,Quantitative validation},
  annotation = {GSCC: 0000057 2025-06-15T15:38:29.937Z 0.07}
}

@article{bahriExplainingNeuralScaling2024,
  title = {Explaining Neural Scaling Laws},
  author = {Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
  year = 2024,
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {27},
  pages = {e2311878121},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2311878121},
  urldate = {2025-09-13},
  abstract = {The population loss of trained deep neural networks often follows precise power-law scaling relations with either the size of the training dataset or the number of parameters in the network. We propose a theory that explains the origins of and connects these scaling laws. We identify variance-limited and resolution-limited scaling behavior for both dataset and model size, for a total of four scaling regimes. The variance-limited scaling follows simply from the existence of a well-behaved infinite data or infinite width limit, while the resolution-limited regime can be explained by positing that models are effectively resolving a smooth data manifold. In the large width limit, this can be equivalently obtained from the spectrum of certain kernels, and we present evidence that large width and large dataset resolution-limited scaling exponents are related by a duality. We exhibit all four scaling regimes in the controlled setting of large random feature and pretrained models and test the predictions empirically on a range of standard architectures and datasets. We also observe several empirical relationships between datasets and scaling exponents under modifications of task and architecture aspect ratio. Our work provides a taxonomy for classifying different scaling regimes, underscores that there can be different mechanisms driving improvements in loss, and lends insight into the microscopic origin and relationships between scaling exponents.},
  file = {/home/paris/gdrive/Zotero/Bahri et al. - 2024 - Explaining neural scaling laws.pdf}
}

@article{baiExplainableDeepLearning2021,
  title = {Explainable Deep Learning for Efficient and Robust Pattern Recognition: {{A}} Survey of Recent Developments},
  shorttitle = {Explainable Deep Learning for Efficient and Robust Pattern Recognition},
  author = {Bai, Xiao and Wang, Xiang and Liu, Xianglong and Liu, Qiang and Song, Jingkuan and Sebe, Nicu and Kim, Been},
  year = 2021,
  journal = {Pattern Recognition},
  volume = {120},
  pages = {108102},
  publisher = {Elsevier},
  urldate = {2025-06-24}
}

@article{barthelemySolublePhosphorylatedTau2020,
  title = {A Soluble Phosphorylated Tau Signature Links Tau, Amyloid and the Evolution of Stages of Dominantly Inherited {{Alzheimer}}'s Disease},
  author = {Barth{\'e}lemy, Nicolas R. and Li, Yan and {Joseph-Mathurin}, Nelly and Gordon, Brian A. and Hassenstab, Jason and Benzinger, Tammie LS and Buckles, Virginia and Fagan, Anne M. and Perrin, Richard J. and Goate, Alison M.},
  year = 2020,
  journal = {Nature medicine},
  volume = {26},
  number = {3},
  pages = {398--407},
  publisher = {Nature Publishing Group US New York},
  urldate = {2024-12-15},
  file = {/home/paris/Zotero/storage/7JB226HC/PMC7309367.html}
}

@article{basuFundamentalsPETPET2011,
  title = {Fundamentals of {{PET}} and {{PET}}/{{CT}} Imaging},
  author = {Basu, Sandip and Kwee, Thomas C. and Surti, Suleman and Akin, Esma A. and Yoo, Don and Alavi, Abass},
  year = 2011,
  month = jun,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1228},
  number = {1},
  pages = {1--18},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/j.1749-6632.2011.06077.x},
  urldate = {2025-03-28},
  abstract = {In this review, the fundamental principles of fluorodeoxyglucose (FDG) positron emission tomography (PET) and FDG PET/computed tomography (CT) imaging have been described. The basic physics of PET instrumentation, radiotracer chemistry, and the artifacts, as well as normal physiological or benign pathological variants, have been described and presented to the readers in a lucid manner to enable them an easy grasp of the fundamentals of the subject. Finally, we have outlined the current developments in quantitative PET imaging, including dual time point and delayed PET imaging, time-of-flight technology in PET imaging and partial volume correction, and global disease assessment with their potential of being incorporated into the assessment of benign and malignant disorders.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/home/paris/Zotero/storage/FFKAK2W7/Basu et al. - 2011 - Fundamentals of PET and PETCT imaging.pdf}
}

@article{batemanClinicalBiomarkerChanges2012,
  title = {Clinical and {{Biomarker Changes}} in {{Dominantly Inherited Alzheimer}}'s {{Disease}}},
  author = {Bateman, Randall J. and Xiong, Chengjie and Benzinger, Tammie L.S. and Fagan, Anne M. and Goate, Alison and Fox, Nick C. and Marcus, Daniel S. and Cairns, Nigel J. and Xie, Xianyun and Blazey, Tyler M. and Holtzman, David M. and Santacruz, Anna and Buckles, Virginia and Oliver, Angela and Moulder, Krista and Aisen, Paul S. and Ghetti, Bernardino and Klunk, William E. and McDade, Eric and Martins, Ralph N. and Masters, Colin L. and Mayeux, Richard and Ringman, John M. and Rossor, Martin N. and Schofield, Peter R. and Sperling, Reisa A. and Salloway, Stephen and Morris, John C.},
  year = 2012,
  month = aug,
  journal = {New England Journal of Medicine},
  volume = {367},
  number = {9},
  pages = {795--804},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMoa1202753},
  urldate = {2024-12-15},
  langid = {english},
  file = {/home/paris/Zotero/storage/V6KRHLJQ/Bateman et al. - 2012 - Clinical and Biomarker Changes in Dominantly Inherited Alzheimer's Disease.pdf;/home/paris/Zotero/storage/K84C4H7B/NEJMoa1202753.html}
}

@article{begumbektasMachineLearningMedicine2025,
  title = {Machine {{Learning}} for {{Medicine Must Be Interpretable}}, {{Shareable}}, {{Reproducible}} and {{Accountable}} by {{Design}}},
  author = {Beg{\"u}m Bekta{\c s}, Ayy{\"u}ce and G{\"o}nen, Mithat},
  year = 2025,
  journal = {arXiv e-prints},
  pages = {arXiv--2508},
  urldate = {2025-10-15}
}

@misc{BenefitsDangersAnthropomorphic,
  title = {The Benefits and Dangers of Anthropomorphic Conversational Agents \textbar{} {{PNAS}}},
  urldate = {2025-09-10},
  howpublished = {https://www.pnas.org/doi/10.1073/pnas.2415898122}
}

@article{benzingerRegionalVariabilityImaging2013,
  title = {Regional Variability of Imaging Biomarkers in Autosomal Dominant {{Alzheimer}}'s Disease},
  author = {Benzinger, Tammie L. S. and Blazey, Tyler and Jack, Clifford R. and Koeppe, Robert A. and Su, Yi and Xiong, Chengjie and Raichle, Marcus E. and Snyder, Abraham Z. and Ances, Beau M. and Bateman, Randall J. and Cairns, Nigel J. and Fagan, Anne M. and Goate, Alison and Marcus, Daniel S. and Aisen, Paul S. and Christensen, Jon J. and Ercole, Lindsay and Hornbeck, Russ C. and Farrar, Angela M. and Aldea, Patricia and Jasielec, Mateusz S. and Owen, Christopher J. and Xie, Xianyun and Mayeux, Richard and Brickman, Adam and McDade, Eric and Klunk, William and Mathis, Chester A. and Ringman, John and Thompson, Paul M. and Ghetti, Bernardino and Saykin, Andrew J. and Sperling, Reisa A. and Johnson, Keith A. and Salloway, Stephen and Correia, Stephen and Schofield, Peter R. and Masters, Colin L. and Rowe, Christopher and Villemagne, Victor L. and Martins, Ralph and Ourselin, Sebastien and Rossor, Martin N. and Fox, Nick C. and Cash, David M. and Weiner, Michael W. and Holtzman, David M. and Buckles, Virginia D. and Moulder, Krista and Morris, John C.},
  year = 2013,
  month = nov,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {47},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1317918110},
  urldate = {2025-10-15},
  abstract = {Significance                            Beta-amyloid plaque accumulation, glucose hypometabolism, and neuronal atrophy are hallmarks of Alzheimer's disease. However, the regional ordering of these biomarkers prior to dementia remains untested. In a cohort with Alzheimer's disease mutations, we performed an integrated whole-brain analysis of three major imaging techniques: amyloid PET, [               18               F]fluro-deoxyglucose PET, and structural MRI. We found that most gray-matter structures with amyloid plaques later have hypometabolism followed by atrophy. Critically, however, not all regions lose metabolic function, and not all regions atrophy, even when there is significant amyloid deposition. These regional disparities have important implications for clinical trials of disease-modifying therapies.                        ,                             Major imaging biomarkers of Alzheimer's disease include amyloid deposition [imaged with [               11               C]Pittsburgh compound B (PiB) PET], altered glucose metabolism (imaged with [               18               F]fluro-deoxyglucose PET), and structural atrophy (imaged by MRI). Recently we published the initial subset of imaging findings for specific regions in a cohort of individuals with autosomal dominant Alzheimer's disease. We now extend this work to include a larger cohort, whole-brain analyses integrating all three imaging modalities, and longitudinal data to examine regional differences in imaging biomarker dynamics. The anatomical distribution of imaging biomarkers is described in relation to estimated years from symptom onset. Autosomal dominant Alzheimer's disease mutation carrier individuals have elevated PiB levels in nearly every cortical region 15 y before the estimated age of onset. Reduced cortical glucose metabolism and cortical thinning in the medial and lateral parietal lobe appeared 10 and 5 y, respectively, before estimated age of onset. Importantly, however, a divergent pattern was observed subcortically. All subcortical gray-matter regions exhibited elevated PiB uptake, but despite this, only the hippocampus showed reduced glucose metabolism. Similarly, atrophy was not observed in the caudate and pallidum despite marked amyloid accumulation. Finally, before hypometabolism, a hypermetabolic phase was identified for some cortical regions, including the precuneus and posterior cingulate. Additional analyses of individuals in which longitudinal data were available suggested that an accelerated appearance of volumetric declines approximately coincides with the onset of the symptomatic phase of the disease.},
  langid = {english},
  file = {/home/paris/Zotero/storage/NTA8EKTY/Benzinger et al. - 2013 - Regional variability of imaging biomarkers in autosomal dominant Alzheimer’s disease.pdf}
}

@article{betterAlzheimersDiseaseFacts2023,
  title = {Alzheimer's Disease Facts and Figures},
  author = {Better, MAPPING A.},
  year = 2023,
  journal = {Alzheimers Dement},
  volume = {19},
  number = {4},
  pages = {1598--1695},
  urldate = {2024-12-09},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Better - 2023 - Alzheimer’s disease facts and figures.pdf}
}

@misc{BewareExplanationsAI,
  title = {Beware of ``{{Explanations}}'' of {{AI}}},
  urldate = {2025-09-12},
  howpublished = {https://arxiv.org/html/2504.06791v1},
  file = {/home/paris/Zotero/storage/DM3JLS56/2504.html}
}

@misc{BewareExplanationsAIa,
  title = {Beware of ``{{Explanations}}'' of {{AI}}},
  urldate = {2025-09-12},
  howpublished = {https://arxiv.org/html/2504.06791v1}
}

@article{bhagwatUnderstandingImpactPreprocessing2021,
  title = {Understanding the Impact of Preprocessing Pipelines on Neuroimaging Cortical Surface Analyses},
  author = {Bhagwat, Nikhil and Barry, Amadou and Dickie, Erin W and Brown, Shawn T and Devenyi, Gabriel A and Hatano, Koji and DuPre, Elizabeth and Dagher, Alain and Chakravarty, Mallar and Greenwood, Celia M T and Misic, Bratislav and Kennedy, David N and Poline, Jean-Baptiste},
  year = 2021,
  month = jan,
  journal = {GigaScience},
  volume = {10},
  number = {1},
  pages = {giaa155},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giaa155},
  urldate = {2025-04-18},
  abstract = {The choice of preprocessing pipeline introduces variability in neuroimaging analyses that affects the reproducibility of scientific findings. Features derived from structural and functional MRI data are sensitive to the algorithmic or parametric differences of preprocessing tasks, such as image normalization, registration, and segmentation to name a few. Therefore it is critical to understand and potentially mitigate the cumulative biases of pipelines in order to distinguish biological effects from methodological variance.Here we use an open structural MRI dataset (ABIDE), supplemented with the Human Connectome Project, to highlight the impact of pipeline selection on cortical thickness measures. Specifically, we investigate the effect of (i) software tool (e.g., ANTS, CIVET, FreeSurfer), (ii) cortical parcellation (Desikan-Killiany-Tourville, Destrieux, Glasser), and (iii) quality control procedure (manual, automatic). We divide our statistical analyses by (i) method type, i.e., task-free (unsupervised) versus task-driven (supervised); and (ii) inference objective, i.e., neurobiological group differences versus individual prediction.Results show that software, parcellation, and quality control significantly affect task-driven neurobiological inference. Additionally, software selection strongly affects neurobiological (i.e. group) and individual task-free analyses, and quality control alters the performance for the individual-centric prediction tasks.This comparative performance evaluation partially explains the source of inconsistencies in neuroimaging findings. Furthermore, it underscores the need for more rigorous scientific workflows and accessible informatics resources to replicate and compare preprocessing pipelines to address the compounding problem of reproducibility in the age of large-scale, data-driven computational neuroscience.},
  file = {/home/paris/Zotero/storage/2SKLI4H7/Bhagwat et al. - 2021 - Understanding the impact of preprocessing pipelines on neuroimaging cortical surface analyses.pdf;/home/paris/Zotero/storage/CVBYM2AE/6106556.html}
}

@article{bhattacharyaIntegrationMultimodalImaging2025,
  title = {Integration of Multimodal Imaging Data with Machine Learning for Improved Diagnosis and Prognosis in Neuroimaging},
  author = {Bhattacharya, Saurabh and Prusty, Sashikanta and Pande, Sanjay P. and Gulhane, Monali and Lavate, Santosh H. and Rakesh, Nitin and Veerasamy, Saravanan},
  year = 2025,
  journal = {Frontiers in Human Neuroscience},
  volume = {19},
  pages = {1552178},
  publisher = {Frontiers Media SA},
  urldate = {2025-10-24},
  file = {/home/paris/Zotero/storage/PPCP7HU3/Bhattacharya et al. - 2025 - Integration of multimodal imaging data with machine learning for improved diagnosis and prognosis in.pdf}
}

@article{bhosekarReviewDeepLearningbased,
  title = {A {{Review}} of {{Deep Learning-based Multi-modal Medical Image Fusion}}},
  author = {Bhosekar, Shailesh and Singh, Prabhishek and Garg, Deepak and Ravi, Vinayakumar and Diwakar, Manoj},
  doi = {10.2174/0118750362370697250630063814},
  urldate = {2025-10-15},
  abstract = {A Review of Deep Learning-based Multi-modal Medical Image Fusion},
  langid = {english},
  file = {/home/paris/Zotero/storage/ZX7S4D2M/Bhosekar et al. - A Review of Deep Learning-based Multi-modal Medical Image Fusion.pdf}
}

@article{BlackBox2025,
  title = {Black Box},
  year = 2025,
  month = jun,
  journal = {Wikipedia},
  urldate = {2025-09-02},
  abstract = {In science, computing, and engineering, a black box is a system which can be viewed in terms of its inputs and outputs (or transfer characteristics), without any knowledge of its internal workings. Its implementation is "opaque" (black). The term can be used to refer to many inner workings, such as those of a transistor, an engine, an algorithm, the human brain, or an institution or government. To analyze an open system with a typical "black box approach", only the behavior of the stimulus/response will be accounted for, to infer the (unknown) box. The usual representation of this "black box system" is a data flow diagram centered in the box. The opposite of a black box is a system where the inner components or logic are available for inspection, which is most commonly referred to as a white box (sometimes also known as a "clear box" or a "glass box").},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1293422646},
  file = {/home/paris/Zotero/storage/2IL286BH/index.html}
}

@incollection{bottouTradeoffsLargeScaleLearning2011,
  title = {The {{Tradeoffs}} of {{Large-Scale Learning}}},
  booktitle = {Optimization for {{Machine Learning}}},
  author = {Bottou, L{\'e}on and Bousquet, Olivier},
  editor = {Sra, Suvrit and Nowozin, Sebastian and Wright, Stephen J.},
  year = 2011,
  month = sep,
  pages = {351--368},
  publisher = {The MIT Press},
  doi = {10.7551/mitpress/8996.003.0015},
  urldate = {2025-11-04},
  abstract = {This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation--estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.},
  isbn = {978-0-262-29877-3},
  langid = {english},
  file = {/home/paris/Zotero/storage/SXZ7UXWW/Bottou and Bousquet - 2011 - The Tradeoffs of Large-Scale Learning.pdf}
}

@article{bozzaliContributionVoxelbasedMorphometry2006,
  title = {The Contribution of Voxel-Based Morphometry in Staging Patients with Mild Cognitive Impairment},
  author = {Bozzali, M. and Filippi, M. and Magnani, G. and Cercignani, M. and Franceschi, M. and Schiatti, E. and Castiglioni, S. and Mossini, R. and Falautano, M. and Scotti, G. and Comi, G. and Falini, A.},
  year = 2006,
  month = aug,
  journal = {Neurology},
  volume = {67},
  number = {3},
  pages = {453--460},
  publisher = {Wolters Kluwer},
  doi = {10.1212/01.wnl.0000228243.56665.c2},
  urldate = {2025-07-25},
  abstract = {Objective: To assess whether different patterns of regional gray matter loss in patients with mild cognitive impairment (MCI) are associated with different risks of conversion to Alzheimer disease (AD), using MRI and voxel-based morphometry (VBM). Methods: The authors recruited 22 patients with MCI, 22 patients with probable AD, and 20 healthy subjects (HS). T1 volumes from each subject were postprocessed according to an optimized VBM protocol. All patients were clinically followed up (mean [SD] time = 28.7 [5.7] months), and patients with MCI were reclassified into two groups (converters and nonconverters to AD). Results: When comparing patients with AD to HS, widespread areas of reduced gray matter density were found predominantly in temporal, frontal, and parietal lobes and in the insula. Comparing MCI converters and nonconverters with HS, the converters showed more widespread areas of reduced gray matter density than nonconverters, with a pattern of abnormalities similar to that seen in patients with AD. Conversely, when comparing the same groups with patients with AD, MCI nonconverters showed a pattern of gray matter density similar to that of HS. Areas of decreased gray matter density were also found in MCI converters compared with nonconverters. Conclusions: Different patterns of gray matter density distribution in patients with mild cognitive impairment may be associated to different rates of conversion to Alzheimer disease.},
  file = {/home/paris/gdrive/Zotero/Bozzali et al. - 2006 - The contribution of voxel-based morphometry in staging patients with mild cognitive impairment.pdf}
}

@article{braakNeuropathologicalStageingAlzheimerrelated1991,
  title = {Neuropathological Stageing of {{Alzheimer-related}} Changes},
  author = {Braak, Heiko and Braak, Eva},
  year = 1991,
  journal = {Acta neuropathologica},
  volume = {82},
  number = {4},
  pages = {239--259},
  publisher = {Springer},
  urldate = {2025-03-14},
  file = {/home/paris/Zotero/storage/BH2HIUZV/Braak and Braak - 1991 - Neuropathological stageing of Alzheimer-related changes.pdf}
}

@article{braakStagesPathologicProcess2011,
  title = {Stages of the Pathologic Process in {{Alzheimer}} Disease: Age Categories from 1 to 100 Years},
  shorttitle = {Stages of the Pathologic Process in {{Alzheimer}} Disease},
  author = {Braak, Heiko and Thal, Dietmar R. and Ghebremedhin, Estifanos and Del Tredici, Kelly},
  year = 2011,
  journal = {Journal of Neuropathology \& Experimental Neurology},
  volume = {70},
  number = {11},
  pages = {960--969},
  publisher = {American Association of Neuropathologists, Inc.},
  urldate = {2024-12-15}
}

@article{buadesNonlocalMeansDenoising2011,
  title = {Non-Local Means Denoising},
  author = {Buades, Antoni and Coll, Bartomeu and Morel, Jean-Michel},
  year = 2011,
  journal = {Image processing on line},
  volume = {1},
  pages = {208--212},
  urldate = {2026-01-19},
  file = {/home/paris/Zotero/storage/Q28ZNLQ7/Buades et al. - 2011 - Non-local means denoising.pdf}
}

@article{buadesReviewImageDenoising2005,
  title = {A {{Review}} of {{Image Denoising Algorithms}}, with a {{New One}}},
  author = {Buades, A. and Coll, B. and Morel, J. M.},
  year = 2005,
  month = jan,
  journal = {Multiscale Modeling \& Simulation},
  volume = {4},
  number = {2},
  pages = {490--530},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1540-3459},
  doi = {10.1137/040616024},
  urldate = {2025-07-01},
  abstract = {In this paper we propose a generic recursive algorithm for improving image denoising methods. Given the initial denoised image, we suggest repeating the following ``SOS'' procedure: (i) Strengthen the signal by adding the previous denoised image to the degraded input image, (ii) Operate the denoising method on the strengthened image, and (iii) Subtract the previous denoised image from the restored signal-strengthened outcome. The convergence of this process is studied for the K-SVD image denoising and related algorithms. Still in the context of K-SVD image denoising, we introduce an interesting interpretation of the SOS algorithm as a technique for closing the gap between the local patch-modeling and the global restoration task, thereby leading to improved performance. In a quest for the theoretical origin of the SOS algorithm, we provide a graph-based interpretation of our method, where the SOS recursive update effectively minimizes a penalty function that aims to denoise the image, while being regularized by the graph Laplacian. We demonstrate the SOS boosting algorithm for several leading denoising methods (K-SVD, NLM, BM3D, and EPLL), showing its tendency to further improve denoising performance.},
  file = {/home/paris/gdrive/Zotero/Denosing/Buades et al. - 2005 - A Review of Image Denoising Algorithms, with a New One.pdf}
}

@article{buxtonPhysicsFunctionalMagnetic2013,
  title = {The Physics of Functional Magnetic Resonance Imaging ({{fMRI}})},
  author = {Buxton, Richard B},
  year = 2013,
  month = sep,
  journal = {Reports on Progress in Physics},
  volume = {76},
  number = {9},
  pages = {096601},
  issn = {0034-4885, 1361-6633},
  doi = {10.1088/0034-4885/76/9/096601},
  urldate = {2025-04-01},
  copyright = {http://iopscience.iop.org/info/page/text-and-data-mining},
  file = {/home/paris/Zotero/storage/A4FAVSBJ/Buxton - 2013 - The physics of functional magnetic resonance imaging (fMRI).pdf}
}

@article{caoPrevalenceDementiaSystematic2020,
  title = {The {{Prevalence}} of {{Dementia}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  shorttitle = {The {{Prevalence}} of {{Dementia}}},
  author = {Cao, Qing and Tan, Chen-Chen and Xu, Wei and Hu, Hao and Cao, Xi-Peng and Dong, Qiang and Tan, Lan and Yu, Jin-Tai},
  year = 2020,
  month = feb,
  journal = {Journal of Alzheimer's Disease},
  volume = {73},
  number = {3},
  pages = {1157--1166},
  publisher = {SAGE Publications},
  issn = {1387-2877},
  doi = {10.3233/JAD-191092},
  urldate = {2025-10-17},
  abstract = {Dementia is a severe neurodegenerative disorder and it can be categorized into several subtypes by different pathogenic causes. We sought to comprehensively analyzed the prevalence of dementia from perspectives of geographic region (Asia, Africa, South America, and Europe/North America), age, and gender. We searched PubMed and EMBASE for relevant articles on dementia published from January 1985 to August 2019. In these studies, analyses were stratified by geographic region, age, and gender. Meta-regression was conducted to identify if there were significant differences between groups. We included forty-seven studies. Among the individuals aged 50 and over in the community, the pooled prevalence for all-cause dementia, Alzheimer's disease, and vascular dementia were 697 (CI95\%: 546--864) per 10,000 persons, 324 (CI95\%: 228--460) per 10,000 persons, and 116 (CI95\%: 86--157) per 10,000 persons, respectively. In our study, the prevalence of all-type dementia in individuals aged 100 years and older (6,592 per 10,000 cases) is 244 times higher than in those aged 50--59 (27 per 10,000 cases). The number of people living with dementia approximately doubles every five years. The prevalence was greater in women than in men (788 cases versus 561 cases per 10,000 persons) in overall analysis. In individuals aged 60 to 69 years, AD prevalence in females was 1.9 times greater than that in males (108 cases versus 56 cases per 10,000 persons), while the prevalence of VaD was 1.8 times greater in males than in females (56 cases versus 32 cases per 10,000 persons). Prevalence rate was higher in Europe and North America than in Asia, Africa, and South America.},
  langid = {english}
}

@article{castellanoAutomatedDetectionAlzheimers2024,
  title = {Automated Detection of {{Alzheimer}}'s Disease: A Multi-Modal Approach with {{3D MRI}} and Amyloid {{PET}}},
  shorttitle = {Automated Detection of {{Alzheimer}}'s Disease},
  author = {Castellano, Giovanna and Esposito, Andrea and Lella, Eufemia and Montanaro, Graziano and Vessio, Gennaro},
  year = 2024,
  month = mar,
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {5210},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-56001-9},
  urldate = {2025-10-24},
  abstract = {Recent advances in deep learning and imaging technologies have revolutionized automated medical image analysis, especially in diagnosing Alzheimer's disease through neuroimaging. Despite the availability of various imaging modalities for the same patient, the development of multi-modal models leveraging these modalities remains underexplored. This paper addresses this gap by proposing and evaluating classification models using 2D and 3D MRI images and amyloid PET scans in uni-modal and multi-modal frameworks. Our findings demonstrate that models using volumetric data learn more effective representations than those using only 2D images. Furthermore, integrating multiple modalities enhances model performance over single-modality approaches significantly. We achieved state-of-the-art performance on the OASIS-3 cohort. Additionally, explainability analyses with Grad-CAM indicate that our model focuses on crucial AD-related regions for its predictions, underscoring its potential to aid in understanding the disease's causes.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Alzheimer's disease,Diagnostic markers},
  file = {/home/paris/Zotero/storage/UUZQJDPZ/Castellano et al. - 2024 - Automated detection of Alzheimer’s disease a multi-modal approach with 3D MRI and amyloid PET.pdf}
}

@misc{celayaMISTSimpleScalable2024,
  title = {{{MIST}}: {{A Simple}} and {{Scalable End-To-End 3D Medical Imaging Segmentation Framework}}},
  shorttitle = {{{MIST}}},
  author = {Celaya, Adrian and Lim, Evan and Glenn, Rachel and Mi, Brayden and Balsells, Alex and Schellingerhout, Dawid and Netherton, Tucker and Chung, Caroline and Riviere, Beatrice and Fuentes, David},
  year = 2024,
  month = nov,
  number = {arXiv:2407.21343},
  eprint = {2407.21343},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.21343},
  urldate = {2025-06-24},
  abstract = {Medical imaging segmentation is a highly active area of research, with deep learning-based methods achieving state-of-the-art results in several benchmarks. However, the lack of standardized tools for training, testing, and evaluating new methods makes the comparison of methods difficult. To address this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple, modular, and end-to-end medical imaging segmentation framework designed to facilitate consistent training, testing, and evaluation of deep learning-based medical imaging segmentation methods. MIST standardizes data analysis, preprocessing, and evaluation pipelines, accommodating multiple architectures and loss functions. This standardization ensures reproducible and fair comparisons across different methods. We detail MIST's data format requirements, pipelines, and auxiliary features and demonstrate its efficacy using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results highlight MIST's ability to produce accurate segmentation masks and its scalability across multiple GPUs, showcasing its potential as a powerful tool for future medical imaging research and development.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/gdrive/Zotero/Celaya et al. - 2024 - MIST A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework.pdf;/home/paris/Zotero/storage/KTH3DXGF/2407.html}
}

@book{chakiBeginnersGuideImage2018,
  title = {A Beginner's Guide to Image Preprocessing Techniques},
  author = {Chaki, Jyotismita and Dey, Nilanjan},
  year = 2018,
  publisher = {CRC Press},
  urldate = {2025-05-21}
}

@article{ChallengesMachineLearning2022,
  title = {Challenges for Machine Learning in Clinical Translation of Big Data Imaging Studies},
  year = 2022,
  month = dec,
  journal = {Neuron},
  volume = {110},
  number = {23},
  pages = {3866--3881},
  publisher = {Cell Press},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.09.012},
  urldate = {2025-10-15},
  abstract = {Combining deep learning image analysis methods and large-scale imaging datasets offers many opportunities to neuroscience imaging and epidemiology. Ho\dots},
  langid = {american},
  file = {/home/paris/Zotero/storage/2ZI8CR7N/2022 - Challenges for machine learning in clinical translation of big data imaging studies.pdf;/home/paris/Zotero/storage/I7FRDTD5/S0896627322008170.html}
}

@article{chetelatDirectVoxelbasedComparison2008,
  title = {Direct Voxel-Based Comparison between Grey Matter Hypometabolism and Atrophy in {{Alzheimer}}'s Disease},
  author = {Ch{\'e}telat, G. and Desgranges, B. and Landeau, B. and M{\'e}zenge, F. and Poline, J. B. and {de la Sayette}, V. and Viader, F. and Eustache, F. and Baron, J.-C.},
  year = 2008,
  month = jan,
  journal = {Brain},
  volume = {131},
  number = {1},
  pages = {60--71},
  issn = {0006-8950},
  doi = {10.1093/brain/awm288},
  urldate = {2025-07-25},
  abstract = {Although the patterns of structural and metabolic brain alterations in Alzheimer's disease are being refined and discrepancies between them are being underlined, the exact relationships between atrophy and hypometabolism are still unclear. In this study, we aimed to provide a direct comparison between grey matter atrophy and hypometabolism in a sample of patients with clinically probable Alzheimer's disease, using a voxel-based method specially designed to statistically compare the two imaging modalities. Eighteen patients with probable Alzheimer's disease of mild severity and 15 healthy aged controls underwent both high-resolution T1 MRI and resting-state 18FDG-PET. The MRI data sets were handled using optimized VBM. The PET data were coregistered to their corresponding MRI, corrected voxel-wise for partial volume averaging and spatially normalized using the same parameters as those of their corresponding MRI volume. A differential smoothing was applied on the MRI and PET data sets to equalize their effective smoothness and resolution. For each patient, Z-score maps of atrophy and hypometabolism were created by comparing to the controls data set, respectively averaged to provide the profile of hypometabolism and atrophy, and entered in a voxel-by-voxel SPM analysis to assess the statistical differences between hypometabolism and atrophy. The observed patterns of hypometabolism and atrophy were consistent with previous studies. However, the direct comparison revealed marked regional variability in the relationship between hypometabolism and atrophy. Thus, the hypometabolism significantly exceeded atrophy in most altered structures, particularly in the posterior cingulate-precuneus, orbitofrontal, inferior temporo-parietal, parahippocampal, angular and fusiform areas. In contrast, a few hypometabolic structures among which the hippocampus exhibited similar degrees of atrophy and hypometabolism, a profile that significantly differed from the posterior cingulate. Excessive hypometabolism relative to atrophy suggests the intervention of additional hypometabolism-inducing factors, such as disconnection and amyloid deposition, resulting in genuine functional perturbation ahead of actual atrophy and perhaps of pathology as well. Conversely, in the hippocampus, where disconnection processes are also likely to occur, relative synaptic compensatory mechanisms may be taking place, maintaining neuronal activity in the face of structural alterations.},
  file = {/home/paris/gdrive/Zotero/Chételat et al. - 2008 - Direct voxel-based comparison between grey matter hypometabolism and atrophy in Alzheimer's disease.pdf;/home/paris/Zotero/storage/2GWJ86F5/awm288.html}
}

@article{chetelatEarlyDiagnosisAlzheimers2003a,
  title = {Early Diagnosis of Alzheimer's Disease: Contribution of Structural Neuroimaging},
  shorttitle = {Early Diagnosis of Alzheimer's Disease},
  author = {a{\"e}l Chetelat, G. and Baron, Jean-Claude},
  year = 2003,
  month = feb,
  journal = {NeuroImage},
  volume = {18},
  number = {2},
  pages = {525--541},
  issn = {1053-8119},
  doi = {10.1016/S1053-8119(02)00026-5},
  urldate = {2024-12-20},
  abstract = {To accurately predict the development of Alzheimer's disease (AD) at its predementia stage would be a major breakthrough from both therapeutic and research standpoints. In this review, our focus is on markers obtained with structural imaging---especially magnetic resonance imaging (MRI)---and on studies of subjects at risk of developing AD. Among the latter, amnestic mild cognitive impairment (MCI) is currently the most commonly accepted reference, and therefore is specially targeted in this review. MCI refers to patients with significant but isolated memory impairment relative to subjects of identical age. Consistent with established histopathological data, structural imaging studies comparing patients with early probable AD to healthy aged subjects have shown that the most specific and sensitive features of AD at this stage are hippocampal and entorhinal cortex atrophy, especially when combined with a reduced volume of the temporal neocortex. MCI patients have significant hippocampal atrophy when compared to aged normal controls. When comparing patients with probable AD to MCI subjects, hippocampal region atrophy significantly extends to the neighboring temporal association neocortex. However, only longitudinal studies of MCI subjects are suited to assess (in a retrospective way) the predictive value of initial atrophy measurements for progression to AD. Few such studies have been published so far and for the most they were based on small samples. Furthermore, the comparison among studies is clouded by differences in both populations studied and MRI methodology used. Nevertheless, comparing the initial MRI data of at-risk subjects who convert to AD at follow-up to those of nonconverters suggests that a reduced association temporal neocortex volume combined with hippocampal or anterior cingulate cortex atrophy may be the best predictor of progression to AD. These data, although still preliminary, are consistent with postmortem studies describing the hierarchical progression of tau lesions in normal aging and early stages of AD, such that damage to the medial temporal lobe and association cortex would account for the memory and nonmemory cognitive impairments, respectively, the combination of which is required to operationally define probable AD. Future research in this field should capitalize on thorough methodology for brain structure delineation, and combine atrophy measurements to cognitive and/or functional imaging data.},
  file = {/home/paris/Zotero/storage/4DA7VQCW/S1053811902000265.html}
}

@article{chiccoAdvantagesMatthewsCorrelation2020,
  title = {The Advantages of the {{Matthews}} Correlation Coefficient ({{MCC}}) over {{F1}} Score and Accuracy in Binary Classification Evaluation},
  author = {Chicco, Davide and Jurman, Giuseppe},
  year = 2020,
  month = jan,
  journal = {BMC Genomics},
  volume = {21},
  pages = {6},
  issn = {1471-2164},
  doi = {10.1186/s12864-019-6413-7},
  urldate = {2025-08-28},
  abstract = {Background To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets. Results The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset. Conclusions In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
  pmcid = {PMC6941312},
  pmid = {31898477},
  file = {/home/paris/gdrive/Zotero/Chicco and Jurman - 2020 - The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary cl.pdf}
}

@article{chiccoMatthewsCorrelationCoefficient2021,
  title = {The {{Matthews}} Correlation Coefficient ({{MCC}}) Is More Reliable than Balanced Accuracy, Bookmaker Informedness, and Markedness in Two-Class Confusion Matrix Evaluation},
  author = {Chicco, Davide and T{\"o}tsch, Niklas and Jurman, Giuseppe},
  year = 2021,
  month = feb,
  journal = {BioData Mining},
  volume = {14},
  pages = {13},
  issn = {1756-0381},
  doi = {10.1186/s13040-021-00244-z},
  urldate = {2025-09-27},
  abstract = {Evaluating binary classifications is a pivotal task in statistics and machine learning, because it can influence decisions in multiple areas, including for example prognosis or therapies of patients in critical conditions. The scientific community has not agreed on a general-purpose statistical indicator for evaluating two-class confusion matrices (having true positives, true negatives, false positives, and false negatives) yet, even if advantages of the Matthews correlation coefficient (MCC) over accuracy and F1 score have already been shown.In this manuscript, we reaffirm that MCC is a robust metric that summarizes the classifier performance in a single value, if positive and negative cases are of equal importance. We compare MCC to other metrics which value positive and negative cases equally: balanced accuracy (BA), bookmaker informedness (BM), and markedness (MK). We explain the mathematical relationships between MCC and these indicators, then show some use cases and a bioinformatics scenario where these metrics disagree and where MCC generates a more informative response.Additionally, we describe three exceptions where BM can be more appropriate: analyzing classifications where dataset prevalence is unrepresentative, comparing classifiers on different datasets, and assessing the random guessing level of a classifier. Except in these cases, we believe that MCC is the most informative among the single metrics discussed, and suggest it as standard measure for scientists of all fields. A Matthews correlation coefficient close to +1, in fact, means having high values for all the other confusion matrix metrics. The same cannot be said for balanced accuracy, markedness, bookmaker informedness, accuracy and F1 score.},
  pmcid = {PMC7863449},
  pmid = {33541410},
  file = {/home/paris/gdrive/Zotero/Chicco et al. - 2021 - The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker inform.pdf}
}

@article{chooVisualAnalyticsExplainable2018,
  title = {Visual Analytics for Explainable Deep Learning},
  author = {Choo, Jaegul and Liu, Shixia},
  year = 2018,
  journal = {IEEE computer graphics and applications},
  volume = {38},
  number = {4},
  pages = {84--92},
  publisher = {IEEE},
  urldate = {2025-06-24}
}

@misc{ciosUniquenessMedicalData2019,
  title = {Uniqueness of {{Medical Data Mining}}: {{How}} the New Technologies and Data They Generate Are Transforming Medicine},
  shorttitle = {Uniqueness of {{Medical Data Mining}}},
  author = {Cios, Krzysztof J. and Krawczyk, Bartosz and Cios, Jacquelyne and Staley, Kevin J.},
  year = 2019,
  month = may,
  number = {arXiv:1905.09203},
  eprint = {1905.09203},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.09203},
  urldate = {2025-10-24},
  abstract = {The paper describes how the new technologies and data they generate are transforming medicine. It stresses the uniqueness of heterogeneous medical data and the ways of dealing with them. It lists different sources that generate big medical data, their security, legal and ethical issues, as well as machine learning/AI methods of dealing with them. A unique feature of the paper is use of case studies to illustrate how the new technologies influence medical practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/home/paris/Zotero/storage/XJWCHTZP/Cios et al. - 2019 - Uniqueness of Medical Data Mining How the new technologies and data they generate are transforming.pdf;/home/paris/Zotero/storage/YIZ6B8DB/1905.html}
}

@misc{ClassificationBrainImage,
  title = {Classification of {{Brain Image Tumor}} Using {{EfficientNet B1-B2 Deep Learning}} \textbar{} {{Semesta Teknika}}},
  urldate = {2025-06-24},
  howpublished = {https://journal.umy.ac.id/index.php/st/article/view/19691},
  file = {/home/paris/gdrive/Zotero/Classification of Brain Image Tumor using EfficientNet B1-B2 Deep Learning  Semesta Teknika.pdf}
}

@article{cletiEfficientDeepLearning,
  title = {Efficient {{Deep Learning}}: {{A Survey}} of {{Model Compression}} and {{Optimization Techniques}} for {{Resource-Constrained Environments}}},
  shorttitle = {Efficient {{Deep Learning}}},
  author = {Cleti, Meade},
  urldate = {2025-10-16}
}

@misc{ClinicalNuclearMedicine,
  title = {Clinical {{Nuclear Medicine}}},
  urldate = {2025-03-28},
  howpublished = {https://journals.lww.com/nuclearmed/abstract/2014/10000/brain\_pet\_in\_the\_diagnosis\_of\_alzheimer\_s\_disease.26.aspx},
  file = {/home/paris/Zotero/storage/2ADYV4FI/brain_pet_in_the_diagnosis_of_alzheimer_s_disease.26.html}
}

@article{collewetInfluenceMRIAcquisition2004,
  title = {Influence of {{MRI}} Acquisition Protocols and Image Intensity Normalization Methods on Texture Classification},
  author = {Collewet, G. and Strzelecki, M. and Mariette, F.},
  year = 2004,
  month = jan,
  journal = {Magnetic Resonance Imaging},
  volume = {22},
  number = {1},
  pages = {81--91},
  issn = {0730-725X},
  doi = {10.1016/j.mri.2003.09.001},
  urldate = {2025-06-03},
  abstract = {Texture analysis methods quantify the spatial variations in gray level values within an image and thus can provide useful information on the structures observed. However, they are sensitive to acquisition conditions due to the use of different protocols and to intra- and interscanner variations in the case of MRI. The influence was studied of two protocols and four different conditions of normalization of gray levels on the discrimination power of texture analysis methods applied to soft cheeses. Thirty-two samples of soft cheese were chosen at two different ripening periods (16 young and 16 old samples) in order to obtain two different microscopic structures of the protein gel. Proton density and T2-weighted MR images were acquired using a spin echo sequence on a 0.2 T scanner. Gray levels were normalized according to four methods: original gray levels, same maximum for all images, same mean for all images, and dynamics limited to {$\mu$} \textpm{} 3{$\sigma$}. Regions of interest were automatically defined, and texture descriptors were then computed for the co-occurrence matrix, run length matrix, gradient matrix, autoregressive model, and wavelet transform. The features with the lowest probability of error and average correlation coefficient were selected and used for classification with 1-nearest neighbor (1-NN) classifier. The best results were obtained when using the limitation of dynamics to {$\mu$} \textpm{} 3{$\sigma$}, which enhanced the differences between the two classes. The results demonstrated the influence of the normalization method and of the acquisition protocol on the effectiveness of the classification and also on the parameters selected for classification. These results indicate the need to evaluate sensitivity to MR acquisition protocols and to gray level normalization methods when texture analysis is required.},
  keywords = {Classification,Gray level normalization,Texture analysis},
  annotation = {GSCC: 0000601 2025-06-15T15:38:32.623Z 0.54},
  file = {/home/paris/gdrive/Zotero/Thesis/Section 4/Intensity Normalization/Collewet et al. - 2004 - Influence of MRI acquisition protocols and image intensity normalization methods on texture classifi.pdf;/home/paris/Zotero/storage/2EQMWPN2/S0730725X03003096.html}
}

@article{coxAFNISoftwareAnalysis1996,
  title = {{{AFNI}}: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages},
  shorttitle = {{{AFNI}}},
  author = {Cox, R. W.},
  year = 1996,
  month = jun,
  journal = {Computers and Biomedical Research, an International Journal},
  volume = {29},
  number = {3},
  pages = {162--173},
  issn = {0010-4809},
  doi = {10.1006/cbmr.1996.0014},
  abstract = {A package of computer programs for analysis and visualization of three-dimensional human brain functional magnetic resonance imaging (FMRI) results is described. The software can color overlay neural activation maps onto higher resolution anatomical scans. Slices in each cardinal plane can be viewed simultaneously. Manual placement of markers on anatomical landmarks allows transformation of anatomical and functional scans into stereotaxic (Talairach-Tournoux) coordinates. The techniques for automatically generating transformed functional data sets from manually labeled anatomical data sets are described. Facilities are provided for several types of statistical analyses of multiple 3D functional data sets. The programs are written in ANSI C and Motif 1.2 to run on Unix workstations.},
  langid = {english},
  pmid = {8812068},
  keywords = {Brain,Computer Systems,Data Display,Humans,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Programming Languages,Software,Stereotaxic Techniques,User-Computer Interface},
  file = {/home/paris/Zotero/storage/J7RHFBJX/Cox - 1996 - AFNI software for analysis and visualization of functional magnetic resonance neuroimages.pdf}
}

@article{cuiDeepMultimodalFusion2023,
  title = {Deep Multimodal Fusion of Image and Non-Image Data in Disease Diagnosis and Prognosis: A Review},
  shorttitle = {Deep Multimodal Fusion of Image and Non-Image Data in Disease Diagnosis and Prognosis},
  author = {Cui, Can and Yang, Haichun and Wang, Yaohong and Zhao, Shilin and Asad, Zuhayr and Coburn, Lori A and Wilson, Keith T and Landman, Bennett A and Huo, Yuankai},
  year = 2023,
  month = apr,
  journal = {Progress in biomedical engineering (Bristol, England)},
  volume = {5},
  number = {2},
  pages = {10.1088/2516-1091/acc2fe},
  issn = {2516-1091},
  doi = {10.1088/2516-1091/acc2fe},
  urldate = {2025-10-24},
  abstract = {The rapid development of diagnostic technologies in healthcare is leading to higher requirements for physicians to handle and integrate the heterogeneous, yet complementary data that are produced during routine practice. For instance, the personalized diagnosis and treatment planning for a single cancer patient relies on various images (e.g. radiology, pathology and camera images) and non-image data (e.g. clinical data and genomic data). However, such decision-making procedures can be subjective, qualitative, and have large inter-subject variabilities. With the recent advances in multimodal deep learning technologies, an increasingly large number of efforts have been devoted to a key question: how do we extract and aggregate multimodal information to ultimately provide more objective, quantitative computer-aided clinical decision making? This paper reviews the recent studies on dealing with such a question. Briefly, this review will include the (a) overview of current multimodal learning workflows, (b) summarization of multimodal fusion methods, (c) discussion of the performance, (d) applications in disease diagnosis and prognosis, and (e) challenges and future directions.},
  pmcid = {PMC10288577},
  pmid = {37360402},
  file = {/home/paris/Zotero/storage/3Q3AIAAF/Cui et al. - 2023 - Deep multimodal fusion of image and non-image data in disease diagnosis and prognosis a review.pdf}
}

@article{danielyanBM3DFramesVariational2011,
  title = {{{BM3D}} Frames and Variational Image Deblurring},
  author = {Danielyan, Aram and Katkovnik, Vladimir and Egiazarian, Karen},
  year = 2011,
  journal = {IEEE Transactions on image processing},
  volume = {21},
  number = {4},
  pages = {1715--1728},
  publisher = {IEEE},
  urldate = {2026-01-19},
  file = {/home/paris/Zotero/storage/83IPFB4W/Danielyan et al. - 2011 - BM3D frames and variational image deblurring.pdf}
}

@inproceedings{dashTransferLearningBased2024,
  title = {Transfer Learning Based Lightweight Model for Classification of {{Alzheimer}}'s Disease Using Brain {{MR}} Images},
  booktitle = {2024 {{OPJU International Technology Conference}} ({{OTCON}}) on {{Smart Computing}} for {{Innovation}} and {{Advancement}} in {{Industry}} 4.0},
  author = {Dash, Prasanta Kumar and Sisodia, Dilip Singh},
  year = 2024,
  month = jun,
  pages = {1--6},
  doi = {10.1109/OTCON60325.2024.10688268},
  urldate = {2025-10-16},
  abstract = {Alzheimer's disease (AD) is one of the prevailing, degenerative, and progressive brain disease which is the primary cause of dementia all over the world. It steadily worsens by affecting the memory, behavioral patterns, and reasoning of an individual. Traditional manual assessment of AD progression using patient's brain MRI scans by radiologist could lead to certain errors with consequential impacts for patient. So, automated end-to-end frameworks are used to identify various AD stages at an early stage. Deep neural networks are widely used to detect AD using MR images. However, the scarcity of MR images for training the Deep Learning models is a significant problem for AD identification. To resolve this issue, transfer learning techniques are used with different pre-train models such as VGGNet, ResNet, DenseNet, and InceptionNet to classify AD using MR images. However, transfer learning models generally take more training parameters with more memory space. Hence, it is difficult to deploy these models in resource constraint environments such as medical applications. To overcome the above problem, we designed a lightweight deep neural network using a pre-trained MobileNetV1 with an optimized architecture that employs depth-wise separable convolution and finetune the model for AD classification. The proposed model was evaluated against models like VGG16, DenseNet, AlexNet, and ResNet50 in existing literatures using evaluation measures such as recall, precision, F1 score, and accuracy. The proposed model outperformed other cutting-edge models used in this study, achieving a precision of 98\%, accuracy of 97.8\%, recall of 95\%, and F1 score of 96\%.},
  keywords = {Accuracy,Alzheimer's disease,Brain modeling,Brain MRI,Computational modeling,Depth-wise separable convolution,Fine tuning,Lightweight models,Medical services,Positron emission tomography,Residual neural networks,Technological innovation,Training,Transfer learning}
}

@book{dawbarnNeurobiologyAlzheimersDisease2007,
  title = {Neurobiology of {{Alzheimer}}'s {{Disease}}},
  author = {Dawbarn, David and Allen, Shelley J.},
  year = 2007,
  month = may,
  publisher = {Oxford University Press},
  abstract = {Alzheimer's disease is the most common form of dementia in the elderly; 450,000 people in the UK and 4.5 million people in the USA suffer with this disease. This 3rd edition of Neurobiology of Alzheimer's Disease gives a comprehensive and readable introduction to the disease, from molecular pathology to clinical practice. The book is intended for readers new to the field, and it also covers an extensive range of themes for those with in-depth knowledge of Alzheimer's disease. It will therefore act either as an introduction to the whole field of neurodegeneration or it will help experienced researchers to access the latest research in specialist topics. Each chapter is written by eminent scientists leading their fields in neuropathology, clinical practice and molecular neurobiology; appendices detail disease-associated proteins, their sequences, familial mutations and known structures. It will be essential reading for students interested in neurodegeneration and for researchers and clinicians, giving a coherent and cohesive approach to the whole area of research, and allowing access at different levels. For those in the pharmaceutical industry it describes the underlying molecular mechanisms involved in the pathogenesis of Alzheimer's disease and explains how current and potential therapeutics may work.},
  googlebooks = {agRREAAAQBAJ},
  isbn = {978-0-19-103458-9},
  langid = {english},
  keywords = {Medical / Genetics,Medical / Neurology,Medical / Neuroscience,Medical / Psychiatry / General,Science / Life Sciences / Cell Biology,Science / Life Sciences / Molecular Biology,Science / Life Sciences / Neuroscience}
}

@article{deasis-cruzFetalGANAutomatedSegmentation2022,
  title = {{{FetalGAN}}: {{Automated Segmentation}} of {{Fetal Functional Brain MRI Using Deep Generative Adversarial Learning}} and {{Multi-Scale 3D U-Net}}},
  shorttitle = {{{FetalGAN}}},
  author = {{De Asis-Cruz}, Josepheen and Krishnamurthy, Dhineshvikram and Jose, Chris and Cook, Kevin M. and Limperopoulos, Catherine},
  year = 2022,
  month = jun,
  journal = {Frontiers in Neuroscience},
  volume = {16},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2022.887634},
  urldate = {2025-06-24},
  abstract = {An important step in the preprocessing of resting state functional magnetic resonance images (rs-fMRI) is the separation of brain from non-brain voxels. Widely used imaging tools such as FSL's BET2 and AFNI's 3dSkullStrip accomplish this task effectively. In fetal functional brain imaging, however, the presence of maternal tissue around the brain coupled with the non-standard position of the fetal head limit the usefulness of these tools. Accurate brain masks are thus generated manually, a time-consuming and tedious process that slows down preprocessing of fetal rs-fMRI. Recently, deep learning-based segmentation models such as convolutional neural networks (CNNs) have been increasingly used for automated segmentation of medical images, including the fetal brain. Here, we propose a computationally efficient end-to-end generative adversarial neural network (GAN) for segmenting the fetal brain. This method, which we call FetalGAN, yielded whole brain masks that closely approximated the manually labeled ground truth. FetalGAN performed better than 3D U-Net model and BET2: FetalGAN, dice score=0.942+/-0.095, precision=0.973+/-0.040; 3D U-Net, dice score=0.930+/-0.098, precision = 0.940+/-0.102, BET2, dice score=0.841+/-0.101, precision=0.747+/-0.126. FetalGAN was also faster than 3D U-Net and the manual method (7.35 sec vs 10.25 sec vs \textasciitilde 5 min/volume). To the best of our knowledge, this is the first successful implementation of 3D CNN with GAN on fetal fMRI brain images and represents a significant advance in fully automating processing of rs-MRI images.},
  langid = {english},
  keywords = {3D U-Net,deep learning,fetal brain,fetal rs-fMRI,generative adversarial networks (GANs),resting state,segmentation},
  file = {/home/paris/gdrive/Zotero/De Asis-Cruz et al. - 2022 - FetalGAN Automated Segmentation of Fetal Functional Brain MRI Using Deep Generative Adversarial Lea.pdf}
}

@article{dehsarviADPrepFullyAutomated2023,
  title = {{{ADPrep}} - {{A}} Fully Automated {{Alzheimer}}'s {{Disease Neuroimaging Preprocessing Pipeline}} for {{MRI}} and Multi-Tracer {{PET}} Data},
  author = {Dehsarvi, Amir and Denecke, Jannis and Biel, Davina and Dewenter, Anna and Roemer, Sebastian Niclas and Steward, Anna and Wanger, Fabian and Brendel, Matthias and Franzmeier, Nicolai},
  year = 2023,
  month = dec,
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  pages = {e081918},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1552-5279},
  doi = {10.1002/alz.081918},
  urldate = {2025-10-24},
  abstract = {Background State-of-the-art preprocessing of MRI and PET data is crucial for Alzheimer's disease (AD) neuroimaging research. Therefore, standardization and harmonization of neuroimaging preprocessin...},
  langid = {english}
}

@article{delisleRealisticImageNormalization2021,
  title = {Realistic Image Normalization for Multi-{{Domain}} Segmentation},
  author = {Delisle, Pierre-Luc and {Anctil-Robitaille}, Benoit and Desrosiers, Christian and Lombaert, Herve},
  year = 2021,
  month = dec,
  journal = {Medical Image Analysis},
  volume = {74},
  pages = {102191},
  issn = {1361-8415},
  doi = {10.1016/j.media.2021.102191},
  urldate = {2025-06-09},
  abstract = {Image normalization is a building block in medical image analysis. Conventional approaches are customarily employed on a per-dataset basis. This strategy, however, prevents the current normalization algorithms from fully exploiting the complex joint information available across multiple datasets. Consequently, ignoring such joint information has a direct impact on the processing of segmentation algorithms. This paper proposes to revisit the conventional image normalization approach by, instead, learning a common normalizing function across multiple datasets. Jointly normalizing multiple datasets is shown to yield consistent normalized images as well as an improved image segmentation when intensity shifts are large. To do so, a fully automated adversarial and task-driven normalization approach is employed as it facilitates the training of realistic and interpretable images while keeping performance on par with the state-of-the-art. The adversarial training of our network aims at finding the optimal transfer function to improve both, jointly, the segmentation accuracy and the generation of realistic images. We have evaluated the performance of our normalizer on both infant and adult brain images from the iSEG, MRBrainS and ABIDE datasets. The results indicate that our contribution does provide an improved realism to the normalized images, while retaining a segmentation accuracy at par with the state-of-the-art learnable normalization approaches.},
  keywords = {3D MRI,Brain segmentation,Data harmonization,Generative adversarial networks,Intensity normalization},
  annotation = {GSCC: 0000025 2025-06-15T15:38:37.221Z 0.14},
  file = {/home/paris/Zotero/storage/PF6IBU78/Delisle et al. - 2021 - Realistic image normalization for multi-Domain segmentation.pdf}
}

@inproceedings{deraadEffectPreprocessingConvolutional2021,
  title = {The {{Effect}} of {{Preprocessing}} on {{Convolutional Neural Networks}} for {{Medical Image Segmentation}}},
  booktitle = {2021 {{IEEE}} 18th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {{de Raad}, K.B. and {van Garderen}, K.A. and Smits, M. and {van der Voort}, S.R. and Incekara, F. and Oei, E.H.G. and Hirvasniemi, J. and Klein, S. and Starmans, M.P.A.},
  year = 2021,
  month = apr,
  pages = {655--658},
  issn = {1945-8452},
  doi = {10.1109/ISBI48211.2021.9433952},
  urldate = {2025-06-24},
  abstract = {In recent years, deep learning has become the leading method for medical image segmentation. While the majority of studies focus on developments of network architectures, several studies have shown that non-architectural factors also play a substantial role in performance improvement. An important factor is preprocessing. However, there is no agreement on which preprocessing steps work best for different applications. The aim of this study was to investigate the effect of preprocessing on model performance. To this end, we conducted a systematic evaluation of 24 preprocessing configurations on three clinical application datasets (brain, liver, and knee). Different configurations of normalization, region of interest selection, bias field correction, and resampling methods were applied before training one convolutional neural network. Performance varied up to 64 percentage points between configurations within one dataset. Across the three datasets, different configurations performed best. In conclusion, to improve model performance, preprocessing should be tuned to the specific segmentation application.},
  keywords = {Biological system modeling,deep learning,Deep learning,Image segmentation,Liver,Network architecture,performance,preprocessing,segmentation,Systematics,Training}
}

@article{deshmaneParallelMRImaging2012a,
  title = {Parallel {{MR}} Imaging},
  author = {Deshmane, Anagha and Gulani, Vikas and Griswold, Mark A. and Seiberlich, Nicole},
  year = 2012,
  month = jul,
  journal = {Journal of Magnetic Resonance Imaging},
  volume = {36},
  number = {1},
  pages = {55--72},
  issn = {1053-1807, 1522-2586},
  doi = {10.1002/jmri.23639},
  urldate = {2025-06-27},
  abstract = {Abstract                            Parallel imaging is a robust method for accelerating the acquisition of magnetic resonance imaging (MRI) data, and has made possible many new applications of MR imaging. Parallel imaging works by acquiring a reduced amount of               k               -space data with an array of receiver coils. These undersampled data can be acquired more quickly, but the undersampling leads to aliased images. One of several parallel imaging algorithms can then be used to reconstruct artifact-free images from either the aliased images (SENSE-type reconstruction) or from the undersampled data (GRAPPA-type reconstruction). The advantages of parallel imaging in a clinical setting include faster image acquisition, which can be used, for instance, to shorten breath-hold times resulting in fewer motion-corrupted examinations. In this article the basic concepts behind parallel imaging are introduced. The relationship between undersampling and aliasing is discussed and two commonly used parallel imaging methods, SENSE and GRAPPA, are explained in detail. Examples of artifacts arising from parallel imaging are shown and ways to detect and mitigate these artifacts are described. Finally, several current applications of parallel imaging are presented and recent advancements and promising research in parallel imaging are briefly reviewed. J. Magn. Reson. Imaging 2012;36:55--72. \copyright{} 2012 Wiley Periodicals, Inc.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Denosing/Deshmane et al. - 2012 - Parallel MR imaging 1.pdf;/home/paris/gdrive/Zotero/Denosing/Deshmane et al. - 2012 - Parallel MR imaging.pdf}
}

@misc{devireddyComparativeStudyExplainable2025,
  title = {A {{Comparative Study}} of {{Explainable AI Methods}}: {{Model-Agnostic}} vs. {{Model-Specific Approaches}}},
  shorttitle = {A {{Comparative Study}} of {{Explainable AI Methods}}},
  author = {Devireddy, Keerthi},
  year = 2025,
  month = apr,
  number = {arXiv:2504.04276},
  eprint = {2504.04276},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.04276},
  urldate = {2025-10-27},
  abstract = {This paper compares model-agnostic and model-specific approaches to explainable AI (XAI) in deep learning image classification. I examine how LIME and SHAP (model-agnostic methods) differ from Grad-CAM and Guided Backpropagation (model-specific methods) when interpreting ResNet50 predictions across diverse image categories. Through extensive testing with various species from dogs and birds to insects I found that each method reveals different aspects of the models decision-making process. Model-agnostic techniques provide broader feature attribution that works across different architectures, while model-specific approaches excel at highlighting precise activation regions with greater computational efficiency. My analysis shows there is no "one-size-fits-all" solution for model interpretability. Instead, combining multiple XAI methods offers the most comprehensive understanding of complex models particularly valuable in high-stakes domains like healthcare, autonomous vehicles, and financial services where transparency is crucial. This comparative framework provides practical guidance for selecting appropriate interpretability techniques based on specific application needs and computational constraints.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/paris/Zotero/storage/TXGIPTXT/Devireddy - 2025 - A Comparative Study of Explainable AI Methods Model-Agnostic vs. Model-Specific Approaches.pdf;/home/paris/Zotero/storage/R2TKQVEF/2504.html}
}

@article{diederikp.kingmaAdamMethodStochastic2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  author = {{Diederik P. Kingma} and Kingma, Diederik P. and {Jimmy Ba} and Ba, Jimmy},
  year = 2014,
  month = dec,
  journal = {arXiv: Learning},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  annotation = {MAG ID: 1522301498}
}

@article{dimitriadisHowRandomRandom2018,
  title = {How Random Is the Random Forest? {{Random}} Forest Algorithm on the Service of Structural Imaging Biomarkers for {{Alzheimer}}'s Disease: From {{Alzheimer}}'s Disease Neuroimaging Initiative ({{ADNI}}) Database},
  shorttitle = {How Random Is the Random Forest?},
  author = {Dimitriadis, Stavros I. and Liparas, Dimitris},
  year = 2018,
  month = jun,
  journal = {Neural Regeneration Research},
  volume = {13},
  number = {6},
  pages = {962--970},
  issn = {1673-5374},
  doi = {10.4103/1673-5374.233433},
  urldate = {2025-08-14},
  abstract = {Neuroinformatics is a fascinating research field that applies computational models and analytical tools to high dimensional experimental neuroscience data for a better understanding of how the brain functions or dysfunctions in brain diseases. Neuroinformaticians work in the intersection of neuroscience and informatics supporting the integration of various sub-disciplines (behavioural neuroscience, genetics, cognitive psychology, etc.) working on brain research. Neuroinformaticians are the pathway of information exchange between informaticians and clinicians for a better understanding of the outcome of computational models and the clinical interpretation of the analysis. Machine learning is one of the most significant computational developments in the last decade giving tools to neuroinformaticians and finally to radiologists and clinicians for an automatic and early diagnosis-prognosis of a brain disease. Random forest (RF) algorithm has been successfully applied to high-dimensional neuroimaging data for feature reduction and also has been applied to classify the clinical label of a subject using single or multi-modal neuroimaging datasets. Our aim was to review the studies where RF was applied to correctly predict the Alzheimer's disease (AD), the conversion from mild cognitive impairment (MCI) and its robustness to overfitting, outliers and handling of non-linear data. Finally, we described our RF-based model that gave us the 1st position in an international challenge for automated prediction of MCI from MRI data.},
  pmcid = {PMC6022472},
  pmid = {29926817},
  file = {/home/paris/gdrive/Zotero/Dimitriadis and Liparas - 2018 - How random is the random forest Random forest algorithm on the service of structural imaging biomar.pdf}
}

@article{diogoEarlyDiagnosisAlzheimers2022,
  title = {Early Diagnosis of {{Alzheimer}}'s Disease Using Machine Learning: A Multi-Diagnostic, Generalizable Approach},
  shorttitle = {Early Diagnosis of {{Alzheimer}}'s Disease Using Machine Learning},
  author = {Diogo, Vasco S{\'a} and Ferreira, Hugo Alexandre and Prata, Diana and {Alzheimer's Disease Neuroimaging Initiative}},
  year = 2022,
  month = aug,
  journal = {Alzheimer's Research \& Therapy},
  volume = {14},
  number = {1},
  pages = {107},
  issn = {1758-9193},
  doi = {10.1186/s13195-022-01047-y},
  abstract = {BACKGROUND: Early and accurate diagnosis of Alzheimer's disease (AD) is essential for disease management and therapeutic choices that can delay disease progression. Machine learning (ML) approaches have been extensively used in attempts to develop algorithms for reliable early diagnosis of AD, although clinical usefulness, interpretability, and generalizability of the classifiers across datasets and MRI protocols remain limited. METHODS: We report a multi-diagnostic and generalizable approach for mild cognitive impairment (MCI) and AD diagnosis using structural MRI and ML. Classifiers were trained and tested using subjects from the AD Neuroimaging Initiative (ADNI) database (n = 570) and the Open Access Series of Imaging Studies (OASIS) project database (n = 531). Several classifiers are compared and combined using voting for a decision. Additionally, we report tests of generalizability across datasets and protocols (IR-SPGR and MPRAGE), the impact of using graph theory measures on diagnostic classification performance, the relative importance of different brain regions on classification for better interpretability, and an evaluation of the potential for clinical applicability of the classifier. RESULTS: Our "healthy controls (HC) vs. AD" classifier trained and tested on the combination of ADNI and OASIS datasets obtained a balanced accuracy (BAC) of 90.6\% and a Matthew's correlation coefficient (MCC) of 0.811. Our "HC vs. MCI vs. AD" classifier trained and tested on the ADNI dataset obtained a 62.1\% BAC (33.3\% being the by-chance cut-off) and 0.438 MCC. Hippocampal features were the strongest contributors to the classification decisions (approx. 25-45\%), followed by temporal (approx. 13\%), cingulate, and frontal regions (approx. 8-13\% each), which is consistent with our current understanding of AD and its progression. Classifiers generalized well across both datasets and protocols. Finally, using graph theory measures did not improve classification performance. CONCLUSIONS: In sum, we present a diagnostic tool for MCI and AD trained using baseline scans and a follow-up diagnosis regardless of progression, which is multi-diagnostic, generalizable across independent data sources and acquisition protocols, and with transparently reported performance. Rated as potentially clinically applicable, our tool may be clinically useful to inform diagnostic decisions in dementia, if successful in real-world prospective clinical trials.},
  langid = {english},
  pmcid = {PMC9347083},
  pmid = {35922851},
  keywords = {Alzheimer Disease,Alzheimer's disease,Classification,Cognitive Dysfunction,Dementia,Early diagnosis,Early Diagnosis,Graph theory,Humans,Machine learning,Machine Learning,Magnetic Resonance Imaging,Mild cognitive impairment,Prognosis,Prospective Studies},
  file = {/home/paris/Zotero/storage/4383NV9E/Diogo et al. - 2022 - Early diagnosis of Alzheimer's disease using machine learning a multi-diagnostic, generalizable app.pdf}
}

@article{domingosFewUsefulThings2012,
  title = {A Few Useful Things to Know about Machine Learning},
  author = {Domingos, Pedro},
  year = 2012,
  month = oct,
  journal = {Communications of the ACM},
  volume = {55},
  number = {10},
  pages = {78--87},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/2347736.2347755},
  urldate = {2025-10-31},
  abstract = {Tapping into the "folk knowledge" needed to advance machine learning applications.},
  langid = {english},
  file = {/home/paris/Zotero/storage/E3KKWFD8/Domingos - 2012 - A few useful things to know about machine learning.pdf}
}

@article{duboisResearchCriteriaDiagnosis2007,
  title = {Research Criteria for the Diagnosis of {{Alzheimer}}'s Disease: Revising the {{NINCDS-ADRDA}} Criteria},
  shorttitle = {Research Criteria for the Diagnosis of {{Alzheimer}}'s Disease},
  author = {Dubois, Bruno and Feldman, Howard H. and Jacova, Claudia and Dekosky, Steven T. and {Barberger-Gateau}, Pascale and Cummings, Jeffrey and Delacourte, Andr{\'e} and Galasko, Douglas and Gauthier, Serge and Jicha, Gregory and Meguro, Kenichi and O'brien, John and Pasquier, Florence and Robert, Philippe and Rossor, Martin and Salloway, Steven and Stern, Yaakov and Visser, Pieter J. and Scheltens, Philip},
  year = 2007,
  month = aug,
  journal = {The Lancet. Neurology},
  volume = {6},
  number = {8},
  pages = {734--746},
  issn = {1474-4422},
  doi = {10.1016/S1474-4422(07)70178-3},
  abstract = {The NINCDS-ADRDA and the DSM-IV-TR criteria for Alzheimer's disease (AD) are the prevailing diagnostic standards in research; however, they have now fallen behind the unprecedented growth of scientific knowledge. Distinctive and reliable biomarkers of AD are now available through structural MRI, molecular neuroimaging with PET, and cerebrospinal fluid analyses. This progress provides the impetus for our proposal of revised diagnostic criteria for AD. Our framework was developed to capture both the earliest stages, before full-blown dementia, as well as the full spectrum of the illness. These new criteria are centred on a clinical core of early and significant episodic memory impairment. They stipulate that there must also be at least one or more abnormal biomarkers among structural neuroimaging with MRI, molecular neuroimaging with PET, and cerebrospinal fluid analysis of amyloid beta or tau proteins. The timeliness of these criteria is highlighted by the many drugs in development that are directed at changing pathogenesis, particularly at the production and clearance of amyloid beta as well as at the hyperphosphorylation state of tau. Validation studies in existing and prospective cohorts are needed to advance these criteria and optimise their sensitivity, specificity, and accuracy.},
  langid = {english},
  pmid = {17616482},
  keywords = {Alzheimer Disease,Amyloid beta-Peptides,Diagnostic and Statistical Manual of Mental Disorders,Diagnostic Imaging,Disease Progression,Humans,Memory Disorders,National Institutes of Health (U.S.),Severity of Illness Index,tau Proteins,Time Factors,United States}
}

@article{duboisResearchCriteriaDiagnosis2007a,
  title = {Research Criteria for the Diagnosis of {{Alzheimer}}'s Disease: Revising the {{NINCDS-ADRDA}} Criteria},
  shorttitle = {Research Criteria for the Diagnosis of {{Alzheimer}}'s Disease},
  author = {Dubois, Bruno and Feldman, Howard H. and Jacova, Claudia and Dekosky, Steven T. and {Barberger-Gateau}, Pascale and Cummings, Jeffrey and Delacourte, Andr{\'e} and Galasko, Douglas and Gauthier, Serge and Jicha, Gregory and Meguro, Kenichi and O'brien, John and Pasquier, Florence and Robert, Philippe and Rossor, Martin and Salloway, Steven and Stern, Yaakov and Visser, Pieter J. and Scheltens, Philip},
  year = 2007,
  month = aug,
  journal = {The Lancet. Neurology},
  volume = {6},
  number = {8},
  pages = {734--746},
  issn = {1474-4422},
  doi = {10.1016/S1474-4422(07)70178-3},
  abstract = {The NINCDS-ADRDA and the DSM-IV-TR criteria for Alzheimer's disease (AD) are the prevailing diagnostic standards in research; however, they have now fallen behind the unprecedented growth of scientific knowledge. Distinctive and reliable biomarkers of AD are now available through structural MRI, molecular neuroimaging with PET, and cerebrospinal fluid analyses. This progress provides the impetus for our proposal of revised diagnostic criteria for AD. Our framework was developed to capture both the earliest stages, before full-blown dementia, as well as the full spectrum of the illness. These new criteria are centred on a clinical core of early and significant episodic memory impairment. They stipulate that there must also be at least one or more abnormal biomarkers among structural neuroimaging with MRI, molecular neuroimaging with PET, and cerebrospinal fluid analysis of amyloid beta or tau proteins. The timeliness of these criteria is highlighted by the many drugs in development that are directed at changing pathogenesis, particularly at the production and clearance of amyloid beta as well as at the hyperphosphorylation state of tau. Validation studies in existing and prospective cohorts are needed to advance these criteria and optimise their sensitivity, specificity, and accuracy.},
  langid = {english},
  pmid = {17616482},
  keywords = {Alzheimer Disease,Amyloid beta-Peptides,Diagnostic and Statistical Manual of Mental Disorders,Diagnostic Imaging,Disease Progression,Humans,Memory Disorders,National Institutes of Health (U.S.),Severity of Illness Index,tau Proteins,Time Factors,United States}
}

@article{duongHypometabolicMismatchAtrophy2025,
  title = {Hypometabolic Mismatch with Atrophy and Tau Pathology in Mixed {{Alzheimer}}'s and {{Lewy}} Body Disease},
  author = {Duong, Michael Tran and Das, Sandhitsu R and Khandelwal, Pulkit and Lyu, Xueying and Xie, Long and McGrew, Emily and Dehghani, Nadia and McMillan, Corey T and Lee, Edward B and Shaw, Leslie M and Yushkevich, Paul A and Wolk, David A and Nasrallah, Ilya M and {Alzheimer's Disease Neuroimaging Initiative}},
  year = 2025,
  month = may,
  journal = {Brain},
  volume = {148},
  number = {5},
  pages = {1577--1587},
  issn = {0006-8950},
  doi = {10.1093/brain/awae352},
  urldate = {2025-07-25},
  abstract = {Polypathology is a major driver of heterogeneity in the clinical presentation and extent of neurodegeneration (N) in patients with Alzheimer's disease (AD). Beyond amyloid (A) and tau (T) pathologies, over half of patients with AD have concomitant pathology such as {$\alpha$}-synuclein (S) in mixed AD with Lewy body disease (LBD). Patients with multiple aetiology dementia such as AD + LBD have faster progression and potentially differential responses to targeted treatments, although the diagnosis of AD + LBD can be challenging given the overlapping clinical and imaging features. Development and validation of improved in vivo biomarkers are required to study relationships between N and S and identify imaging patterns reflecting mixed AD + LBD pathologies.We hypothesized that individual proteinopathies, such as T and S, are associated with commensurate levels of N. Thus, we assessed biomarkers of A, T, N and S with PET, MRI and CSF seeding amplification assay (SAA) data to determine molecular presentations of mixed A+S+ versus A+S-- cognitively impaired patients from the Alzheimer's Disease Neuroimaging Initiative (ADNI).Strikingly, A+S+ patients had parieto-occipital 18F-fluorodeoxyglucose hypometabolism (a measure of N) disproportionate to the degree of regional atrophy or T burden, highlighting worse hypometabolism associated with S+ status on SAA. Following up on this hypometabolic mismatch with CSF metabolite and proteome analyses, we found that A+S+ patients exhibited lower CSF levels of dopamine metabolites and synaptic markers like neuronal pentraxin-2 (NPTX2), suggesting that altered neurotransmission and neuron integrity contribute to this dissociation between metabolic PET and MRI. Potential confounders exist when studying relations between N, AD and LBD pathologies, including neuroinflammation and other non-Alzheimer's pathologies in mixed dementia, although our findings imply posterior hypometabolic mismatch is related more to S than vascular or TDP-43 pathology.Overall, A+S+ patients had posterior mismatch with excessive 18F-fluorodeoxyglucose hypometabolism relative to atrophy or T load, possibly reflecting impaired neuronal integrity. Further research must disentangle the impact of multiple proteinopathies and clinicopathologic factors on hypometabolism and atrophy. Cumulatively, patients with mixed AD + LBD aetiologies harbour a unique metabolic PET mismatch signature.},
  file = {/home/paris/Zotero/storage/8AL9ZR5C/awae352.html}
}

@article{ebrahimiConvolutionalNeuralNetworks2021,
  title = {Convolutional Neural Networks for {{Alzheimer}}'s Disease Detection on {{MRI}} Images},
  author = {Ebrahimi, Amir and Luo, Suhuai},
  year = 2021,
  month = mar,
  journal = {Journal of Medical Imaging},
  volume = {8},
  number = {2},
  pages = {024503},
  issn = {2329-4302},
  doi = {10.1117/1.JMI.8.2.024503},
  urldate = {2025-08-19},
  abstract = {Purpose: Detection of Alzheimer's disease (AD) on magnetic resonance imaging (MRI) using convolutional neural networks (CNNs), which is useful for detecting AD in its preliminary states., Approach: Our study implements and compares several deep models and configurations, including two-dimensional (2D) and three-dimensional (3D) CNNs and recurrent neural networks (RNNs). To use a 2D CNN on 3D MRI volumes, each MRI scan is split into 2D slices, neglecting the connection among 2D image slices in an MRI volume. Instead, a CNN model could be followed by an RNN in a way that the model of 2D CNN + RNN can understand the connection among sequences of 2D image slices for an MRI. The issue is that the feature extraction step in the 2D CNN is independent of classification in the RNN. To tackle this, 3D CNNs can be employed instead of 2D CNNs to make voxel-based decisions. Our study's main contribution is to introduce transfer learning from a dataset of 2D images to 3D CNNs., Results: The results on our MRI dataset indicate that sequence-based decisions improve the accuracy of slice-based decisions by 2\% in classifying AD patients from healthy subjects. Also the 3D voxel-based method with transfer learning outperforms the other methods with 96.88\% accuracy, 100\% sensitivity, and 94.12\% specificity., Conclusions: Several implementations and experiments using CNNs on MRI scans for AD detection demonstrated that the voxel-based method with transfer learning from ImageNet to MRI datasets using 3D CNNs considerably improved the results compared with the others.},
  pmcid = {PMC8083897},
  pmid = {33937437}
}

@article{ebrahimiConvolutionalNeuralNetworks2021a,
  title = {Convolutional Neural Networks for {{Alzheimer}}'s Disease Detection on {{MRI}} Images},
  author = {Ebrahimi, Amir and Luo, Suhuai},
  year = 2021,
  month = mar,
  journal = {Journal of Medical Imaging},
  volume = {8},
  number = {2},
  pages = {024503},
  issn = {2329-4302},
  doi = {10.1117/1.JMI.8.2.024503},
  urldate = {2025-08-16},
  abstract = {Purpose: Detection of Alzheimer's disease (AD) on magnetic resonance imaging (MRI) using convolutional neural networks (CNNs), which is useful for detecting AD in its preliminary states., Approach: Our study implements and compares several deep models and configurations, including two-dimensional (2D) and three-dimensional (3D) CNNs and recurrent neural networks (RNNs). To use a 2D CNN on 3D MRI volumes, each MRI scan is split into 2D slices, neglecting the connection among 2D image slices in an MRI volume. Instead, a CNN model could be followed by an RNN in a way that the model of 2D CNN + RNN can understand the connection among sequences of 2D image slices for an MRI. The issue is that the feature extraction step in the 2D CNN is independent of classification in the RNN. To tackle this, 3D CNNs can be employed instead of 2D CNNs to make voxel-based decisions. Our study's main contribution is to introduce transfer learning from a dataset of 2D images to 3D CNNs., Results: The results on our MRI dataset indicate that sequence-based decisions improve the accuracy of slice-based decisions by 2\% in classifying AD patients from healthy subjects. Also the 3D voxel-based method with transfer learning outperforms the other methods with 96.88\% accuracy, 100\% sensitivity, and 94.12\% specificity., Conclusions: Several implementations and experiments using CNNs on MRI scans for AD detection demonstrated that the voxel-based method with transfer learning from ImageNet to MRI datasets using 3D CNNs considerably improved the results compared with the others.},
  pmcid = {PMC8083897},
  pmid = {33937437}
}

@article{ebrahimiConvolutionalNeuralNetworks2021b,
  title = {Convolutional Neural Networks for {{Alzheimer}}'s Disease Detection on {{MRI}} Images},
  author = {Ebrahimi, Amir and Luo, Suhuai},
  year = 2021,
  month = mar,
  journal = {Journal of Medical Imaging},
  volume = {8},
  number = {2},
  pages = {024503},
  issn = {2329-4302},
  doi = {10.1117/1.JMI.8.2.024503},
  urldate = {2025-08-16},
  abstract = {Purpose: Detection of Alzheimer's disease (AD) on magnetic resonance imaging (MRI) using convolutional neural networks (CNNs), which is useful for detecting AD in its preliminary states., Approach: Our study implements and compares several deep models and configurations, including two-dimensional (2D) and three-dimensional (3D) CNNs and recurrent neural networks (RNNs). To use a 2D CNN on 3D MRI volumes, each MRI scan is split into 2D slices, neglecting the connection among 2D image slices in an MRI volume. Instead, a CNN model could be followed by an RNN in a way that the model of 2D CNN + RNN can understand the connection among sequences of 2D image slices for an MRI. The issue is that the feature extraction step in the 2D CNN is independent of classification in the RNN. To tackle this, 3D CNNs can be employed instead of 2D CNNs to make voxel-based decisions. Our study's main contribution is to introduce transfer learning from a dataset of 2D images to 3D CNNs., Results: The results on our MRI dataset indicate that sequence-based decisions improve the accuracy of slice-based decisions by 2\% in classifying AD patients from healthy subjects. Also the 3D voxel-based method with transfer learning outperforms the other methods with 96.88\% accuracy, 100\% sensitivity, and 94.12\% specificity., Conclusions: Several implementations and experiments using CNNs on MRI scans for AD detection demonstrated that the voxel-based method with transfer learning from ImageNet to MRI datasets using 3D CNNs considerably improved the results compared with the others.},
  pmcid = {PMC8083897},
  pmid = {33937437}
}

@article{eladImageDenoisingDeep2023,
  title = {Image {{Denoising}}: {{The Deep Learning Revolution}} and {{Beyond}}---{{A Survey Paper}}},
  shorttitle = {Image {{Denoising}}},
  author = {Elad, Michael and Kawar, Bahjat and Vaksman, Gregory},
  year = 2023,
  month = sep,
  journal = {SIAM Journal on Imaging Sciences},
  volume = {16},
  number = {3},
  pages = {1594--1654},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/23M1545859},
  urldate = {2025-05-25},
  abstract = {.Deep learning has proved to be a powerful tool for solving inverse problems in imaging, and most of the related work is based on supervised learning. In many applications, collecting truth images is a challenging and costly task, and the prerequisite of having a training dataset of truth images limits its applicability. This paper proposes a self-supervised deep learning method for solving inverse imaging problems that does not require any training samples. The proposed approach is built on a reparametrization of latent images using a convolutional neural network, and the reconstruction is motivated by approximating the minimum mean square error estimate of the latent image using a Langevin dynamics--based Monte Carlo (MC) method. To efficiently sample the network weights in the context of image reconstruction, we propose a Langevin MC scheme called Adam-LD, inspired by the well-known optimizer in deep learning, Adam. The proposed method is applied to solve linear and nonlinear inverse problems, specifically, sparse-view computed tomography image reconstruction and phase retrieval. Our experiments demonstrate that the proposed method outperforms existing unsupervised or self-supervised solutions in terms of reconstruction quality.},
  file = {/home/paris/gdrive/Zotero/Denosing/Elad et al. - 2023 - Image Denoising The Deep Learning Revolution and Beyond—A Survey Paper.pdf}
}

@article{englerTwoyearFollowupAmyloid2006,
  title = {Two-Year Follow-up of Amyloid Deposition in Patients with {{Alzheimer}}'s Disease},
  author = {Engler, Henry and Forsberg, Anton and Almkvist, Ove and Blomquist, Gunnar and Larsson, Emma and Savitcheva, Irina and Wall, Anders and Ringheim, Anna and L{\aa}ngstr{\"o}m, Bengt and Nordberg, Agneta},
  year = 2006,
  month = nov,
  journal = {Brain},
  volume = {129},
  number = {11},
  pages = {2856--2866},
  issn = {0006-8950},
  doi = {10.1093/brain/awl178},
  urldate = {2025-03-30},
  abstract = {Beta amyloid is one of the major histopathological hallmarks of Alzheimer's disease. We recently reported in vivo imaging of amyloid in 16 Alzheimer patients, using the PET ligand N-methyl[11C]2-(4{$\prime$}-methylaminophenyl)-6-hydroxy-benzothiazole (PIB). In the present study we rescanned these 16 Alzheimer patients after 2.0 \textpm{} 0.5 years and have described the interval change in amyloid deposition and regional cerebral metabolic rate for glucose (rCMRGlc) at follow-up. Sixteen patients with Alzheimer's disease were re-examined by means of PET, using PIB and 2-[18F]fluoro-2-deoxy-d-glucose (FDG) after 2.0 \textpm{} 0.5 years. The patients were all on cholinesterase inhibitor treatment and five also on treatment with the N-methyl-d-aspartate (NMDA) antagonist memantine. In order to estimate the accuracy of the PET PIB measurements, four additional Alzheimer patients underwent repeated examinations with PIB within 20 days (test--retest). Relative PIB retention in cortical regions differed by 3--7\% in the test--retest study. No significant difference in PIB retention was observed between baseline and follow-up while a significant (P \&lt; 0.01) 20\% decrease in rCMRGlc was observed in cortical brain regions. A significant negative correlation between rCMRGlc and PIB retention was observed in the parietal cortex in the Alzheimer patients at follow-up (r = 0.67, P = 0.009). A non-significant decline in Mini-Mental State Examination (MMSE) score from 24.3 \textpm{} 3.7 (mean \textpm{} standard deviation) to 22.7 \textpm{} 6.1 was measured at follow-up. Five of the Alzheimer patients showed a significant decline in MMSE score of \&gt;3 (21.4 \textpm{} 3.5 to 15.6 \textpm{} 3.9, P \&lt; 0.01) (AD-progressive) while the rest of the patients were cognitively more stable (MMSE score = 25.6 \textpm{} 3.1 to 25.9 \textpm{} 3.7) (AD-stable) compared with baseline. A positive correlation (P = 0.001) was observed in the parietal cortex between Rey Auditory Verbal Learning (RAVL) test score and rCMRGlc at follow-up while a negative correlation (P = 0.018) was observed between RAVL test and PIB retention in the parietal at follow-up. Relatively stable PIB retention after 2 years of follow-up in patients with mild Alzheimer's disease suggests that amyloid deposition in the brain reaches a plateau by the early clinical stages of Alzheimer's disease and therefore may precede a decline in rCMRGlc and cognition. It appears that anti-amyloid therapies will need to induce a significant decrease in amyloid load in order for PIB PET images to detect a drug effect in Alzheimer patients. FDG imaging may be able to detect a stabilization of cerebral metabolism caused by therapy administered to patients with a clinical diagnosis of Alzheimer's disease.},
  file = {/home/paris/Zotero/storage/37ZRX9QE/289548.html}
}

@misc{EngramStabilityMaturation,
  title = {Engram Stability and Maturation during Systems Consolidation - {{PMC}}},
  urldate = {2025-09-10},
  howpublished = {https://pmc.ncbi.nlm.nih.gov/articles/PMC10524918/},
  file = {/home/paris/Zotero/storage/SLAPQ4VA/PMC10524918.html}
}

@article{eskildsenBEaSTBrainExtraction2012,
  title = {{{BEaST}}: Brain Extraction Based on Nonlocal Segmentation Technique},
  shorttitle = {{{BEaST}}},
  author = {Eskildsen, Simon F. and Coup{\'e}, Pierrick and Fonov, Vladimir and Manj{\'o}n, Jos{\'e} V. and Leung, Kelvin K. and Guizard, Nicolas and Wassef, Shafik N. and {\O}stergaard, Lasse Riis and Collins, D. Louis and {Alzheimer's Disease Neuroimaging Initiative}},
  year = 2012,
  month = feb,
  journal = {NeuroImage},
  volume = {59},
  number = {3},
  pages = {2362--2373},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2011.09.012},
  abstract = {Brain extraction is an important step in the analysis of brain images. The variability in brain morphology and the difference in intensity characteristics due to imaging sequences make the development of a general purpose brain extraction algorithm challenging. To address this issue, we propose a new robust method (BEaST) dedicated to produce consistent and accurate brain extraction. This method is based on nonlocal segmentation embedded in a multi-resolution framework. A library of 80 priors is semi-automatically constructed from the NIH-sponsored MRI study of normal brain development, the International Consortium for Brain Mapping, and the Alzheimer's Disease Neuroimaging Initiative databases. In testing, a mean Dice similarity coefficient of 0.9834\textpm 0.0053 was obtained when performing leave-one-out cross validation selecting only 20 priors from the library. Validation using the online Segmentation Validation Engine resulted in a top ranking position with a mean Dice coefficient of 0.9781\textpm 0.0047. Robustness of BEaST is demonstrated on all baseline ADNI data, resulting in a very low failure rate. The segmentation accuracy of the method is better than two widely used publicly available methods and recent state-of-the-art hybrid approaches. BEaST provides results comparable to a recent label fusion approach, while being 40 times faster and requiring a much smaller library of priors.},
  langid = {english},
  pmid = {21945694},
  keywords = {Adolescent,Adult,Algorithms,Brain,Brain Mapping,Computers,Databases Factual,False Negative Reactions,False Positive Reactions,Female,Humans,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Male,Quality Control,Reference Standards,Reproducibility of Results,Software,Young Adult},
  file = {/home/paris/Zotero/storage/NZGL2GH5/Eskildsen et al. - 2012 - BEaST brain extraction based on nonlocal segmentation technique.pdf}
}

@book{everittCambridgeDictionaryStatistics2010,
  title = {The {{Cambridge}} Dictionary of Statistics},
  author = {Everitt, Brian S. and Skrondal, Anders},
  year = 2010,
  volume = {4},
  publisher = {Cambridge university press Cambridge, UK},
  urldate = {2025-11-04}
}

@misc{Explain2025,
  title = {Explain},
  year = 2025,
  month = jun,
  journal = {Wiktionary, the free dictionary},
  urldate = {2025-08-30},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 85410733},
  file = {/home/paris/Zotero/storage/CWTJVHCC/index.html}
}

@misc{ExplainableAIDemos,
  title = {Explainable {{AI Demos}}},
  urldate = {2025-09-02},
  howpublished = {https://lrpserver.hhi.fraunhofer.de/image-classification},
  file = {/home/paris/Zotero/storage/MS7VPUKR/image-classification.html}
}

@article{fanBriefReviewImage2019,
  title = {Brief Review of Image Denoising Techniques},
  author = {Fan, Linwei and Zhang, Fan and Fan, Hui and Zhang, Caiming},
  year = 2019,
  month = jul,
  journal = {Visual Computing for Industry, Biomedicine, and Art},
  volume = {2},
  number = {1},
  pages = {7},
  issn = {2524-4442},
  doi = {10.1186/s42492-019-0016-7},
  urldate = {2025-05-25},
  abstract = {With the explosion in the number of digital images taken every day, the demand for more accurate and visually pleasing images is increasing. However, the images captured by modern cameras are inevitably degraded by noise, which leads to deteriorated visual image quality. Therefore, work is required to reduce noise without losing image features (edges, corners, and other sharp structures). So far, researchers have already proposed various methods for decreasing noise. Each method has its own advantages and disadvantages. In this paper, we summarize some important research in the field of image denoising. First, we give the formulation of the image denoising problem, and then we present several image denoising techniques. In addition, we discuss the characteristics of these techniques. Finally, we provide several promising directions for future research.},
  langid = {english},
  keywords = {3-D Image Reconstruction,Computational  Methods for Stochastic Equations,Convolutional neural network,Image denoising,Image Processing,Imaging Techniques,Low-rank,Non-local means,Signal Processing,Signal Speech and Image Processing,Sparse representation},
  file = {/home/paris/gdrive/Zotero/Denosing/Fan et al. - 2019 - Brief review of image denoising techniques.pdf}
}

@article{fangLifetimeRiskProjected2025,
  title = {Lifetime Risk and Projected Burden of Dementia},
  author = {Fang, Michael and Hu, Jiaqi and Weiss, Jordan and Knopman, David S. and Albert, Marilyn and Windham, B. Gwen and Walker, Keenan A. and Sharrett, A. Richey and Gottesman, Rebecca F. and Lutsey, Pamela L. and Mosley, Thomas and Selvin, Elizabeth and Coresh, Josef},
  year = 2025,
  month = mar,
  journal = {Nature Medicine},
  volume = {31},
  number = {3},
  pages = {772--776},
  issn = {1546-170X},
  doi = {10.1038/s41591-024-03340-9},
  abstract = {Understanding the lifetime risk of dementia can inform public health planning and improve patient engagement in prevention. Using data from a community-based, prospective cohort study (n\,=\,15,043; 26.9\% Black race, 55.1\% women and 30.8\% with at least one apolipoprotein E4 (APOE {$\varepsilon$}4) allele), we estimated the lifetime risk of dementia (from age 55\,years to 95\,years), with mortality treated as a competing event. We applied lifetime risk estimates to US Census projections to evaluate the annual number of incident dementia cases from 2020 to 2060. The lifetime risk of dementia after age 55\,years was 42\% (95\% confidence interval: 41-43). Rates were substantially higher in women, Black adults and APOE {$\varepsilon$}4 carriers, with lifetime risks ranging from approximately 45\% to 60\% in these populations. The number of US adults who will develop dementia each year was projected to increase from approximately 514,000 in 2020 to approximately 1 million in 2060. The relative growth in new dementia cases was especially pronounced for Black adults. These results highlight the urgent need for policies that enhance healthy aging, with a focus on health equity.},
  langid = {english},
  pmcid = {PMC12305800},
  pmid = {39806070},
  keywords = {Aged,Aged 80 and over,Apolipoprotein E4,Black or African American,Cost of Illness,Dementia,Female,Humans,Incidence,Male,Middle Aged,Prospective Studies,Risk Factors,United States,White}
}

@inproceedings{farahaniBriefReviewDomain2021,
  title = {A {{Brief Review}} of {{Domain Adaptation}}},
  booktitle = {Advances in {{Data Science}} and {{Information Engineering}}},
  author = {Farahani, Abolfazl and Voghoei, Sahar and Rasheed, Khaled and Arabnia, Hamid R.},
  editor = {Stahlbock, Robert and Weiss, Gary M. and {Abou-Nasr}, Mahmoud and Yang, Cheng-Ying and Arabnia, Hamid R. and Deligiannidis, Leonidas},
  year = 2021,
  pages = {877--894},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-71704-9_65},
  abstract = {Classical machine learning assumes that the training and test sets come from the same distributions. Therefore, a model learned from the labeled training data is expected to perform well on the test data. However, this assumption may not always hold in real-world applications where the training and the test data fall from different distributions, due to many factors, e.g., collecting the training and test sets from different sources or having an outdated training set due to the change of data over time. In this case, there would be a discrepancy across domain distributions, and naively applying the trained model on the new dataset may cause degradation in the performance. Domain adaptation is a subfield within machine learning that aims to cope with these types of problems by aligning the disparity between domains such that the trained model can be generalized into the domain of interest. This paper focuses on unsupervised domain adaptation, where the labels are only available in the source domain. It addresses the categorization of domain adaptation from different viewpoints. Besides, it presents some successful shallow and deep domain adaptation approaches that aim to deal with domain adaptation problems.},
  isbn = {978-3-030-71704-9},
  langid = {english},
  annotation = {GSCC: 0000817 2025-06-15T15:38:42.119Z 3.51}
}

@article{fatimaStateoftheArtTraditionalMachine2020,
  title = {State-of-the-{{Art Traditional}} to the {{Machine-}} and {{Deep-Learning-Based Skull Stripping Techniques}}, {{Models}}, and {{Algorithms}}},
  author = {Fatima, Anam and Shahid, Ahmad Raza and Raza, Basit and Madni, Tahir Mustafa and Janjua, Uzair Iqbal},
  year = 2020,
  month = dec,
  journal = {Journal of Digital Imaging},
  volume = {33},
  number = {6},
  pages = {1443--1464},
  issn = {1618-727X},
  doi = {10.1007/s10278-020-00367-5},
  urldate = {2026-01-16},
  abstract = {Several neuroimaging processing applications consider skull stripping as a crucial pre-processing step. Due to complex anatomical brain structure and intensity variations in brain magnetic resonance imaging (MRI), an appropriate skull stripping is an important part.~The process of skull stripping basically deals with the removal of the skull region for clinical analysis in brain segmentation tasks, and its accuracy and efficiency are quite crucial for diagnostic purposes. It requires more accurate and detailed methods for differentiating brain regions and the skull regions and is considered as a challenging task. This paper is focused on the transition of the conventional to the machine- and deep-learning-based automated skull stripping methods for brain MRI images. It is observed in this study that deep learning approaches have outperformed conventional and machine learning techniques in many ways, but they have their limitations. It also includes the comparative analysis of the current state-of-the-art skull stripping methods, a critical discussion of some challenges, model of quantifying parameters, and future work directions.},
  langid = {english},
  keywords = {Brain extraction,Conventional skull stripping methods,Deep learning skull stripping methods,Machine learning skull stripping methods,MRI,Skull stripping}
}

@article{fawcettIntroductionROCAnalysis2006,
  title = {An Introduction to {{ROC}} Analysis},
  author = {Fawcett, Tom},
  year = 2006,
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {27},
  number = {8},
  pages = {861--874},
  issn = {01678655},
  doi = {10.1016/j.patrec.2005.10.010},
  urldate = {2025-08-28},
  abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Fawcett - 2006 - An introduction to ROC analysis.pdf}
}

@article{ferreiraNeuroimagingAlzheimersDisease2011,
  title = {Neuroimaging in {{Alzheimer}}'s Disease: Current Role in Clinical Practice and Potential Future Applications},
  shorttitle = {Neuroimaging in {{Alzheimer}}'s Disease},
  author = {Ferreira, Luiz Kobuti and Busatto, Geraldo F},
  year = 2011,
  month = jan,
  journal = {Clinics},
  volume = {66},
  pages = {19--24},
  issn = {1807-5932},
  doi = {10.1590/S1807-59322011001300003},
  urldate = {2024-11-09},
  abstract = {Alzheimer's disease is the most common cause of dementia and its prevalence is expected to increase in the coming years. Therefore, accurate diagnosis is crucial for patients, clinicians and researchers. Neuroimaging techniques have provided invaluable information about Alzheimer's disease and, owing to recent advances, these methods will have an increasingly important role in research and clinical practice. The purpose of this article is to review recent neuroimaging studies of Alzheimer's disease that provide relevant information to clinical practice, including a new modality: in vivo amyloid imaging. Magnetic resonance imaging, single photon emission computed tomography and 18F-fluorodeoxyglucose-positron emission tomography are currently available for clinical use. Patients with suspected Alzheimer's disease are commonly investigated with magnetic resonance imaging because it provides detailed images of brain structure and allows the identification of supportive features for the diagnosis. Neurofunctional techniques such as single photon emission computed tomography and 18F-fluorodeoxyglucose-positron emission tomography can also be used to complement the diagnostic investigation in cases of uncertainty. Amyloid imaging is a non-invasive technique that uses positron emission tomography technology to investigate the accumulation of the {$\beta$}-amyloid peptide in the brain, which is a hallmark of Alzheimer's disease. This is a promising test but currently its use is restricted to very few specialized research centers in the world. Technological innovations will probably increase its availability and reliability, which are the necessary steps to achieve robust clinical applicability. Thus, in the future it is likely that amyloid imaging techniques will be used in the clinical evaluation of patients with Alzheimer's disease.},
  keywords = {Alzheimer's disease,Amyloid imaging,Classification,Diagnosis,Neuroimaging},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Ferreira and Busatto - 2011 - Neuroimaging in Alzheimer's disease current role in clinical practice and potential future applicat.pdf;/home/paris/Zotero/storage/7LUPULXD/S1807593222015800.html}
}

@article{ferreiraNeuroimagingAlzheimersDisease2011a,
  title = {Neuroimaging in {{Alzheimer}}'s Disease: Current Role in Clinical Practice and Potential Future Applications},
  shorttitle = {Neuroimaging in {{Alzheimer}}'s Disease},
  author = {Ferreira, Luiz Kobuti and Busatto, Geraldo F},
  year = 2011,
  month = jan,
  journal = {Clinics},
  volume = {66},
  pages = {19--24},
  issn = {1807-5932},
  doi = {10.1590/S1807-59322011001300003},
  urldate = {2025-10-17},
  abstract = {Alzheimer's disease is the most common cause of dementia and its prevalence is expected to increase in the coming years. Therefore, accurate diagnosis is crucial for patients, clinicians and researchers. Neuroimaging techniques have provided invaluable information about Alzheimer's disease and, owing to recent advances, these methods will have an increasingly important role in research and clinical practice. The purpose of this article is to review recent neuroimaging studies of Alzheimer's disease that provide relevant information to clinical practice, including a new modality: in vivo amyloid imaging. Magnetic resonance imaging, single photon emission computed tomography and 18F-fluorodeoxyglucose-positron emission tomography are currently available for clinical use. Patients with suspected Alzheimer's disease are commonly investigated with magnetic resonance imaging because it provides detailed images of brain structure and allows the identification of supportive features for the diagnosis. Neurofunctional techniques such as single photon emission computed tomography and 18F-fluorodeoxyglucose-positron emission tomography can also be used to complement the diagnostic investigation in cases of uncertainty. Amyloid imaging is a non-invasive technique that uses positron emission tomography technology to investigate the accumulation of the {$\beta$}-amyloid peptide in the brain, which is a hallmark of Alzheimer's disease. This is a promising test but currently its use is restricted to very few specialized research centers in the world. Technological innovations will probably increase its availability and reliability, which are the necessary steps to achieve robust clinical applicability. Thus, in the future it is likely that amyloid imaging techniques will be used in the clinical evaluation of patients with Alzheimer's disease.},
  keywords = {Alzheimer's disease,Amyloid imaging,Classification,Diagnosis,Neuroimaging},
  file = {/home/paris/Zotero/storage/4XRXRRMV/Ferreira and Busatto - 2011 - Neuroimaging in Alzheimer's disease current role in clinical practice and potential future applicat.pdf;/home/paris/Zotero/storage/MS7AYZEJ/S1807593222015800.html}
}

@article{ferreiraNeurostructuralPredictorsAlzheimers2011,
  title = {Neurostructural Predictors of {{Alzheimer}}'s Disease: A Meta-Analysis of {{VBM}} Studies},
  shorttitle = {Neurostructural Predictors of {{Alzheimer}}'s Disease},
  author = {Ferreira, Luiz K. and Diniz, Breno S. and Forlenza, Orestes V. and Busatto, Geraldo F. and Zanetti, Marcus V.},
  year = 2011,
  month = oct,
  journal = {Neurobiology of Aging},
  volume = {32},
  number = {10},
  pages = {1733--1741},
  issn = {1558-1497},
  doi = {10.1016/j.neurobiolaging.2009.11.008},
  abstract = {The identification of biological markers at early stages of Alzheimer's disease (AD) contributes to diagnostic accuracy and adds prognostic value. However, in spite of recent developments, results of neurostructural imaging studies on predicting conversion to AD are not uniform. We conducted a systematic review of voxel-based morphometry (VBM) studies about the neurostructural predictors of conversion to AD. Ten studies met inclusion criteria and nine reported baseline regional gray matter (GM) atrophy in mild cognitive impairment (MCI) or healthy subjects who progressed to AD. Using the method of Activation Likelihood Estimation, we meta-analyzed the coordinates from the six longitudinal VBM studies that enrolled subjects with amnestic MCI (aMCI) at baseline. These comprised a total of 429 aMCI subjects, of which 142 converted to AD. Meta-analysis yielded one significant cluster of GM volumetric reduction in aMCI patients who converted to AD, located in the left hippocampus and parahippocampal gyrus. In conclusion, left medial temporal lobe atrophy is the most consistent neurostructural biomarker to predict conversion from aMCI to AD.},
  langid = {english},
  pmid = {20005012},
  keywords = {Alzheimer Disease,Brain,Cognition Disorders,Humans,Neuroimaging,Predictive Value of Tests},
  file = {/home/paris/gdrive/Zotero/Ferreira et al. - 2011 - Neurostructural predictors of Alzheimer's disease a meta-analysis of VBM studies.pdf}
}

@misc{fischDeepbetFastBrain2023,
  title = {Deepbet: {{Fast}} Brain Extraction of {{T1-weighted MRI}} Using {{Convolutional Neural Networks}}},
  shorttitle = {Deepbet},
  author = {Fisch, Lukas and Zumdick, Stefan and Barkhau, Carlotta and Emden, Daniel and Ernsting, Jan and Leenings, Ramona and Sarink, Kelvin and Winter, Nils R. and Risse, Benjamin and Dannlowski, Udo and Hahn, Tim},
  year = 2023,
  month = aug,
  number = {arXiv:2308.07003},
  eprint = {2308.07003},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.07003},
  urldate = {2026-01-16},
  abstract = {Brain extraction in magnetic resonance imaging (MRI) data is an important segmentation step in many neuroimaging preprocessing pipelines. Image segmentation is one of the research fields in which deep learning had the biggest impact in recent years enabling high precision segmentation with minimal compute. Consequently, traditional brain extraction methods are now being replaced by deep learning-based methods. Here, we used a unique dataset comprising 568 T1-weighted (T1w) MR images from 191 different studies in combination with cutting edge deep learning methods to build a fast, high-precision brain extraction tool called deepbet. deepbet uses LinkNet, a modern UNet architecture, in a two stage prediction process. This increases its segmentation performance, setting a novel state-of-the-art performance during cross-validation with a median Dice score (DSC) of 99.0\% on unseen datasets, outperforming current state of the art models (DSC = 97.8\% and DSC = 97.9\%). While current methods are more sensitive to outliers, resulting in Dice scores as low as 76.5\%, deepbet manages to achieve a Dice score of {$>$} 96.9\% for all samples. Finally, our model accelerates brain extraction by a factor of \textasciitilde 10 compared to current methods, enabling the processing of one image in \textasciitilde 2 seconds on low level hardware.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/Zotero/storage/E7CJYZHV/Fisch et al. - 2023 - Deepbet Fast brain extraction of T1-weighted MRI using Convolutional Neural Networks.pdf;/home/paris/Zotero/storage/3LKUEWY6/2308.html}
}

@misc{fischDeepmriprepVoxelbasedMorphometry2024,
  title = {Deepmriprep: {{Voxel-based Morphometry}} ({{VBM}}) {{Preprocessing}} via {{Deep Neural Networks}}},
  shorttitle = {Deepmriprep},
  author = {Fisch, Lukas and Winter, Nils R. and Goltermann, Janik and Barkhau, Carlotta and Emden, Daniel and Ernsting, Jan and Konowski, Maximilian and Leenings, Ramona and Borgers, Tiana and Flinkenfl{\"u}gel, Kira and Grotegerd, Dominik and Kraus, Anna and Leehr, Elisabeth J. and Meinert, Susanne and Stein, Frederike and Teutenberg, Lea and {Thomas-Odenthal}, Florian and Usemann, Paula and Hermesdorf, Marco and Jamalabadi, Hamidreza and Jansen, Andreas and Nenadic, Igor and Straube, Benjamin and Kircher, Tilo and Berger, Klaus and Risse, Benjamin and Dannlowski, Udo and Hahn, Tim},
  year = 2024,
  month = oct,
  number = {arXiv:2408.10656},
  eprint = {2408.10656},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.10656},
  urldate = {2025-07-23},
  abstract = {Voxel-based Morphometry (VBM) has emerged as a powerful approach in neuroimaging research, utilized in over 7,000 studies since the year 2000. Using Magnetic Resonance Imaging (MRI) data, VBM assesses variations in the local density of brain tissue and examines its associations with biological and psychometric variables. Here, we present deepmriprep, a neural network-based pipeline that performs all necessary preprocessing steps for VBM analysis of T1-weighted MR images using deep neural networks. Utilizing the Graphics Processing Unit (GPU), deepmriprep is 37 times faster than CAT12, the leading VBM preprocessing toolbox. The proposed method matches CAT12 in accuracy for tissue segmentation and image registration across more than 100 datasets and shows strong correlations in VBM results. Tissue segmentation maps from deepmriprep have over 95\% agreement with ground truth maps, and its non-linear registration, using supervised SYMNet, predicts smooth deformation fields comparable to CAT12. The high processing speed of deepmriprep enables rapid preprocessing of extensive datasets and thereby fosters the application of VBM analysis to large-scale neuroimaging studies and opens the door to real-time applications. Finally, deepmripreps straightforward, modular design enables researchers to easily understand, reuse, and advance the underlying methods, fostering further advancements in neuroimaging research. deepmriprep can be conveniently installed as a Python package and is publicly accessible at https://github.com/wwu-mmll/deepmriprep.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/gdrive/Zotero/Fisch et al. - 2024 - deepmriprep Voxel-based Morphometry (VBM) Preprocessing via Deep Neural Networks.pdf;/home/paris/Zotero/storage/WJR9HPJW/2408.html}
}

@article{fitzgeraldErrorRadiology2001,
  title = {Error in {{Radiology}}},
  author = {Fitzgerald, Richard},
  year = 2001,
  month = dec,
  journal = {Clinical Radiology},
  volume = {56},
  number = {12},
  pages = {938--946},
  issn = {0009-9260},
  doi = {10.1053/crad.2001.0858},
  urldate = {2025-06-16},
  abstract = {Literature review indicates high levels of error within radiology. The aetiology of radiological error is multi-factorial. While individuals have a duty to progressively improve their performance, the experience of safety cultures in other high-risk human activities has shown that a system approach of root cause analysis is the method required to reduce error significantly. FitzGerald, R. (2001). Clinical Radiology56, 938--946.},
  keywords = {error,radiology},
  file = {/home/paris/Zotero/storage/5YJLDMFM/Fitzgerald - 2001 - Error in Radiology.pdf;/home/paris/Zotero/storage/EFFAWP3S/S000992600190858X.html}
}

@article{freeboroughMRImageTexture1998,
  title = {{{MR}} Image Texture Analysis Applied to the Diagnosis and Tracking of {{Alzheimer}}'s Disease},
  author = {Freeborough, P.A. and Fox, N.C.},
  year = 1998,
  month = jun,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {17},
  number = {3},
  pages = {475--478},
  issn = {1558-254X},
  doi = {10.1109/42.712137},
  urldate = {2025-06-16},
  abstract = {The authors assess the value of magnetic resonance (MR) image texture in Alzheimer's disease (AD) both as a diagnostic marker and as a measure of progression. T/sub 1/-weighted MR scans were acquired from 40 normal controls and 24 AD patients. These were split into a training set (20 controls, 40 AD) and a test set (20 controls, 14 AD). In addition, five control subjects and five AD patients were scanned repeatedly over several years. On each scan a texture feature vector was evaluated over the brain; this consisted of 260 measures derived from the spatial gray-level dependence method. A stepwise discriminant analysis was applied to the training set, to obtain a linear discriminant function. In the test set, this function yielded significantly different values for the control and AD groups (p{$<$}10/sup -4/) with only small group overlap; a classification rate of 91\% was obtained. For the repeatedly scanned control subjects, the median increment in the discriminant function between successive scans of 0.12 was not significantly different from zero (p{$>$}0.05); for the repeatedly scanned AD patients the corresponding median increment of 1.4 was significantly different from zero (p{$<$}0.05). MR image texture may be a useful aid in the diagnosis and tracking of Alzheimer's disease.},
  keywords = {Alzheimer's disease,Brain,Drugs,Image texture,Image texture analysis,Magnetic resonance,Magnetic resonance imaging,Medical treatment,Neoplasms,Testing}
}

@misc{FreeSurfer,
  title = {{{FreeSurfer}}},
  journal = {FreeSurfer},
  urldate = {2026-01-16},
  abstract = {Software Package for Brain MRI Analysis},
  howpublished = {https://surfer.nmr.mgh.harvard.edu},
  langid = {english}
}

@incollection{freieslebenDearXAICommunity2023,
  title = {Dear {{XAI Community}}, {{We Need}} to {{Talk}}!: {{Fundamental Misconceptions}} in {{Current XAI Research}}},
  shorttitle = {Dear {{XAI Community}}, {{We Need}} to {{Talk}}!},
  booktitle = {Explainable {{Artificial Intelligence}}},
  author = {Freiesleben, Timo and K{\"o}nig, Gunnar},
  editor = {Longo, Luca},
  year = 2023,
  volume = {1901},
  pages = {48--65},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-44064-9_3},
  urldate = {2025-09-08},
  isbn = {978-3-031-44063-2 978-3-031-44064-9},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Freiesleben and König - 2023 - Dear XAI Community, We Need to Talk! Fundamental Misconceptions in Current XAI Research.pdf}
}

@article{frisoniClinicalUseStructural2010,
  title = {The Clinical Use of Structural {{MRI}} in {{Alzheimer}} Disease},
  author = {Frisoni, Giovanni B. and Fox, Nick C. and Jack Jr, Clifford R. and Scheltens, Philip and Thompson, Paul M.},
  year = 2010,
  journal = {Nature reviews neurology},
  volume = {6},
  number = {2},
  pages = {67--77},
  publisher = {Nature Publishing Group UK London},
  urldate = {2025-03-15},
  file = {/home/paris/Zotero/storage/FDU8DZYM/Frisoni et al. - 2010 - The clinical use of structural MRI in Alzheimer disease.pdf}
}

@article{fuDeepLearningMedical2020,
  title = {Deep Learning in Medical Image Registration: A Review},
  shorttitle = {Deep Learning in Medical Image Registration},
  author = {Fu, Yabo and Lei, Yang and Wang, Tonghe and Curran, Walter J and Liu, Tian and Yang, Xiaofeng},
  year = 2020,
  month = oct,
  journal = {Physics in Medicine \& Biology},
  volume = {65},
  number = {20},
  pages = {20TR01},
  publisher = {IOP Publishing},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ab843e},
  urldate = {2025-07-10},
  abstract = {This paper presents a review of deep learning (DL)-based medical image registration methods. We summarized the latest developments and applications of DL-based registration methods in the medical field. These methods were classified into seven categories according to their methods, functions and popularity. A detailed review of each category was presented, highlighting important contributions and identifying specific challenges. A short assessment was presented following the detailed review of each category to summarize its achievements and future potential. We provided a comprehensive comparison among DL-based methods for lung and brain registration using benchmark datasets. Lastly, we analyzed the statistics of all the cited works from various aspects, revealing the popularity and future trend of DL-based medical image registration.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Fu et al. - 2020 - Deep learning in medical image registration a review.pdf}
}

@misc{FullArticleVoxelbased,
  title = {Full Article: {{Voxel-based}} Morphometry: Current Perspectives},
  urldate = {2025-07-23},
  howpublished = {https://www.tandfonline.com/doi/full/10.2147/NAN.S66439},
  file = {/home/paris/Zotero/storage/P2FQFGKR/NAN.html}
}

@misc{FunctionalBrainConnectivity,
  title = {Functional {{Brain Connectivity Using fMRI}} in {{Aging}} and {{Alzheimer}}'s {{Disease}} \textbar{} {{Neuropsychology Review}}},
  urldate = {2025-04-15},
  howpublished = {https://link.springer.com/article/10.1007/s11065-014-9249-6}
}

@misc{gaoComprehensiveSurveyImbalanced2025,
  title = {A {{Comprehensive Survey}} on {{Imbalanced Data Learning}}},
  author = {Gao, Xinyi and Xie, Dongting and Zhang, Yihang and Wang, Zhengren and Chen, Chong and He, Conghui and Yin, Hongzhi and Zhang, Wentao},
  year = 2025,
  month = sep,
  eprint = {2502.08960},
  primaryclass = {cs},
  doi = {10.1007/s11704-025-50274-7},
  urldate = {2025-09-27},
  abstract = {With the expansion of data availability, machine learning (ML) has achieved remarkable breakthroughs in both academia and industry. However, imbalanced data distributions are prevalent in various types of raw data and severely hinder the performance of ML by biasing the decision-making processes. To deepen the understanding of imbalanced data and facilitate the related research and applications, this survey systematically analyzes various real-world data formats and concludes existing researches for different data formats into four distinct categories: data re-balancing, feature representation, training strategy, and ensemble learning. This structured analysis helps researchers comprehensively understand the pervasive nature of imbalance across diverse data formats, thereby paving a clearer path toward achieving specific research goals. We provide an overview of relevant open-source libraries, spotlight current challenges, and offer novel insights aimed at fostering future advancements in this critical area of study.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Gao et al. - 2025 - A Comprehensive Survey on Imbalanced Data Learning 1.pdf}
}

@misc{gaoComprehensiveSurveyImbalanced2025a,
  title = {A {{Comprehensive Survey}} on {{Imbalanced Data Learning}}},
  author = {Gao, Xinyi and Xie, Dongting and Zhang, Yihang and Wang, Zhengren and Chen, Chong and He, Conghui and Yin, Hongzhi and Zhang, Wentao},
  year = 2025,
  month = sep,
  eprint = {2502.08960},
  primaryclass = {cs},
  doi = {10.1007/s11704-025-50274-7},
  urldate = {2025-09-27},
  abstract = {With the expansion of data availability, machine learning (ML) has achieved remarkable breakthroughs in both academia and industry. However, imbalanced data distributions are prevalent in various types of raw data and severely hinder the performance of ML by biasing the decision-making processes. To deepen the understanding of imbalanced data and facilitate the related research and applications, this survey systematically analyzes various real-world data formats and concludes existing researches for different data formats into four distinct categories: data re-balancing, feature representation, training strategy, and ensemble learning. This structured analysis helps researchers comprehensively understand the pervasive nature of imbalance across diverse data formats, thereby paving a clearer path toward achieving specific research goals. We provide an overview of relevant open-source libraries, spotlight current challenges, and offer novel insights aimed at fostering future advancements in this critical area of study.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Gao et al. - 2025 - A Comprehensive Survey on Imbalanced Data Learning.pdf}
}

@inproceedings{garreauExplainingExplainerFirst2020,
  title = {Explaining the {{Explainer}}: {{A First Theoretical Analysis}} of {{LIME}}},
  shorttitle = {Explaining the {{Explainer}}},
  booktitle = {Proceedings of the {{Twenty Third International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Garreau, Damien and Luxburg, Ulrike},
  year = 2020,
  month = jun,
  pages = {1287--1296},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-09-10},
  abstract = {Machine learning is used more and more often for sensitive applications, sometimes replacing humans in critical decision-making processes. As such, interpretability of these algorithms is a pressing need. One popular algorithm to provide interpretability is LIME (Local Interpretable Model-Agnostic Explanation). In this paper, we provide the first theoretical analysis of LIME. We derive closed-form expressions for the coefficients of the interpretable model when the function to explain is linear. The good news is that these coefficients are proportional to the gradient of the function to explain: LIME indeed discovers meaningful features. However, our analysis also reveals that poor choices of parameters can lead LIME to miss important features.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Garreau and Luxburg - 2020 - Explaining the Explainer A First Theoretical Analysis of LIME 1.pdf;/home/paris/gdrive/Zotero/Garreau and Luxburg - 2020 - Explaining the Explainer A First Theoretical Analysis of LIME.pdf}
}

@article{geertlitjensSurveyDeepLearning2017,
  title = {A Survey on Deep Learning in Medical Image Analysis},
  author = {{Geert Litjens} and Litjens, Geert and {Thijs Kooi} and Kooi, Thijs and {Babak Ehteshami Bejnordi} and Bejnordi, Babak Ehteshami and {Arnaud Arindra Adiyoso Setio} and Setio, Arnaud Arindra Adiyoso and {Francesco Ciompi} and Ciompi, Francesco and {Mohsen Ghafoorian} and Ghafoorian, Mohsen and {Jeroen van der Laak} and {van der Laak}, Jeroen and {Bram van Ginneken} and {van Ginneken}, Bram and {Clara I. S\'anchez} and S{\'a}nchez, Clara I.},
  year = 2017,
  month = dec,
  journal = {Medical Image Analysis},
  volume = {42},
  pages = {60--88},
  doi = {10.1016/j.media.2017.07.005},
  abstract = {Abstract   Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
  annotation = {MAG ID: 2592929672},
  file = {/home/paris/gdrive/Zotero/Geert Litjens et al. - 2017 - A survey on deep learning in medical image analysis.pdf}
}

@inproceedings{geMDMAMultimodalData2023,
  title = {{{MDMA}}: {{Multimodal Data}} and {{Multi-attention Based Deep Learning Model}} for {{Alzheimer}}'s {{Disease Diagnosis}}},
  shorttitle = {{{MDMA}}},
  booktitle = {2023 8th {{International Conference}} on {{Cloud Computing}} and {{Big Data Analytics}} ({{ICCCBDA}})},
  author = {Ge, Chang and Xu, Jianyu and Hu, Jinyun and Liu, Peishun and Tang, Ruichun and Wang, Jinyu and Ren, Huyue},
  year = 2023,
  month = apr,
  pages = {120--127},
  issn = {2832-3734},
  doi = {10.1109/ICCCBDA56900.2023.10154636},
  urldate = {2025-10-24},
  abstract = {Recently, multimodal data-based methods have shown excellent performance in Alzheimer's Disease(AD) diagnosis. However, these methods commonly have the following two shortcomings: 1) the feature extraction processes of different modalities are independent and lack cooperation, which may lead to limited representation ability of the extracted features, and 2) the multimodal fusion operation is a simple concatenation, thus causing rough fusion features. To address these two issues, we propose a deep learning network based on multimodal data and multi-attention(MDMA), which consists of two key components, namely Cross-Modal Channel and Spatial attention (CMCS) and Cross-Modal Cross-Attention (CMCA). The CMCS module uses the interaction information from MRI and PET to recalibrate both channel-wise and spatial features for each modality. The CMCA module utilizes two multi-head cross attention to interactively fuse information from images and clinical data. In addition, Gradient-weighted Class Activation Mapping (Grad-CAM) method is used for visualizing the focused areas of the proposed model to make our model more transparent. Evaluated on the ADNI dataset with multimodal data collected from 113 AD, 146 mild cognitive impairment (MCI), and 135 normal controls (NC), we demonstrate that the proposed model achieves better results in terms of accuracy, sensitivity and specificity.},
  keywords = {alzheimer's disease,atttention mechanism,Biological system modeling,classification,deep learning,Deep learning,Fuses,Image color analysis,Magnetic resonance imaging,multimodal fusion,Neuroimaging,Sensitivity and specificity},
  file = {/home/paris/Zotero/storage/PGY7DXEA/10154636.html}
}

@inproceedings{ghafoorianTransferLearningDomain2017,
  title = {Transfer {{Learning}} for {{Domain Adaptation}} in {{MRI}}: {{Application}} in {{Brain Lesion Segmentation}}},
  shorttitle = {Transfer {{Learning}} for {{Domain Adaptation}} in {{MRI}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} - {{MICCAI}} 2017},
  author = {Ghafoorian, Mohsen and Mehrtash, Alireza and Kapur, Tina and Karssemeijer, Nico and Marchiori, Elena and Pesteie, Mehran and Guttmann, Charles R. G. and {de Leeuw}, Frank-Erik and Tempany, Clare M. and {van Ginneken}, Bram and Fedorov, Andriy and Abolmaesumi, Purang and Platel, Bram and Wells, William M.},
  editor = {Descoteaux, Maxime and {Maier-Hein}, Lena and Franz, Alfred and Jannin, Pierre and Collins, D. Louis and Duchesne, Simon},
  year = 2017,
  pages = {516--524},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-66179-7_59},
  abstract = {Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis and treatment. However, variations in MRI acquisition protocols result in different appearances of normal and diseased tissue in the images. Convolutional neural networks (CNNs), which have shown to be successful in many medical image analysis tasks, are typically sensitive to the variations in imaging protocols. Therefore, in many cases, networks trained on data acquired with one MRI protocol, do not perform satisfactorily on data acquired with different protocols. This limits the use of models trained with large annotated legacy datasets on a new dataset with a different domain which is often a recurring situation in clinical settings. In this study, we aim to answer the following central questions regarding domain adaptation in medical image analysis: Given a fitted legacy model, (1) How much data from the new domain is required for a decent adaptation of the original network?; and, (2) What portion of the pre-trained model parameters should be retrained given a certain number of the new domain training samples? To address these questions, we conducted extensive experiments in white matter hyperintensity segmentation task. We trained a CNN on legacy MR images of brain and evaluated the performance of the domain-adapted network on the same task with images from a different domain. We then compared the performance of the model to the surrogate scenarios where either the same trained network is used or a new network is trained from scratch on the new dataset. The domain-adapted network tuned only by two training examples achieved a Dice score of 0.63 substantially outperforming a similar network trained on the same set of examples from scratch.},
  isbn = {978-3-319-66179-7},
  langid = {english},
  annotation = {GSCC: 0000460 2025-06-15T15:39:14.723Z 1.04},
  file = {/home/paris/Zotero/storage/BN3WFSTU/Ghafoorian et al. - 2017 - Transfer Learning for Domain Adaptation in MRI Application in Brain Lesion Segmentation.pdf}
}

@article{goceriFullyAutomatedAdaptive2018,
  title = {Fully {{Automated}} and {{Adaptive Intensity Normalization Using Statistical Features}} for {{Brain MR Images}}},
  author = {Goceri, Evgin},
  year = 2018,
  month = mar,
  journal = {Celal Bayar University Journal of Science},
  volume = {14},
  number = {1},
  pages = {125--134},
  publisher = {Manisa Celal Bayar \"Universitesi},
  issn = {1305-130X, 1305-1385},
  doi = {10.18466/cbayarfbe.384729},
  urldate = {2025-06-03},
  abstract = {Accuracy of the results obtained by automated processing of brain magnetic resonance images has vital importance for diagnosis and evaluation of a progressive disease during treatment . However, automated processing methods such as segmentation, registration and comparison of these images are challenging issues. Because intensity values do not only depend on the underlying tissue type. They can change due to scanner-related artifacts and noise, which usually occurs in magnetic resonance images. In addition to intensity variations, low contrast and partial volume effects increases the difficulty in automated methods with these images. Intensity normalization has a significant role to increase performance of automated image processing methods. Because it is applied as a pre-processing step and efficiency of the other steps in these methods is based on the results obtained from the pre-processing step. The goal of intensity normalization is to make uniform the mean and variance values in images. Different methods have been applied for this purpose in the literature and each method has been tested with different kind of images. In this work; 1) The state-of-art normalization methods applied for magnetic resonance images have been reviewed. 2) A fully automated and adaptive approach has been proposed for intensity normalization in brain magnetic resonance images. 3) Comparative performance evaluations of the results obtained by four different normalization approaches using the same images have been presented. Comparisons of all methods implemented in this work indicate a better performance of the proposed approach for brain magnetic resonance images.},
  langid = {english},
  annotation = {GSCC: 0000055 2025-06-16T09:13:38.379Z 0.15},
  file = {/home/paris/Zotero/storage/JXYV3NBR/Goceri - 2018 - Fully Automated and Adaptive Intensity Normalization Using Statistical Features for Brain MR Images.pdf}
}

@article{golrizkhatamiChallengesIntegrativeDisease2020,
  title = {Challenges of {{Integrative Disease Modeling}} in {{Alzheimer}}'s {{Disease}}},
  author = {Golriz Khatami, Sepehr and Robinson, Christine and Birkenbihl, Colin and {Domingo-Fern{\'a}ndez}, Daniel and Hoyt, Charles Tapley and {Hofmann-Apitius}, Martin},
  year = 2020,
  month = jan,
  journal = {Frontiers in Molecular Biosciences},
  volume = {6},
  pages = {158},
  issn = {2296-889X},
  doi = {10.3389/fmolb.2019.00158},
  urldate = {2026-01-14},
  abstract = {Dementia-related diseases like Alzheimer's Disease (AD) have a tremendous social and economic cost. A deeper understanding of its underlying pathophysiologies may provide an opportunity for earlier detection and therapeutic intervention. Previous approaches for characterizing AD were targeted at single aspects of the disease. Yet, due to the complex nature of AD, the success of these approaches was limited. However, in recent years, advancements in integrative disease modeling, built on a wide range of AD biomarkers, have taken a global view on the disease, facilitating more comprehensive analysis and interpretation. Integrative AD models can be sorted in two primary types, namely hypothetical models and data-driven models. The latter group split into two subgroups: (i) Models that use traditional statistical methods such as linear models, (ii) Models that take advantage of more advanced artificial intelligence approaches such as machine learning. While many integrative AD models have been published over the last decade, their impact on clinical practice is limited. There exist major challenges in the course of integrative AD modeling, namely data missingness and censoring, imprecise human-involved priori knowledge, model reproducibility, dataset interoperability, dataset integration, and model interpretability. In this review, we highlight recent advancements and future possibilities of integrative modeling in the field of AD research, showcase and discuss the limitations and challenges involved, and finally, propose avenues to address several of these challenges.},
  pmcid = {PMC6971060},
  pmid = {31993440},
  file = {/home/paris/Zotero/storage/R6UYU6Q9/Golriz Khatami et al. - 2020 - Challenges of Integrative Disease Modeling in Alzheimer's Disease.pdf}
}

@article{gomarUtilityCombinationsBiomarkers2011,
  title = {Utility of Combinations of Biomarkers, Cognitive Markers, and Risk Factors to Predict Conversion from Mild Cognitive Impairment to {{Alzheimer}} Disease in Patients in the {{Alzheimer}}'s Disease Neuroimaging Initiative},
  author = {Gomar, Jesus J. and {Bobes-Bascaran}, Maria T. and {Conejero-Goldberg}, Concepcion and Davies, Peter and Goldberg, Terry E. and Initiative, Alzheimer's Disease Neuroimaging},
  year = 2011,
  journal = {Archives of general psychiatry},
  volume = {68},
  number = {9},
  pages = {961--969},
  publisher = {American Medical Association},
  urldate = {2024-11-16}
}

@article{gouKnowledgeDistillationSurvey2021,
  title = {Knowledge {{Distillation}}: {{A Survey}}},
  shorttitle = {Knowledge {{Distillation}}},
  author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng},
  year = 2021,
  month = jun,
  journal = {International Journal of Computer Vision},
  volume = {129},
  number = {6},
  pages = {1789--1819},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-021-01453-z},
  urldate = {2025-10-16},
  langid = {english},
  file = {/home/paris/Zotero/storage/EK6Z4E8S/Gou et al. - 2021 - Knowledge Distillation A Survey.pdf}
}

@article{goyalImageDenoisingReview2020,
  title = {Image Denoising Review: {{From}} Classical to State-of-the-Art Approaches},
  shorttitle = {Image Denoising Review},
  author = {Goyal, Bhawna and Dogra, Ayush and Agrawal, Sunil and Sohi, Balwinder Singh and Sharma, Apoorav},
  year = 2020,
  journal = {Information fusion},
  volume = {55},
  pages = {220--244},
  publisher = {Elsevier},
  urldate = {2025-07-01},
  file = {/home/paris/gdrive/Zotero/Denosing/Goyal et al. - 2020 - Image denoising review From classical to state-of-the-art approaches.pdf}
}

@article{grochSPECTYear2000,
  title = {{{SPECT}} in the {{Year}} 2000: {{Basic Principles}}},
  author = {Groch, Mark W and Erwin, William D},
  langid = {english},
  file = {/home/paris/Zotero/storage/M57X78LB/Groch and Erwin - SPECT in the Year 2000 Basic Principles.pdf}
}

@article{gudbjartssonRicianDistributionNoisy1995,
  title = {The {{Rician Distribution}} of {{Noisy MRI Data}}},
  author = {Gudbjartsson, H{\'a}kon and Patz, Samuel},
  year = 1995,
  month = dec,
  journal = {Magnetic resonance in medicine},
  volume = {34},
  number = {6},
  pages = {910--914},
  issn = {0740-3194},
  doi = {10.1002/mrm.1910340618},
  urldate = {2025-06-02},
  abstract = {The image intensity in magnetic resonance magnitude images in the presence of noise is shown to be governed by a Rician distribution. Low signal intensities (SNR {$<$} 2) are therefore biased due to the noise. It is shown how the underlying noise can be estimated from the images and a simple correction scheme is provided to reduce the bias. The noise characteristics in phase images are also studied and shown to be very different from those of the magnitude images. Common to both, however, is that the noise distributions are nearly Gaussian for SNR larger than two.},
  pmcid = {PMC2254141},
  pmid = {8598820},
  file = {/home/paris/gdrive/Zotero/Denosing/Gudbjartsson and Patz - 1995 - The Rician Distribution of Noisy MRI Data.pdf}
}

@article{guidoOverviewAdvancementsSupport2024,
  title = {An {{Overview}} on the {{Advancements}} of {{Support Vector Machine Models}} in {{Healthcare Applications}}: {{A Review}}},
  shorttitle = {An {{Overview}} on the {{Advancements}} of {{Support Vector Machine Models}} in {{Healthcare Applications}}},
  author = {Guido, Rosita and Ferrisi, Stefania and Lofaro, Danilo and Conforti, Domenico},
  year = 2024,
  month = apr,
  journal = {Information},
  volume = {15},
  number = {4},
  pages = {235},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info15040235},
  urldate = {2025-06-09},
  abstract = {Support vector machines (SVMs) are well-known machine learning algorithms for classification and regression applications. In the healthcare domain, they have been used for a variety of tasks including diagnosis, prognosis, and prediction of disease outcomes. This review is an extensive survey on the current state-of-the-art of SVMs developed and applied in the medical field over the years. Many variants of SVM-based approaches have been developed to enhance their generalisation capabilities. We illustrate the most interesting SVM-based models that have been developed and applied in healthcare to improve performance metrics on benchmark datasets, including hybrid classification methods that combine, for instance, optimization algorithms with SVMs. We even report interesting results found in medical applications related to real-world data. Several issues around SVMs, such as selection of hyperparameters and learning from data of questionable quality, are discussed as well. The several variants developed and introduced over the years could be useful in designing new methods to improve performance in critical fields such as healthcare, where accuracy, specificity, and other metrics are crucial. Finally, current research trends and future directions are underlined.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {healthcare,imbalanced dataset,support vector machine},
  file = {/home/paris/Zotero/storage/JC6G4Y6X/Guido et al. - 2024 - An Overview on the Advancements of Support Vector Machine Models in Healthcare Applications A Revie.pdf}
}

@article{gulumReviewExplainableDeep2021,
  title = {A Review of Explainable Deep Learning Cancer Detection Models in Medical Imaging},
  author = {Gulum, Mehmet A. and Trombley, Christopher M. and Kantardzic, Mehmed},
  year = 2021,
  journal = {Applied Sciences},
  volume = {11},
  number = {10},
  pages = {4573},
  publisher = {MDPI},
  urldate = {2025-06-24}
}

@article{gunningXAIExplainableArtificial2019,
  title = {{{XAI}}---{{Explainable}} Artificial Intelligence},
  author = {Gunning, David and Stefik, Mark and Choi, Jaesik and Miller, Timothy and Stumpf, Simone and Yang, Guang-Zhong},
  year = 2019,
  month = dec,
  journal = {Science Robotics},
  volume = {4},
  number = {37},
  pages = {eaay7120},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.aay7120},
  urldate = {2025-09-03},
  abstract = {Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications.           ,              Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications.},
  copyright = {http://www.sciencemag.org/about/science-licenses-journal-article-reuse},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Gunning et al. - 2019 - XAI—Explainable artificial intelligence.pdf}
}

@inproceedings{guoClassImbalanceProblem2008,
  title = {On the Class Imbalance Problem},
  booktitle = {2008 {{Fourth}} International Conference on Natural Computation},
  author = {Guo, Xinjian and Yin, Yilong and Dong, Cailing and Yang, Gongping and Zhou, Guangtong},
  year = 2008,
  volume = {4},
  pages = {192--201},
  publisher = {IEEE},
  urldate = {2025-10-14}
}

@article{hamiltonRecentAdvancesParallel2017,
  title = {Recent Advances in Parallel Imaging for {{MRI}}},
  author = {Hamilton, Jesse and Franson, Dominique and Seiberlich, Nicole},
  year = 2017,
  journal = {Progress in nuclear magnetic resonance spectroscopy},
  volume = {101},
  pages = {71--95},
  publisher = {Elsevier},
  urldate = {2025-06-27},
  file = {/home/paris/gdrive/Zotero/Denosing/Hamilton et al. - 2017 - Recent advances in parallel imaging for MRI.pdf}
}

@article{hammadNovelEndtoendDeep2022,
  title = {A Novel End-to-End Deep Learning Approach for Cancer Detection Based on Microscopic Medical Images},
  author = {Hammad, Mohamed and Bakrey, Mohamed and Bakhiet, Ali and Tadeusiewicz, Ryszard and {El-Latif}, Ahmed A. Abd and P{\l}awiak, Pawe{\l}},
  year = 2022,
  month = jul,
  journal = {Biocybernetics and Biomedical Engineering},
  volume = {42},
  number = {3},
  pages = {737--748},
  issn = {0208-5216},
  doi = {10.1016/j.bbe.2022.05.009},
  urldate = {2025-06-24},
  abstract = {As a result of late diagnosis, cancer is the second leading cause of death in most countries in the world. Usually, many cases of cancer are diagnosed at an advanced stage, which reduces the chances of recovery from the disease due to the inability to provide appropriate treatment. The earlier cancer is detected, the more effective the treatment can be, especially for incurable cancers, which can result in a shorter life expectancy due to the rapid spread of the disease. The early detection of cancer also greatly reduces the financial consequences of it, as the cost of treating it in its early stages is much lower than in its other stages. Therefore, several previous studies focus on developing computer-aided cancer diagnosis systems (CACDs) that can detect cancer in its earliest stages automatically. In this paper, a novel approach is proposed for cancer detection. The proposed approach is an end-to-end deep learning approach, where the input images are fed directly to the deep model for final decision. In this research, the accuracy of a new deep convolutional neural network (CNN) for cancer detection is explored. The microscopic medical images obtained from the cancer database were used to evaluate our study, which were labelled as normal and abnormal images. The presented model achieved an accuracy of 99.99\%, which is the highest accuracy compared with other deep learning models. Finally, the proposed approach would be very useful and effective, especially in low-income countries where referral systems for patients with suspected cancer are often unavailable, resulting in delayed and fragmented care.},
  keywords = {CAD,Cancer,CNN,Deep learning,Detection,End-to-end,Microscopic medical images},
  file = {/home/paris/Zotero/storage/PDF752U2/S020852162200047X.html}
}

@article{hassenDeepLearningMethods2024,
  title = {Deep Learning Methods for Early Detection of {{Alzheimer}}'s Disease Using Structural {{MR}} Images: A Survey},
  shorttitle = {Deep Learning Methods for Early Detection of {{Alzheimer}}'s Disease Using Structural {{MR}} Images},
  author = {Hassen, Sonia Ben and Neji, Mohamed and Hussain, Zain and Hussain, Amir and Alimi, Adel M. and Frikha, Mondher},
  year = 2024,
  month = apr,
  journal = {Neurocomputing},
  volume = {576},
  pages = {127325},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2024.127325},
  urldate = {2025-06-09},
  abstract = {In this paper, we present an extensive review of the most recent works on Alzheimer's disease (AD) prediction, focusing on Moderate Cognitive Impairment (MCI) conversion prediction. We aimed to identify the most useful brain-magnetic resonance imaging (MRI) biomarkers and deep learning frameworks used for prediction. To achieve this, we analyzed more than 130 studies and reviewed 7 articles. A closer examination revealed that the hippocampus is an important region of interest (ROI) affected early by AD, and many related features help detect the disease in its early stages. However, when considered alone, this ROI is not sufficient to ensure high prediction performance. Therefore, several other brain regions can also provide additional information to improve prediction accuracy. Concerning state-of-the-art deep neural networks, the U-Net represents the most efficient architecture for hippocampus segmentation. The RESU-Net architecture achieved the highest Dice Similarity Coefficient (DSC) value, equal to 94\%.For MCI conversion prediction, the best results were obtained by two models identifying significant landmarks from the entire brain for classification. The multi-stream convolutional neural network achieved the best Area Under the Curve (AUC) and specificity of 94.39\% and 99.70\%, respectively. Finally, a region ensemble model delivered the highest accuracy of 85.90\%, highlighting the need for further research to address this challenging problem.},
  keywords = {Alzheimer's disease,Deep learning,Hippocampus,Progressive MCI,Stable MCI,Structural MRI}
}

@article{hassounFundamentalsArtificialNeural,
  title = {Fundamentals of {{Artificial Neural Networks-}}},
  author = {Hassoun, H},
  langid = {english},
  file = {/home/paris/Zotero/storage/6AGV2BBB/Hassoun - Fundamentals of Artificial Neural Networks-.pdf}
}

@book{hassounFundamentalsArtificialNeural1995,
  title = {Fundamentals of {{Artificial Neural Networks}}},
  author = {Hassoun, Mohamad H.},
  year = 1995,
  publisher = {MIT Press},
  abstract = {"In Fundamentals of Artificial Neural Networks, Mohamad Hassoun provides the first systematic account of artificial neural network paradigms by identifying clearly the fundamental concepts and major methodologies underlying most of the current theory and practice employed by neural network researchers. Such a systematic and unified treatment makes the subject more accessible to students and practitioners. Here, important results are integrated in order to more fully explain a wide range of existing empirical observations and commonly used heuristics. There are numerous illustrative examples, more than 200 end-of-chapter analytical and computer-based problems that will aid in the development of neural network analysis and design skills, and a bibliography of nearly 700 references. Proceeding in a clear and logical fashion, the book presents the basic building blocks and concepts of artificial neural networks, brings together supervised, reinforcement, and unsupervised learning rules in simple nets in a common framework, and then covers such topics as the convergence and solution properties of these learning rules, learning multilayer nets using backprop and its variants, major neural network paradigms, associative memories, energy minimizing nets, Boltzmann machines and Boltzmann learning, and other global search/optimization algorithms such as stochastic gradient search, simulated annealing, and genetic algorithms."--Page 4 of cover.},
  googlebooks = {Otk32Y3QkxQC},
  isbn = {978-0-262-08239-6},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / General,Computers / Computer Science,Computers / Data Science / Neural Networks}
}

@article{hintonFastLearningAlgorithm2006,
  title = {A {{Fast Learning Algorithm}} for {{Deep Belief Nets}}},
  author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
  year = 2006,
  month = jul,
  journal = {Neural Computation},
  volume = {18},
  number = {7},
  pages = {1527--1554},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.2006.18.7.1527},
  urldate = {2025-10-31},
  abstract = {We show how to use ``complementary priors'' to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
  langid = {english},
  file = {/home/paris/Zotero/storage/97KT7U7V/Hinton et al. - 2006 - A Fast Learning Algorithm for Deep Belief Nets.pdf}
}

@article{hirataVoxelbasedMorphometryDiscriminate2005,
  title = {Voxel-Based Morphometry to Discriminate Early {{Alzheimer}}'s Disease from Controls},
  author = {Hirata, Yoko and Matsuda, Hiroshi and Nemoto, Kiyotaka and Ohnishi, Takashi and Hirao, Kentaro and Yamashita, Fumio and Asada, Takashi and Iwabuchi, Satoshi and Samejima, Hirotsugu},
  year = 2005,
  month = jul,
  journal = {Neuroscience Letters},
  volume = {382},
  number = {3},
  pages = {269--274},
  issn = {0304-3940},
  doi = {10.1016/j.neulet.2005.03.038},
  urldate = {2025-07-18},
  abstract = {We assessed the accuracy of voxel-based morphometry (VBM) using a three-dimensional T1-weighted MRI in discriminating Alzheimer's disease (AD) in the very early stage of amnestic type of mild cognitive impairment and age-matched healthy controls. We randomly divided these subjects into two groups. The first group comprising 30 AD patients and 41 controls was used to identify the area with the most significant gray matter loss in patients compared to normal controls based on the voxel-based analysis of a group comparison. The second group comprising 31 patients and 41 controls was used to determine the discrimination accuracy of VBM. A Z-score map for a gray matter image of a subject was obtained by comparison with mean and standard deviation gray matter images of the controls for each voxel after anatomical standardization and voxel normalization to global mean using the following equation; Z-score=([control mean]-[individual value])/(control S.D.). Receiver operating characteristic curves for a Z-score in the bilateral medial temporal areas including the entorhinal cortex with the most significant loss in the first group showed a high discrimination accuracy of 87.8\%. This result would open up a possibility for early diagnosis of AD using VBM.},
  keywords = {Alzheimer's disease,Mild cognitive impairment,MRI,Voxel-based morphometry},
  file = {/home/paris/gdrive/Zotero/Hirata et al. - 2005 - Voxel-based morphometry to discriminate early Alzheimer's disease from controls.pdf;/home/paris/Zotero/storage/YTMPIKF8/S0304394005003344.html}
}

@article{hoeflerSparsityDeepLearning,
  title = {Sparsity in {{Deep Learning}}: {{Pruning}} and Growth for Efficient Inference and Training in Neural Networks},
  author = {Hoefler, Torsten and Alistarh, Dan and {Ben-Nun}, Tal and Dryden, Nikoli},
  abstract = {The growing energy and performance costs of deep learning have driven the community to reduce the size of neural networks by selectively pruning components. Similarly to their biological counterparts, sparse networks generalize just as well, sometimes even better than, the original dense networks. Sparsity promises to reduce the memory footprint of regular networks to fit mobile devices, as well as shorten training time for ever growing networks. In this paper, we survey prior work on sparsity in deep learning and provide an extensive tutorial of sparsification for both inference and training. We describe approaches to remove and add elements of neural networks, different training strategies to achieve model sparsity, and mechanisms to exploit sparsity in practice. Our work distills ideas from more than 300 research papers and provides guidance to practitioners who wish to utilize sparsity today, as well as to researchers whose goal is to push the frontier forward. We include the necessary background on mathematical methods in sparsification, describe phenomena such as early structure adaptation, the intricate relations between sparsity and the training process, and show techniques for achieving acceleration on real hardware. We also define a metric of pruned parameter efficiency that could serve as a baseline for comparison of different sparse networks. We close by speculating on how sparsity can improve future workloads and outline major open problems in the field.},
  langid = {english},
  file = {/home/paris/Zotero/storage/2ICHB5X7/Hoeﬂer et al. - Sparsity in Deep Learning Pruning and growth for eﬃcient inference and training in neural networks.pdf}
}

@article{hoopesSynthStripSkullstrippingAny2022,
  title = {{{SynthStrip}}: Skull-Stripping for Any Brain Image},
  shorttitle = {{{SynthStrip}}},
  author = {Hoopes, Andrew and Mora, Jocelyn S. and Dalca, Adrian V. and Fischl, Bruce and Hoffmann, Malte},
  year = 2022,
  month = oct,
  journal = {NeuroImage},
  volume = {260},
  pages = {119474},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2022.119474},
  abstract = {The removal of non-brain signal from magnetic resonance imaging (MRI) data, known as skull-stripping, is an integral component of many neuroimage analysis streams. Despite their abundance, popular classical skull-stripping methods are usually tailored to images with specific acquisition properties, namely near-isotropic resolution and T1-weighted (T1w) MRI contrast, which are prevalent in research settings. As a result, existing tools tend to adapt poorly to other image types, such as stacks of thick slices acquired with fast spin-echo (FSE) MRI that are common in the clinic. While learning-based approaches for brain extraction have gained traction in recent years, these methods face a similar burden, as they are only effective for image types seen during the training procedure. To achieve robust skull-stripping across a landscape of imaging protocols, we introduce SynthStrip, a rapid, learning-based brain-extraction tool. By leveraging anatomical segmentations to generate an entirely synthetic training dataset with anatomies, intensity distributions, and artifacts that far exceed the realistic range of medical images, SynthStrip learns to successfully generalize to a variety of real acquired brain images, removing the need for training data with target contrasts. We demonstrate the efficacy of SynthStrip for a diverse set of image acquisitions and resolutions across subject populations, ranging from newborn to adult. We show substantial improvements in accuracy over popular skull-stripping baselines - all with a single trained model. Our method and labeled evaluation data are available at~https://w3id.org/synthstrip.},
  langid = {english},
  pmcid = {PMC9465771},
  pmid = {35842095},
  keywords = {Adult,Brain,Brain extraction,Contrast Media,Deep learning,Head,Humans,Image Processing Computer-Assisted,Image synthesis,Infant Newborn,Magnetic Resonance Imaging,MRI-contrast agnosticism,Skull,Skull stripping},
  file = {/home/paris/Zotero/storage/GXKB6ZT2/Hoopes et al. - 2022 - SynthStrip skull-stripping for any brain image.pdf}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  year = 1989,
  month = jan,
  journal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  urldate = {2025-11-01},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
  file = {/home/paris/Zotero/storage/CDBYHYYB/0893608089900208.html}
}

@misc{houSelfeXplainableAIMedical2024,
  title = {Self-{{eXplainable AI}} for {{Medical Image Analysis}}: {{A Survey}} and {{New Outlooks}}},
  shorttitle = {Self-{{eXplainable AI}} for {{Medical Image Analysis}}},
  author = {Hou, Junlin and Liu, Sicen and Bie, Yequan and Wang, Hongmei and Tan, Andong and Luo, Luyang and Chen, Hao},
  year = 2024,
  month = oct,
  journal = {arXiv.org},
  urldate = {2025-10-27},
  abstract = {The increasing demand for transparent and reliable models, particularly in high-stakes decision-making areas such as medical image analysis, has led to the emergence of eXplainable Artificial Intelligence (XAI). Post-hoc XAI techniques, which aim to explain black-box models after training, have raised concerns about their fidelity to model predictions. In contrast, Self-eXplainable AI (S-XAI) offers a compelling alternative by incorporating explainability directly into the training process of deep learning models. This approach allows models to generate inherent explanations that are closely aligned with their internal decision-making processes, enhancing transparency and supporting the trustworthiness, robustness, and accountability of AI systems in real-world medical applications. To facilitate the development of S-XAI methods for medical image analysis, this survey presents a comprehensive review across various image modalities and clinical applications. It covers more than 200 papers from three key perspectives: 1) input explainability through the integration of explainable feature engineering and knowledge graph, 2) model explainability via attention-based learning, concept-based learning, and prototype-based learning, and 3) output explainability by providing textual and counterfactual explanations. This paper also outlines desired characteristics of explainability and evaluation methods for assessing explanation quality, while discussing major challenges and future research directions in developing S-XAI for medical image analysis.},
  howpublished = {https://arxiv.org/abs/2410.02331v2},
  langid = {english},
  file = {/home/paris/Zotero/storage/6LP4SLZ5/Hou et al. - 2024 - Self-eXplainable AI for Medical Image Analysis A Survey and New Outlooks.pdf}
}

@misc{HttpsWwwlpiteluvaesSanti,
  title = {{{https://www.lpi.tel.uva.es/\textasciitilde santi/personal/docus/noise\_survey\_tec\_report.pdf}}},
  urldate = {2025-06-02},
  howpublished = {https://www.lpi.tel.uva.es/\textasciitilde santi/personal/docus/noise\_survey\_tec\_report.pdf},
  file = {/home/paris/gdrive/Zotero/Denosing/httpswww.lpi.tel.uva.es~santipersonaldocusnoise_survey_tec_report.pdf.pdf}
}

@article{huangDiagnosisAlzheimersDisease2019,
  title = {Diagnosis of {{Alzheimer}}'s {{Disease}} via {{Multi-Modality 3D Convolutional Neural Network}}},
  author = {Huang, Yechong and Xu, Jiahang and Zhou, Yuncheng and Tong, Tong and Zhuang, Xiahai},
  year = 2019,
  month = may,
  journal = {Frontiers in Neuroscience},
  volume = {13},
  pages = {509},
  issn = {1662-4548},
  doi = {10.3389/fnins.2019.00509},
  urldate = {2025-08-19},
  abstract = {Alzheimer's disease (AD) is one of the most common neurodegenerative diseases. In the last decade, studies on AD diagnosis has attached great significance to artificial intelligence-based diagnostic algorithms. Among the diverse modalities of imaging data, T1-weighted MR and FDG-PET are widely used for this task. In this paper, we propose a convolutional neural network (CNN) to integrate all the multi-modality information included in both T1-MR and FDG-PET images of the hippocampal area, for the diagnosis of AD. Different from the traditional machine learning algorithms, this method does not require manually extracted features, instead, it utilizes 3D image-processing CNNs to learn features for the diagnosis or prognosis of AD. To test the performance of the proposed network, we trained the classifier with paired T1-MR and FDG-PET images in the ADNI datasets, including 731 cognitively unimpaired (labeled as CN) subjects, 647 subjects with AD, 441 subjects with stable mild cognitive impairment (sMCI) and 326 subjects with progressive mild cognitive impairment (pMCI). We obtained higher accuracies of 90.10\% for CN vs. AD task, 87.46\% for CN vs. pMCI task, and 76.90\% for sMCI vs. pMCI task. The proposed framework yields a state-of-the-art performance. Finally, the results have demonstrated that (1) segmentation is not a prerequisite when using a CNN for the classification, (2) the combination of two modality imaging data generates better results.},
  pmcid = {PMC6555226},
  pmid = {31213967},
  file = {/home/paris/gdrive/Zotero/Huang et al. - 2019 - Diagnosis of Alzheimer’s Disease via Multi-Modality 3D Convolutional Neural Network.pdf}
}

@article{huangEstablishingMachineLearning2024,
  title = {Establishing a Machine Learning Dementia Progression Prediction Model with Multiple Integrated Data},
  author = {Huang, Yung-Chuan and Liu, Tzu-Chi and Lu, Chi-Jie},
  year = 2024,
  month = nov,
  journal = {BMC Medical Research Methodology},
  volume = {24},
  pages = {288},
  issn = {1471-2288},
  doi = {10.1186/s12874-024-02411-2},
  urldate = {2025-10-14},
  abstract = {Objective Dementia is a significant medical and social issue in most developed countries. Practical tools for predicting the progression of degenerative dementia are highly valuable. Machine learning (ML) methods facilitate the construction of effective models using real-world data, which may include missing values and various integrated datasets. Method This retrospective study analyzed data from 679 patients diagnosed with degenerative dementia at Fu Jen Catholic University Hospital, who were evaluated by neurologists, psychologists and followed for over two years. Predictive variables were categorized into demographic (D), clinical dementia rating (CDR), mini-mental state examination (MMSE), and laboratory data value (LV) groups. These categories were further integrated into three subgroups (D-CDR, D-CDR-MMSE, and D-CDR-MMSE-LV). We utilized the extreme gradient boosting (XGB) model to rank the importance of variables and identify the most effective feature combination via a step-wise approach. Result The D-CDR-MMSE-LV model combination showed robust performance with an excellent area under the receiver operating characteristic curve (AUC) and the highest sensitivity value (84.66). Employing both demographic and neuropsychiatric variables, our prediction model achieved an AUC of 83.74. By incorporating additional clinical information from laboratory data and applying our proposed feature selection strategy, we constructed a model based on eight variables that achieved an AUC of 85.12 using the XGB technique. Conclusion We established a machine-learning model to monitor the progression of dementia using a limited, real-world clinical dataset. The XGB technique identified eight critical variables across our integrated datasets, potentially providing clinicians with valuable guidance. Supplementary Information The online version contains supplementary material available at 10.1186/s12874-024-02411-2.},
  pmcid = {PMC11583646},
  pmid = {39578765},
  file = {/home/paris/Zotero/storage/3DUZL6LN/Huang et al. - 2024 - Establishing a machine learning dementia progression prediction model with multiple integrated data.pdf}
}

@article{huangVoxelbasedMorphometryDeep2023,
  title = {Voxel-Based Morphometry and a Deep Learning Model for the Diagnosis of Early {{Alzheimer}}'s Disease Based on Cerebral Gray Matter Changes},
  author = {Huang, Huaidong and Zheng, Shiqiang and Yang, Zhongxian and Wu, Yi and Li, Yan and Qiu, Jinming and Cheng, Yan and Lin, Panpan and Lin, Yan and Guan, Jitian and Mikulis, David John and Zhou, Teng and Wu, Renhua},
  year = 2023,
  month = feb,
  journal = {Cerebral Cortex},
  volume = {33},
  number = {3},
  pages = {754--763},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhac099},
  urldate = {2025-07-25},
  abstract = {This study aimed to analyse cerebral grey matter changes in mild cognitive impairment (MCI) using voxel-based morphometry and to diagnose early Alzheimer's disease using deep learning methods based on convolutional neural networks (CNNs) evaluating these changes. Participants (111 MCI, 73 normal cognition) underwent 3-T structural magnetic resonance imaging. The obtained images were assessed using voxel-based morphometry, including extraction of cerebral grey matter, analyses of statistical differences, and correlation analyses between cerebral grey matter and clinical cognitive scores in MCI. The CNN-based deep learning method was used to extract features of cerebral grey matter images. Compared to subjects with normal cognition, participants with MCI had grey matter atrophy mainly in the entorhinal cortex, frontal cortex, and bilateral frontotemporal lobes (p \&lt; 0.0001). This atrophy was significantly correlated with the decline in cognitive scores (p \&lt; 0.01). The accuracy, sensitivity, and specificity of the CNN model for identifying participants with MCI were 80.9\%, 88.9\%, and 75\%, respectively. The area under the curve of the model was 0.891. These findings demonstrate that research based on brain morphology can provide an effective way for the clinical, non-invasive, objective evaluation and identification of early Alzheimer's disease.},
  file = {/home/paris/gdrive/Zotero/Huang et al. - 2023 - Voxel-based morphometry and a deep learning model for the diagnosis of early Alzheimer’s disease bas.pdf;/home/paris/Zotero/storage/I4GVVV42/bhac099.html}
}

@article{huImageHarmonizationReview2023,
  title = {Image Harmonization: {{A}} Review of Statistical and Deep Learning Methods for Removing Batch Effects and Evaluation Metrics for Effective Harmonization},
  shorttitle = {Image Harmonization},
  author = {Hu, Fengling and Chen, Andrew A. and Horng, Hannah and Bashyam, Vishnu and Davatzikos, Christos and {Alexander-Bloch}, Aaron and Li, Mingyao and Shou, Haochang and Satterthwaite, Theodore D. and Yu, Meichen and Shinohara, Russell T.},
  year = 2023,
  month = jul,
  journal = {NeuroImage},
  volume = {274},
  pages = {120125},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2023.120125},
  urldate = {2025-06-04},
  abstract = {Magnetic resonance imaging and computed tomography from multiple batches (e.g.~sites, scanners, datasets, etc.) are increasingly used alongside complex downstream analyses to obtain new insights into the human brain. However, significant confounding due to batch-related technical variation, called batch effects, is present in this data; direct application of downstream analyses to the data may lead to biased results. Image harmonization methods seek to remove these batch effects and enable increased generalizability and reproducibility of downstream results. In this review, we describe and categorize current approaches in statistical and deep learning harmonization methods. We also describe current evaluation metrics used to assess harmonization methods and provide a standardized framework to evaluate newly-proposed methods for effective harmonization and preservation of biological information. Finally, we provide recommendations to end-users to advocate for more effective use of current methods and to methodologists to direct future efforts and accelerate development of the field.},
  annotation = {GSCC: 0000105 2025-06-15T15:39:19.929Z 1.02}
}

@article{hulsenExplainableArtificialIntelligence2023,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}): {{Concepts}} and {{Challenges}} in {{Healthcare}}},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}})},
  author = {Hulsen, Tim},
  year = 2023,
  month = sep,
  journal = {AI},
  volume = {4},
  number = {3},
  pages = {652--666},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-2688},
  doi = {10.3390/ai4030034},
  urldate = {2025-09-12},
  abstract = {Artificial Intelligence (AI) describes computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. Examples of AI techniques are machine learning, neural networks, and deep learning. AI can be applied in many different areas, such as econometrics, biometry, e-commerce, and the automotive industry. In recent years, AI has found its way into healthcare as well, helping doctors make better decisions (``clinical decision support''), localizing tumors in magnetic resonance images, reading and analyzing reports written by radiologists and pathologists, and much more. However, AI has one big risk: it can be perceived as a ``black box'', limiting trust in its reliability, which is a very big issue in an area in which a decision can mean life or death. As a result, the term Explainable Artificial Intelligence (XAI) has been gaining momentum. XAI tries to ensure that AI algorithms (and the resulting decisions) can be understood by humans. In this narrative review, we will have a look at some central concepts in XAI, describe several challenges around XAI in healthcare, and discuss whether it can really help healthcare to advance, for example, by increasing understanding and trust. Finally, alternatives to increase trust in AI are discussed, as well as future research possibilities in the area of XAI.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {AI,artificial intelligence,big data,data science,deep learning,explainability,explainable,healthcare,machine learning,medicine,XAI},
  file = {/home/paris/gdrive/Zotero/Hulsen - 2023 - Explainable Artificial Intelligence (XAI) Concepts and Challenges in Healthcare.pdf}
}

@article{huReinforcementLearningMedical2023,
  title = {Reinforcement Learning in Medical Image Analysis: {{Concepts}}, Applications, Challenges, and Future Directions},
  shorttitle = {Reinforcement Learning in Medical Image Analysis},
  author = {Hu, Mingzhe and Zhang, Jiahan and Matkovic, Luke and Liu, Tian and Yang, Xiaofeng},
  year = 2023,
  month = feb,
  journal = {Journal of Applied Clinical Medical Physics},
  volume = {24},
  number = {2},
  pages = {e13898},
  issn = {1526-9914, 1526-9914},
  doi = {10.1002/acm2.13898},
  urldate = {2025-06-26},
  abstract = {Abstract                            Motivation               Medical image analysis involves a series of tasks used to assist physicians in qualitative and quantitative analyses of lesions or anatomical structures which can significantly improve the accuracy and reliability of medical diagnoses and prognoses. Traditionally, these tedious tasks were finished by experienced physicians or medical physicists and were marred with two major problems, low efficiency and bias.               In the past decade, many machine learning methods have been applied to accelerate and automate the image analysis process. Compared to the enormous deployments of supervised and unsupervised learning models, attempts to use reinforcement learning in medical image analysis are still scarce. We hope that this review article could serve as the stepping stone for related research in the future.                                         Significance               We found that although reinforcement learning has gradually gained momentum in recent years, many researchers in the medical analysis field still find it hard to understand and deploy in clinical settings. One possible cause is a lack of well-organized review articles intended for readers without professional computer science backgrounds. Rather than to provide a comprehensive list of all reinforcement learning models applied in medical image analysis, the aim of this review is to help the readers formulate and solve their medical image analysis research through the lens of reinforcement learning.                                         Approach \& Results               We selected published articles from Google Scholar and PubMed. Considering the scarcity of related articles, we also included some outstanding newest preprints. The papers were carefully reviewed and categorized according to the type of image analysis task. In this article, we first reviewed the basic concepts and popular models of reinforcement learning. Then, we explored the applications of reinforcement learning models in medical image analysis. Finally, we concluded the article by discussing the reviewed reinforcement learning approaches' limitations and possible future improvements.},
  langid = {english}
}

@inproceedings{HybridCNNSVMAlzheimers2018,
  title = {Hybrid {{CNN-SVM}} for {{Alzheimer}}'s {{Disease Classification}} from {{Structural MRI}} and the {{Alzheimer}}'s {{Disease Neuroimaging Initiative}} ({{ADNI}})},
  booktitle = {2018 {{International Conference}} on {{Biomedical Engineering}}, {{Machinery}} and {{Earth Science}} ({{BEMES}} 2018)},
  year = 2018,
  publisher = {Francis Academic Press},
  doi = {10.25236/bemes.2018.041},
  urldate = {2025-08-22},
  abstract = {Alzheimer's disease (AD) is a progressive neurological disorder among the elders, which results in memory-related issues in subjects. An accurate classification of patients with AD and mild cognitive impairment (MCI) from healthy control subjects (HC) based on structural magnetic resonance imaging (MRI) is of critical clinical importance. In this paper, good intermediate representations of MRI are obtained from a pre-trained convolutional neural network (CNN). Principal component analysis (PCA) and sequential feature selection (SFS) are applied for feature selection, while a support vector machine (SVM) is adopted to evaluate the classification accuracy. 422 Alzheimer's Disease Neuroimaging Initiative (ADNI) baseline MRI were used for development and validation of our proposed method. As a result, this paper achieved a classification accuracy of 90\% for binary classification of AD and HC, 81\% for AD and MCI and 72\% for MCI and HC.},
  isbn = {978-1-912407-07-1},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/2018 - Hybrid CNN-SVM for Alzheimer's Disease Classification from Structural MRI and the Alzheimer’s Diseas.pdf}
}

@article{iglesiasRobustBrainExtraction2011,
  title = {Robust Brain Extraction across Datasets and Comparison with Publicly Available Methods},
  author = {Iglesias, Juan Eugenio and Liu, Cheng-Yi and Thompson, Paul M. and Tu, Zhuowen},
  year = 2011,
  month = sep,
  journal = {IEEE transactions on medical imaging},
  volume = {30},
  number = {9},
  pages = {1617--1634},
  issn = {1558-254X},
  doi = {10.1109/TMI.2011.2138152},
  abstract = {Automatic whole-brain extraction from magnetic resonance images (MRI), also known as skull stripping, is a key component in most neuroimage pipelines. As the first element in the chain, its robustness is critical for the overall performance of the system. Many skull stripping methods have been proposed, but the problem is not considered to be completely solved yet. Many systems in the literature have good performance on certain datasets (mostly the datasets they were trained/tuned on), but fail to produce satisfactory results when the acquisition conditions or study populations are different. In this paper we introduce a robust, learning-based brain extraction system (ROBEX). The method combines a discriminative and a generative model to achieve the final result. The discriminative model is a Random Forest classifier trained to detect the brain boundary; the generative model is a point distribution model that ensures that the result is plausible. When a new image is presented to the system, the generative model is explored to find the contour with highest likelihood according to the discriminative model. Because the target shape is in general not perfectly represented by the generative model, the contour is refined using graph cuts to obtain the final segmentation. Both models were trained using 92 scans from a proprietary dataset but they achieve a high degree of robustness on a variety of other datasets. ROBEX was compared with six other popular, publicly available methods (BET, BSE, FreeSurfer, AFNI, BridgeBurner, and GCUT) on three publicly available datasets (IBSR, LPBA40, and OASIS, 137 scans in total) that include a wide range of acquisition hardware and a highly variable population (different age groups, healthy/diseased). The results show that ROBEX provides significantly improved performance measures for almost every method/dataset combination.},
  langid = {english},
  pmid = {21880566},
  keywords = {Adult,Aged,Algorithms,Brain,Computer Simulation,Database Management Systems,Databases Factual,Discriminant Analysis,Electronic Data Processing,Female,Humans,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Male,Middle Aged,Models Anatomic,Pattern Recognition Automated,Reproducibility of Results,Sensitivity and Specificity,Skull}
}

@article{ilesanmiMethodsImageDenoising2021,
  title = {Methods for Image Denoising Using Convolutional Neural Network: A Review},
  shorttitle = {Methods for Image Denoising Using Convolutional Neural Network},
  author = {Ilesanmi, Ademola E. and Ilesanmi, Taiwo O.},
  year = 2021,
  month = oct,
  journal = {Complex \& Intelligent Systems},
  volume = {7},
  number = {5},
  pages = {2179--2198},
  issn = {2198-6053},
  doi = {10.1007/s40747-021-00428-4},
  urldate = {2025-05-25},
  abstract = {Image denoising faces significant challenges, arising from the sources of noise. Specifically, Gaussian, impulse, salt, pepper, and speckle noise are complicated sources of noise in imaging. Convolutional neural network (CNN) has increasingly received attention in image denoising task. Several CNN methods for denoising images have been studied. These methods used different datasets for evaluation. In this paper, we offer an elaborate study on different CNN techniques used in image denoising. Different CNN methods for image denoising were categorized and analyzed. Popular datasets used for evaluating CNN image denoising methods were investigated. Several CNN image denoising papers were selected for review and analysis. Motivations and principles of CNN methods were outlined. Some state-of-the-arts CNN image denoising methods were depicted in graphical forms, while other methods were elaborately explained. We proposed a review of image denoising with CNN. Previous and recent papers on image denoising with CNN were selected. Potential challenges and directions for future research were equally fully explicated.},
  langid = {english},
  keywords = {3-D Image Reconstruction,Cellular Noise,Computer Vision,Convolutional neural network,Deep neural network,Image denoising,Image Processing,Imaging Techniques,Noise in images,Signal Processing},
  file = {/home/paris/gdrive/Zotero/Denosing/Ilesanmi and Ilesanmi - 2021 - Methods for image denoising using convolutional neural network a review.pdf}
}

@article{isenseeAutomatedBrainExtraction2019,
  title = {Automated Brain Extraction of Multisequence {{MRI}} Using Artificial Neural Networks},
  author = {Isensee, Fabian and Schell, Marianne and Pflueger, Irada and Brugnara, Gianluca and Bonekamp, David and Neuberger, Ulf and Wick, Antje and Schlemmer, Heinz-Peter and Heiland, Sabine and Wick, Wolfgang and Bendszus, Martin and {Maier-Hein}, Klaus H. and Kickingereder, Philipp},
  year = 2019,
  month = dec,
  journal = {Human Brain Mapping},
  volume = {40},
  number = {17},
  pages = {4952--4964},
  issn = {1097-0193},
  doi = {10.1002/hbm.24750},
  abstract = {Brain extraction is a critical preprocessing step in the analysis of neuroimaging studies conducted with magnetic resonance imaging (MRI) and influences the accuracy of downstream analyses. The majority of brain extraction algorithms are, however, optimized for processing healthy brains and thus frequently fail in the presence of pathologically altered brain or when applied to heterogeneous MRI datasets. Here we introduce a new, rigorously validated algorithm (termed HD-BET) relying on artificial neural networks that aim to overcome these limitations. We demonstrate that HD-BET outperforms six popular, publicly available brain extraction algorithms in several large-scale neuroimaging datasets, including one from a prospective multicentric trial in neuro-oncology, yielding state-of-the-art performance with median improvements of +1.16 to +2.50 points for the Dice coefficient and -0.66 to -2.51\,mm for the Hausdorff distance. Importantly, the HD-BET algorithm, which shows robust performance in the presence of pathology or treatment-induced tissue alterations, is applicable to a broad range of MRI sequence types and is not influenced by variations in MRI hardware and acquisition parameters encountered in both research and clinical practice. For broader accessibility, the HD-BET prediction algorithm is made freely available (www.neuroAI-HD.org) and may become an essential component for robust, automated, high-throughput processing of MRI neuroimaging data.},
  langid = {english},
  pmcid = {PMC6865732},
  pmid = {31403237},
  keywords = {Algorithms,artificial neural networks,Brain,brain extraction,deep learning,Humans,Image Processing Computer-Assisted,magnetic resonance imaging,Magnetic Resonance Imaging,Neural Networks Computer,neuroimaging,Neuroimaging,skull stripping},
  file = {/home/paris/Zotero/storage/QJ8IB4RV/Isensee et al. - 2019 - Automated brain extraction of multisequence MRI using artificial neural networks.pdf}
}

@article{ishiiVoxelBasedMorphometricComparison2005,
  title = {Voxel-{{Based Morphometric Comparison Between Early-}} and {{Late-Onset Mild Alzheimer}}'s {{Disease}} and {{Assessment}} of {{Diagnostic Performance}} of {{Z Score Images}}},
  author = {Ishii, Kazunari and Kawachi, Takashi and Sasaki, Hiroki and Kono, Atsushi K and Fukuda, Tetsuya and Kojima, Yoshio and Mori, Etsuro},
  year = 2005,
  month = feb,
  journal = {AJNR: American Journal of Neuroradiology},
  volume = {26},
  number = {2},
  pages = {333--340},
  issn = {0195-6108},
  urldate = {2025-07-25},
  abstract = {BACKGROUND AND PURPOSE: Voxel-based morphometry (VBM), used for detecting brain atrophy, permits comparison of local gray matter concentration at every voxel in an image between two groups. We sought to delineate the specific patterns of cerebral gray matter loss with regard to onset of Alzheimer's disease (AD) by using MR imaging and VBM and to evaluate the diagnostic performance of VBM with Z score images., METHODS: Two groups of 30 patients with mild AD of different ages of onset were examined. Mean ages in the early- and late-onset groups were 60.2 \textpm{} 5.2 and 71.5 \textpm{} 2.6 years, respectively. Control subjects were aged-matched healthy volunteers. Regions of gray matter loss in early- and late-onset AD were examined with VBM. Diagnostic performance of Z score images obtained with the VBM method was evaluated in patients and control subjects by calculating the area under the receiver operating characteristic curve (Az)., RESULTS: Both AD groups had significantly reduced gray matter in the bilateral medial temporal regions. In addition, the early-onset group had more severe gray matter loss in the bilateral parietal and posterior cingulate cortices and precuneus region. No difference was noted in diagnostic performance of Z score images between the early- (Az = 0.9435) and late-onset (Az = 0.9018) groups., CONCLUSION: Differences were noted in the patterns of regional gray matter loss in patients with early-onset AD versus those with late-onset AD. Parietotemporal and posterior cingulate gray matter loss was found in early-onset AD but not in late-onset AD. Z score images obtained with VBM had a great diagnostic performance for mild AD and can be applied for detecting mild AD in clinical examinations.},
  pmcid = {PMC7974092},
  pmid = {15709131}
}

@article{ishiiVoxelBasedMorphometricComparison2005a,
  title = {Voxel-{{Based Morphometric Comparison Between Early-}} and {{Late-Onset Mild Alzheimer}}'s {{Disease}} and {{Assessment}} of {{Diagnostic Performance}} of {{Z Score Images}}},
  author = {Ishii, Kazunari and Kawachi, Takashi and Sasaki, Hiroki and Kono, Atsushi K and Fukuda, Tetsuya and Kojima, Yoshio and Mori, Etsuro},
  year = 2005,
  month = feb,
  journal = {AJNR: American Journal of Neuroradiology},
  volume = {26},
  number = {2},
  pages = {333--340},
  issn = {0195-6108},
  urldate = {2025-07-25},
  abstract = {BACKGROUND AND PURPOSE: Voxel-based morphometry (VBM), used for detecting brain atrophy, permits comparison of local gray matter concentration at every voxel in an image between two groups. We sought to delineate the specific patterns of cerebral gray matter loss with regard to onset of Alzheimer's disease (AD) by using MR imaging and VBM and to evaluate the diagnostic performance of VBM with Z score images., METHODS: Two groups of 30 patients with mild AD of different ages of onset were examined. Mean ages in the early- and late-onset groups were 60.2 \textpm{} 5.2 and 71.5 \textpm{} 2.6 years, respectively. Control subjects were aged-matched healthy volunteers. Regions of gray matter loss in early- and late-onset AD were examined with VBM. Diagnostic performance of Z score images obtained with the VBM method was evaluated in patients and control subjects by calculating the area under the receiver operating characteristic curve (Az)., RESULTS: Both AD groups had significantly reduced gray matter in the bilateral medial temporal regions. In addition, the early-onset group had more severe gray matter loss in the bilateral parietal and posterior cingulate cortices and precuneus region. No difference was noted in diagnostic performance of Z score images between the early- (Az = 0.9435) and late-onset (Az = 0.9018) groups., CONCLUSION: Differences were noted in the patterns of regional gray matter loss in patients with early-onset AD versus those with late-onset AD. Parietotemporal and posterior cingulate gray matter loss was found in early-onset AD but not in late-onset AD. Z score images obtained with VBM had a great diagnostic performance for mild AD and can be applied for detecting mild AD in clinical examinations.},
  pmcid = {PMC7974092},
  pmid = {15709131}
}

@article{islamBrainMRIAnalysis2018,
  title = {Brain {{MRI}} Analysis for {{Alzheimer}}'s Disease Diagnosis Using an Ensemble System of Deep Convolutional Neural Networks},
  author = {Islam, Jyoti and Zhang, Yanqing},
  year = 2018,
  month = may,
  journal = {Brain Informatics},
  volume = {5},
  number = {2},
  pages = {2},
  issn = {2198-4018},
  doi = {10.1186/s40708-018-0080-3},
  urldate = {2025-07-28},
  abstract = {Alzheimer's disease is an incurable, progressive neurological  brain disorder. Earlier detection of Alzheimer's disease can help with proper treatment and prevent brain tissue damage. Several statistical and machine learning models have been exploited by researchers for Alzheimer's disease diagnosis. Analyzing magnetic resonance imaging (MRI) is a common practice for Alzheimer's disease diagnosis in clinical research. Detection of Alzheimer's disease is exacting due to the similarity in Alzheimer's disease MRI data and standard healthy MRI data of older people. Recently, advanced deep learning techniques have successfully demonstrated human-level performance in numerous fields including medical image analysis. We propose a deep convolutional neural network for Alzheimer's disease diagnosis using brain  MRI data analysis. While most of the existing approaches perform binary classification, our model can identify different stages of Alzheimer's disease and obtains superior performance for early-stage diagnosis. We conducted ample experiments to demonstrate that our proposed model outperformed comparative baselines on the Open Access Series of Imaging Studies dataset.},
  pmcid = {PMC6170939},
  pmid = {29881892},
  file = {/home/paris/gdrive/Zotero/Islam and Zhang - 2018 - Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional.pdf}
}

@misc{ItNotAccuracy,
  title = {It Is {{Not}} ``{{Accuracy}} vs. {{Explainability}}''---{{We Need Both}} for {{Trustworthy AI Systems}} \textbar{} {{IEEE Journals}} \& {{Magazine}} \textbar{} {{IEEE Xplore}}},
  urldate = {2025-10-27},
  howpublished = {https://ieeexplore.ieee.org/document/10029927},
  file = {/home/paris/Zotero/storage/HSTZZ9F4/10029927.html}
}

@article{jackjrSerialPIBMRI2009,
  title = {Serial {{PIB}} and {{MRI}} in Normal, Mild Cognitive Impairment and {{Alzheimer}}'s Disease: Implications for Sequence of Pathological Events in {{Alzheimer}}'s Disease},
  shorttitle = {Serial {{PIB}} and {{MRI}} in Normal, Mild Cognitive Impairment and {{Alzheimer}}'s Disease},
  author = {Jack Jr, Clifford R. and Lowe, Val J. and Weigand, Stephen D. and Wiste, Heather J. and Senjem, Matthew L. and Knopman, David S. and Shiung, Maria M. and Gunter, Jeffrey L. and Boeve, Bradley F. and Kemp, Bradley J.},
  year = 2009,
  journal = {Brain},
  volume = {132},
  number = {5},
  pages = {1355--1365},
  publisher = {Oxford University Press},
  urldate = {2024-12-15},
  file = {/home/paris/Zotero/storage/WYQU3UZC/Jack Jr et al. - 2009 - Serial PIB and MRI in normal, mild cognitive impairment and Alzheimer's disease implications for se.pdf}
}

@article{jacksonIntroductionExpertSystems1986,
  title = {Introduction to Expert Systems},
  author = {Jackson, Peter},
  year = 1986,
  publisher = {Addison-Wesley Pub. Co., Reading, MA},
  urldate = {2025-08-30}
}

@article{jackUnbiasedDescriptiveClassification2016,
  title = {A/{{T}}/{{N}}: {{An}} Unbiased Descriptive Classification Scheme for {{Alzheimer}} Disease Biomarkers},
  shorttitle = {A/{{T}}/{{N}}},
  author = {Jack, Clifford R. and Bennett, David A. and Blennow, Kaj and Carrillo, Maria C. and Feldman, Howard H. and Frisoni, Giovanni B. and Hampel, Harald and Jagust, William J. and Johnson, Keith A. and Knopman, David S. and Petersen, Ronald C. and Scheltens, Philip and Sperling, Reisa A. and Dubois, Bruno},
  year = 2016,
  month = aug,
  journal = {Neurology},
  volume = {87},
  number = {5},
  pages = {539--547},
  issn = {0028-3878, 1526-632X},
  doi = {10.1212/WNL.0000000000002923},
  urldate = {2024-11-08},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Jack et al. - 2016 - ATN An unbiased descriptive classification scheme for Alzheimer disease biomarkers.pdf}
}

@article{jacobsLargeLanguageModels2024,
  title = {Large Language Models Have Divergent Effects on Self-Perceptions of Mind and the Attributes Considered Uniquely Human},
  author = {Jacobs, Oliver L. and Pazhoohi, Farid and Kingstone, Alan},
  year = 2024,
  month = sep,
  journal = {Consciousness and Cognition},
  volume = {124},
  pages = {103733},
  issn = {1053-8100},
  doi = {10.1016/j.concog.2024.103733},
  urldate = {2025-09-10},
  abstract = {The rise of powerful Large Language Models (LLMs) provides a compelling opportunity to investigate the consequences of anthropomorphism, particularly regarding how their exposure may influence the way individuals view themselves (self-perception) and other people (other-perception). Using a mind perception framework, we examined attributions of agency (the ability to do) and experience (the ability to feel). Participants evaluated their agentic and experiential capabilities and the extent to which these features are uniquely human before and after exposure to LLM responses. Post-exposure, participants increased evaluations of their agentic and experiential qualities while decreasing their perception that agency and experience are considered to be uniquely human. These results indicate that anthropomorphizing LLMs impacts attributions of mind for humans in fundamentally divergent ways: enhancing the perception of one's own mind while reducing its uniqueness for others. These results open up a range of future questions regarding how anthropomorphism can affect mind perception toward humans.}
}

@inproceedings{jainOverviewImportanceData2020,
  title = {Overview and {{Importance}} of {{Data Quality}} for {{Machine Learning Tasks}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Jain, Abhinav and Patel, Hima and Nagalapatti, Lokesh and Gupta, Nitin and Mehta, Sameep and Guttula, Shanmukha and Mujumdar, Shashank and Afzal, Shazia and Sharma Mittal, Ruhi and Munigala, Vitobha},
  year = 2020,
  month = aug,
  pages = {3561--3562},
  publisher = {ACM},
  address = {Virtual Event CA USA},
  doi = {10.1145/3394486.3406477},
  urldate = {2025-10-14},
  isbn = {978-1-4503-7998-4},
  langid = {english}
}

@incollection{japkowiczAssessmentMetricsImbalanced2013,
  title = {Assessment {{Metrics}} for {{Imbalanced Learning}}},
  booktitle = {Imbalanced {{Learning}}},
  author = {Japkowicz, Nathalie},
  editor = {He, Haibo and Ma, Yunqian},
  year = 2013,
  month = jun,
  edition = {1},
  pages = {187--206},
  publisher = {Wiley},
  doi = {10.1002/9781118646106.ch8},
  urldate = {2025-10-14},
  isbn = {978-1-118-07462-6 978-1-118-64610-6},
  langid = {english}
}

@article{japkowiczClassImbalanceProblem2002,
  title = {The Class Imbalance Problem: {{A}} Systematic Study1},
  shorttitle = {The Class Imbalance Problem},
  author = {Japkowicz, Nathalie and Stephen, Shaju},
  year = 2002,
  month = nov,
  journal = {Intelligent Data Analysis},
  volume = {6},
  number = {5},
  pages = {429--449},
  issn = {15714128, 1088467X},
  doi = {10.3233/IDA-2002-6504},
  urldate = {2025-10-14}
}

@article{jasodanandAIdrivenFusionMultimodal2025,
  title = {{{AI-driven}} Fusion of Multimodal Data for {{Alzheimer}}'s Disease Biomarker Assessment},
  author = {Jasodanand, Varuna H. and Kowshik, Sahana S. and Puducheri, Shreyas and Romano, Michael F. and Xu, Lingyi and Au, Rhoda and Kolachalama, Vijaya B.},
  year = 2025,
  month = aug,
  journal = {Nature Communications},
  volume = {16},
  number = {1},
  pages = {7407},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-025-62590-4},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease (AD) diagnosis hinges on detecting amyloid beta (A{$\beta$}) plaques and neurofibrillary tau ({$\tau$}) tangles, typically assessed using PET imaging. While accurate, these modalities are expensive and not widely accessible, limiting their utility in routine clinical practice. Here, we present a multimodal computational framework that integrates data from seven distinct cohorts comprising 12,~185 participants to estimate individual PET profiles using more readily available neurological assessments. Our approach achieved an AUROC of 0.79 and 0.84 in classifying A{$\beta$} and {$\tau$} status, respectively. Predicted PET status was consistent with various biomarker profiles and postmortem pathology, and model-identified regional brain volumes aligned with known spatial patterns of tau deposition. This approach can support scalable pre-screening of candidates for anti-amyloid therapies and clinical trials targeting A{$\beta$} and {$\tau$}, offering a practical alternative to direct PET imaging.},
  copyright = {2025 The Author(s)},
  langid = {english},
  keywords = {Alzheimer's disease,Machine learning},
  file = {/home/paris/Zotero/storage/L5QFMA2C/Jasodanand et al. - 2025 - AI-driven fusion of multimodal data for Alzheimer’s disease biomarker assessment.pdf}
}

@misc{jiangDataHeterogeneityLimits2025,
  title = {Data {{Heterogeneity Limits}} the {{Scaling Effect}} of {{Pretraining}} in {{Neural Data Transformers}}},
  author = {Jiang, Linxing Preston and Chen, Shirui and Tanumihardja, Emmanuel and Han, Xiaochuang and Shi, Weijia and {Shea-Brown}, Eric and Rao, Rajesh P. N.},
  year = 2025,
  month = oct,
  primaryclass = {New Results},
  pages = {2025.05.12.653551},
  publisher = {bioRxiv},
  issn = {2692-8205},
  doi = {10.1101/2025.05.12.653551},
  urldate = {2025-10-24},
  abstract = {A key challenge in analyzing neuroscience datasets is the profound variability they exhibit across sessions, animals, and data modalities--i.e., heterogeneity. Several recent studies have demonstrated performance gains from pretraining neural foundation models on multi-session datasets, seemingly overcoming this challenge. However, these studies typically lack fine-grained data scaling analyses. It remains unclear how different sources of heterogeneity influence model performance as the amount of pretraining data increases, and whether all sessions contribute equally to downstream performance gains. In this work, we systematically investigate how data heterogeneity impacts the scaling behavior of neural data transformers (NDTs) in neural activity prediction. We found that explicit sources of heterogeneity, such as brain region mismatches among sessions, reduced scaling benefits of neuron- and region-level activity prediction performances. For tasks that do exhibit consistent scaling, we identified implicit data heterogeneity arising from cross-session variability. Through our proposed session-selection procedure, models pretrained on as few as five selected sessions outperformed those pretrained on the entire dataset of 84 sessions. Our findings challenge the direct applicability of traditional scaling laws to neural data and suggest that prior claims of multi-session scaling benefits may be premature. This work both highlights the importance of incremental data scaling analyses and suggests new avenues toward optimally selecting pretraining data when developing foundation models on large-scale neuroscience datasets.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {\copyright{} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/paris/Zotero/storage/WURLL3WY/Jiang et al. - 2025 - Data Heterogeneity Limits the Scaling Effect of Pretraining in Neural Data Transformers.pdf}
}

@article{joDeepLearningAlzheimers2019,
  title = {Deep {{Learning}} in {{Alzheimer}}'s {{Disease}}: {{Diagnostic Classification}} and {{Prognostic Prediction Using Neuroimaging Data}}},
  shorttitle = {Deep {{Learning}} in {{Alzheimer}}'s {{Disease}}},
  author = {Jo, Taeho and Nho, Kwangsik and Saykin, Andrew J.},
  year = 2019,
  month = aug,
  journal = {Frontiers in Aging Neuroscience},
  volume = {11},
  pages = {220},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2019.00220},
  urldate = {2025-07-28},
  abstract = {Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8\% for AD classification and 83.7\% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0\% for AD classification and 84.2\% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as---omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms.},
  pmcid = {PMC6710444},
  pmid = {31481890},
  file = {/home/paris/gdrive/Zotero/Jo et al. - 2019 - Deep Learning in Alzheimer's Disease Diagnostic Classification and Prognostic Prediction Using Neur.pdf}
}

@article{joDeepLearningAlzheimers2019a,
  title = {Deep {{Learning}} in {{Alzheimer}}'s {{Disease}}: {{Diagnostic Classification}} and {{Prognostic Prediction Using Neuroimaging Data}}},
  shorttitle = {Deep {{Learning}} in {{Alzheimer}}'s {{Disease}}},
  author = {Jo, Taeho and Nho, Kwangsik and Saykin, Andrew J.},
  year = 2019,
  month = aug,
  journal = {Frontiers in Aging Neuroscience},
  volume = {11},
  pages = {220},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2019.00220},
  urldate = {2026-01-14},
  abstract = {Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8\% for AD classification and 83.7\% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0\% for AD classification and 84.2\% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as---omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms.},
  pmcid = {PMC6710444},
  pmid = {31481890},
  file = {/home/paris/Zotero/storage/Z8I4Z7UK/Jo et al. - 2019 - Deep Learning in Alzheimer's Disease Diagnostic Classification and Prognostic Prediction Using Neur.pdf}
}

@article{johnsonSurveyDeepLearning2019,
  title = {Survey on Deep Learning with Class Imbalance},
  author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
  year = 2019,
  month = dec,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {27},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0192-5},
  urldate = {2025-08-29},
  abstract = {The purpose of this study is to examine existing deep learning techniques for addressing class imbalanced data. Effective classification with imbalanced data is an important area of research, as high class imbalance is naturally inherent in many real-world applications, e.g., fraud detection and cancer detection. Moreover, highly imbalanced data poses added difficulty, as most learners will exhibit bias towards the majority class, and in extreme cases, may ignore the minority class altogether. Class imbalance has been studied thoroughly over the last two decades using traditional machine learning models, i.e. non-deep learning. Despite recent advances in deep learning, along with its increasing popularity, very little empirical work in the area of deep learning with class imbalance exists. Having achieved record-breaking performance results in several complex domains, investigating the use of deep neural networks for problems containing high levels of class imbalance is of great interest. Available studies regarding class imbalance and deep learning are surveyed in order to better understand the efficacy of deep learning when applied to class imbalanced data. This survey discusses the implementation details and experimental results for each study, and offers additional insight into their strengths and weaknesses. Several areas of focus include: data complexity, architectures tested, performance interpretation, ease of use, big data application, and generalization to other domains. We have found that research in this area is very limited, that most existing work focuses on computer vision tasks with convolutional neural networks, and that the effects of big data are rarely considered. Several traditional methods for class imbalance, e.g. data sampling and cost-sensitive learning, prove to be applicable in deep learning, while more advanced methods that exploit neural network feature learning abilities show promising results. The survey concludes with a discussion that highlights various gaps in deep learning from class imbalanced data for the purpose of guiding future research.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Johnson and Khoshgoftaar - 2019 - Survey on deep learning with class imbalance.pdf}
}

@article{johnsonSurveyDeepLearning2019a,
  title = {Survey on Deep Learning with Class Imbalance},
  author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
  year = 2019,
  month = dec,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {27},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0192-5},
  urldate = {2025-10-14},
  langid = {english},
  file = {/home/paris/Zotero/storage/KRPLEXMC/Johnson and Khoshgoftaar - 2019 - Survey on deep learning with class imbalance.pdf}
}

@article{jonathanlongFullyConvolutionalNetworks2015,
  title = {Fully Convolutional Networks for Semantic Segmentation},
  author = {{Jonathan Long} and Long, Jonathan and {Evan Shelhamer} and Shelhamer, Evan and {Trevor Darrell} and Darrell, Trevor},
  year = 2015,
  month = jun,
  pages = {3431--3440},
  doi = {10.1109/cvpr.2015.7298965},
  abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build ``fully convolutional'' networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.},
  annotation = {MAG ID: 1903029394},
  file = {/home/paris/gdrive/Zotero/Jonathan Long et al. - 2015 - Fully convolutional networks for semantic segmentation.pdf}
}

@misc{jordonSyntheticDataWhat2022,
  title = {Synthetic {{Data}} -- What, Why and How?},
  author = {Jordon, James and Szpruch, Lukasz and Houssiau, Florimond and Bottarelli, Mirko and Cherubin, Giovanni and Maple, Carsten and Cohen, Samuel N. and Weller, Adrian},
  year = 2022,
  month = may,
  number = {arXiv:2205.03257},
  eprint = {2205.03257},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.03257},
  urldate = {2025-10-31},
  abstract = {This explainer document aims to provide an overview of the current state of the rapidly expanding work on synthetic data technologies, with a particular focus on privacy. The article is intended for a non-technical audience, though some formal definitions have been given to provide clarity to specialists. This article is intended to enable the reader to quickly become familiar with the notion of synthetic data, as well as understand some of the subtle intricacies that come with it. We do believe that synthetic data is a very useful tool, and our hope is that this report highlights that, while drawing attention to nuances that can easily be overlooked in its deployment.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/paris/Zotero/storage/VLUPEZHK/Jordon et al. - 2022 - Synthetic Data -- what, why and how.pdf;/home/paris/Zotero/storage/JSWTQVSH/2205.html}
}

@article{jungBasicPhysicalPrinciples2021,
  title = {Basic {{Physical Principles}} and {{Clinical Applications}} of {{Computed Tomography}}},
  author = {Jung, Haijo},
  year = 2021,
  month = mar,
  journal = {Progress in Medical Physics},
  volume = {32},
  number = {1},
  pages = {1--17},
  publisher = {Korean Society of Medical Physics},
  doi = {10.14316/pmp.2021.32.1.1},
  urldate = {2025-03-20},
  file = {/home/paris/Zotero/storage/SL23VKC4/Jung - 2021 - Basic Physical Principles and Clinical Applications of Computed Tomography.pdf}
}

@incollection{justussonMedianFilteringStatistical1981,
  title = {Median {{Filtering}}: {{Statistical Properties}}},
  shorttitle = {Median {{Filtering}}},
  booktitle = {Two-{{Dimensional Digital Signal Prcessing II}}: {{Transforms}} and {{Median Filters}}},
  author = {Justusson, B. I.},
  year = 1981,
  pages = {161--196},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/BFb0057597},
  urldate = {2025-06-29},
  isbn = {978-3-540-38446-5},
  langid = {english}
}

@article{kaissisEndtoendPrivacyPreserving2021,
  title = {End-to-End Privacy Preserving Deep Learning on Multi-Institutional Medical Imaging},
  author = {Kaissis, Georgios and Ziller, Alexander and {Passerat-Palmbach}, Jonathan and Ryffel, Th{\'e}o and Usynin, Dmitrii and Trask, Andrew and Lima, Ion{\'e}sio and Mancuso, Jason and Jungmann, Friederike and Steinborn, Marc-Matthias and Saleh, Andreas and Makowski, Marcus and Rueckert, Daniel and Braren, Rickmer},
  year = 2021,
  month = jun,
  journal = {Nature Machine Intelligence},
  volume = {3},
  number = {6},
  pages = {473--484},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00337-8},
  urldate = {2025-06-24},
  abstract = {Using large, multi-national datasets for high-performance medical imaging AI systems requires innovation in privacy-preserving machine learning so models can train on sensitive data without requiring data transfer. Here we present PriMIA (Privacy-preserving Medical Image Analysis), a free, open-source software framework for differentially private, securely aggregated federated learning and encrypted inference on medical imaging data. We test PriMIA using a real-life case study in which an expert-level deep convolutional neural network classifies paediatric chest X-rays; the resulting model's classification performance is on par with locally, non-securely trained models. We theoretically and empirically evaluate our framework's performance and privacy guarantees, and demonstrate that the protections provided prevent the reconstruction of usable data by a gradient-based model inversion attack. Finally, we successfully employ the trained model in an end-to-end encrypted remote inference scenario using secure multi-party computation to prevent the disclosure of the data and the model.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Radiography}
}

@article{kalaiWhyLanguageModels,
  title = {Why {{Language Models Hallucinate}}},
  author = {Kalai, Adam Tauman and Nachum, Ofir and Vempala, Santosh S and Zhang, Edwin},
  abstract = {Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such ``hallucinations'' persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious---they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded---language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This ``epidemic'' of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Kalai et al. - Why Language Models Hallucinate.pdf}
}

@article{kalavathiMethodsSkullStripping2016,
  title = {Methods on {{Skull Stripping}} of {{MRI Head Scan Images}}---a {{Review}}},
  author = {Kalavathi, P. and Prasath, V. B. Surya},
  year = 2016,
  month = jun,
  journal = {Journal of Digital Imaging},
  volume = {29},
  number = {3},
  pages = {365--379},
  issn = {1618-727X},
  doi = {10.1007/s10278-015-9847-8},
  urldate = {2025-07-04},
  abstract = {The high resolution magnetic resonance (MR) brain images contain some non-brain tissues such as skin, fat, muscle, neck, and eye balls compared to the functional images namely positron emission tomography (PET), single photon emission computed tomography (SPECT), and functional magnetic resonance imaging (fMRI) which usually contain relatively less non-brain tissues. The presence of these non-brain tissues is considered as a major obstacle for automatic brain image segmentation and analysis techniques. Therefore, quantitative morphometric studies of MR brain images often require a preliminary processing to isolate the brain from extra-cranial or non-brain tissues, commonly referred to as skull stripping. This paper describes the available methods on skull stripping and an exploratory review of recent literature on the existing skull stripping methods.},
  langid = {english},
  keywords = {Brain extraction,Brain Mapping,Brain segmentation,Brain structure segmentation,Brainstem,Forensic Anthropology,Functional magnetic resonance imaging,Magnetic Resonance Imaging,Magnetoencephalography,MRI brain,Skull stripping},
  file = {/home/paris/gdrive/Zotero/Kalavathi and Prasath - 2016 - Methods on Skull Stripping of MRI Head Scan Images—a Review.pdf}
}

@article{kalavathiMethodsSkullStripping2016a,
  title = {Methods on {{Skull Stripping}} of {{MRI Head Scan Images}}---a {{Review}}},
  author = {Kalavathi, P. and Prasath, V. B. Surya},
  year = 2016,
  month = jun,
  journal = {Journal of Digital Imaging},
  volume = {29},
  number = {3},
  pages = {365--379},
  issn = {1618-727X},
  doi = {10.1007/s10278-015-9847-8},
  urldate = {2026-01-16},
  abstract = {The high resolution magnetic resonance (MR) brain images contain some non-brain tissues such as skin, fat, muscle, neck, and eye balls compared to the functional images namely positron emission tomography (PET), single photon emission computed tomography (SPECT), and functional magnetic resonance imaging (fMRI) which usually contain relatively less non-brain tissues. The presence of these non-brain tissues is considered as a major obstacle for automatic brain image segmentation and analysis techniques. Therefore, quantitative morphometric studies of MR brain images often require a preliminary processing to isolate the brain from extra-cranial or non-brain tissues, commonly referred to as skull stripping. This paper describes the available methods on skull stripping and an exploratory review of recent literature on the existing skull stripping methods.},
  langid = {english},
  keywords = {Brain extraction,Brain segmentation,Brain structure segmentation,MRI brain,Skull stripping}
}

@article{kamolovFeatureAttributionMethods2025,
  title = {Feature Attribution Methods in Machine Learning: A State-of-the-Art Review},
  shorttitle = {Feature Attribution Methods in Machine Learning},
  author = {Kamolov, Saidjon},
  year = 2025,
  month = aug,
  journal = {Annals of Mathematics and Computer Science},
  volume = {29},
  pages = {104--111},
  issn = {2789-7206},
  doi = {10.56947/amcs.v29.635},
  urldate = {2025-10-27},
  abstract = {This paper presents a state-of-the-art survey of feature attribution techniques employed in explainable AI. We organize the existing literature into a proposed taxonomy of model-agnostic and model-specific approaches. We analyze the formal definitions, mathematical formulations, usage contexts, strengths, and limitations of these methods. A comparative analysis highlights key trade-offs concerning model agnosticism, explanation form, computational cost, and fidelity to the model. We find that while model-agnostic techniques offer broad applicability by treating models as oracles, often at a higher computational cost, model-specific methods leverage internal model architecture or gradients for potentially more efficient and faithful explanations, albeit with reduced generality.},
  copyright = {Copyright (c) 2025 Annals of Mathematics and Computer Science},
  langid = {english},
  keywords = {deep learning,explainable AI,feature attribution,feature selection},
  file = {/home/paris/Zotero/storage/YA8I2HQE/Kamolov - 2025 - Feature attribution methods in machine learning a state-of-the-art review.pdf}
}

@article{kantarciNeuroimagingAlzheimerDisease2003,
  title = {Neuroimaging in {{Alzheimer}} Disease: An Evidence-Based Review},
  shorttitle = {Neuroimaging in {{Alzheimer}} Disease},
  author = {Kantarci, Kejal and Jack, Clifford R.},
  year = 2003,
  journal = {Neuroimaging Clinics},
  volume = {13},
  number = {2},
  pages = {197--209},
  publisher = {Elsevier},
  urldate = {2024-11-09}
}

@article{karensimonyanVeryDeepConvolutional2014,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {{Karen Simonyan} and {Karen Simonyan} and Simonyan, Karen and {Andrew Zisserman} and Zisserman, Andrew},
  year = 2014,
  month = sep,
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  annotation = {MAG ID: 1686810756}
}

@inproceedings{kastnerRelationTrustExplainability2021,
  title = {On the {{Relation}} of {{Trust}} and {{Explainability}}: {{Why}} to {{Engineer}} for {{Trustworthiness}}},
  shorttitle = {On the {{Relation}} of {{Trust}} and {{Explainability}}},
  booktitle = {2021 {{IEEE}} 29th {{International Requirements Engineering Conference Workshops}} ({{REW}})},
  author = {K{\"a}stner, Lena and Langer, Markus and Lazar, Veronika and Schom{\"a}cker, Astrid and Speith, Timo and Sterz, Sarah},
  year = 2021,
  month = sep,
  pages = {169--175},
  doi = {10.1109/REW53955.2021.00031},
  urldate = {2025-09-09},
  abstract = {Recently, requirements for the explainability of software systems have gained prominence. One of the primary motivators for such requirements is that explainability is expected to facilitate stakeholders' trust in a system. Although this seems intuitively appealing, recent psychological studies indicate that explanations do not necessarily facilitate trust. Thus, explainability requirements might not be suitable for promoting trust.One way to accommodate this finding is, we suggest, to focus on trustworthiness instead of trust. While these two may come apart, we ideally want both: a trustworthy system and the stakeholder's trust. In this paper, we argue that even though trustworthiness does not automatically lead to trust, there are several reasons to engineer primarily for trustworthiness -- and that a system's explainability can crucially contribute to its trustworthiness.},
  keywords = {Conferences,Explainability,NFR,Psychology,Requirements,Requirements engineering,Software systems,Stakeholders,Trust,Trustworthiness,XAI},
  file = {/home/paris/gdrive/Zotero/Kästner et al. - 2021 - On the Relation of Trust and Explainability Why to Engineer for Trustworthiness.pdf;/home/paris/Zotero/storage/9ENFARDX/9582305.html}
}

@misc{kastnerRelationTrustExplainability2021a,
  title = {On the {{Relation}} of {{Trust}} and {{Explainability}}: {{Why}} to {{Engineer}} for {{Trustworthiness}}},
  shorttitle = {On the {{Relation}} of {{Trust}} and {{Explainability}}},
  author = {K{\"a}stner, Lena and Langer, Markus and Lazar, Veronika and Schom{\"a}cker, Astrid and Speith, Timo and Sterz, Sarah},
  year = 2021,
  month = aug,
  number = {arXiv:2108.05379},
  eprint = {2108.05379},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2108.05379},
  urldate = {2025-10-27},
  abstract = {Recently, requirements for the explainability of software systems have gained prominence. One of the primary motivators for such requirements is that explainability is expected to facilitate stakeholders' trust in a system. Although this seems intuitively appealing, recent psychological studies indicate that explanations do not necessarily facilitate trust. Thus, explainability requirements might not be suitable for promoting trust. One way to accommodate this finding is, we suggest, to focus on trustworthiness instead of trust. While these two may come apart, we ideally want both: a trustworthy system and the stakeholder's trust. In this paper, we argue that even though trustworthiness does not automatically lead to trust, there are several reasons to engineer primarily for trustworthiness -- and that a system's explainability can crucially contribute to its trustworthiness.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Software Engineering},
  file = {/home/paris/Zotero/storage/422H5BMS/Kästner et al. - 2021 - On the Relation of Trust and Explainability Why to Engineer for Trustworthiness.pdf;/home/paris/Zotero/storage/5NWRCYCT/2108.html}
}

@article{keEffectResamplingTechniques2024,
  title = {The Effect of Resampling Techniques on the Performances of Machine Learning Clinical Risk Prediction Models in the Setting of Severe Class Imbalance: Development and Internal Validation in a Retrospective Cohort},
  shorttitle = {The Effect of Resampling Techniques on the Performances of Machine Learning Clinical Risk Prediction Models in the Setting of Severe Class Imbalance},
  author = {Ke, Janny Xue Chen and DhakshinaMurthy, Arunachalam and George, Ronald B. and Branco, Paula},
  year = 2024,
  month = nov,
  journal = {Discover Artificial Intelligence},
  volume = {4},
  number = {1},
  pages = {91},
  issn = {2731-0809},
  doi = {10.1007/s44163-024-00199-0},
  urldate = {2025-09-27},
  abstract = {The availability of population datasets and machine learning techniques heralded a new era of sophisticated prediction models involving a large number of routinely collected variables. However, severe class imbalance in clinical datasets is a major challenge. The aim of this study is to investigate the impact of commonly-used resampling techniques in combination with commonly-used machine learning algorithms in a clinical dataset, to determine whether combination(s) of these approaches improve upon the original multivariable logistic regression with no resampling.},
  langid = {english},
  keywords = {Anesthesiology,Class imbalance,Machine learning,Predictive modeling,Resampling,Risk prediction},
  file = {/home/paris/gdrive/Zotero/Ke et al. - 2024 - The effect of resampling techniques on the performances of machine learning clinical risk prediction.pdf}
}

@article{kerDeepLearningApplications2018,
  title = {Deep {{Learning Applications}} in {{Medical Image Analysis}}},
  author = {Ker, Justin and Wang, Lipo and Rao, Jai and Lim, Tchoyoson},
  year = 2018,
  journal = {IEEE Access},
  volume = {6},
  pages = {9375--9389},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2017.2788044},
  urldate = {2025-06-24},
  abstract = {The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.},
  keywords = {Convolution,Convolutional neural networks,deep learning,Image analysis,machine learning,Machine learning algorithms,Medical diagnostic imaging,medical image analysis},
  file = {/home/paris/gdrive/Zotero/Ker et al. - 2018 - Deep Learning Applications in Medical Image Analysis.pdf}
}

@article{khagi3DCNNDesign2020,
  title = {{{3D CNN Design}} for the {{Classification}} of {{Alzheimer}}'s {{Disease Using Brain MRI}} and {{PET}}},
  author = {Khagi, Bijen and Kwon, Goo-Rak},
  year = 2020,
  journal = {IEEE Access},
  volume = {8},
  pages = {217830--217847},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3040486},
  urldate = {2025-08-19},
  abstract = {Attempt to diagnose Alzheimer's disease (AD) using imaging modalities is one of the scopes of deep learning. While considering the theoretical background from past studies, we are trying to identify convolutional neural network (CNN) behaviors moving from 2D to 3D architecture. This study aims to explore the output from a variety of CNN models implemented in the MRI or/and PET classification tasks for AD prediction while trying to summarize its characteristics with a variety of parameters that are tuned and changed. There are many architectures available; however, we are testing a basic architecture with a change in the reception area based on the convolutional layer's kernel size and its strides. The architecture has been categorized as converging, diverging, or equivalent if the filter kernel size is unchanged. This investigation studies a simple encoder based CNN with a sequential flow of features from low-level to high-level feature extraction. The idea is to present a diverging reception area by increasing the filter size and stride from a lower to a higher level. As a result, the feature redundancy is reduced and the trivial features keep on diminishing. The proposed architecture is referred to as `divNet', and several experiments were performed to determine how effective the architecture is in terms of the consumed memory, the number of parameters, running time, classification error, and the generalization error. This study surveys several related experiments by changing the hyper-parameters setting, the architecture selection based on the depth and area of the reception feature, and the data size.},
  keywords = {3D CNN,Alzheimer's disease,Brain,CNN architecture,Computer architecture,data size,Feature extraction,feature redundancy,Magnetic resonance imaging,MRI classification,Neurons,reception area,Three-dimensional displays,Two dimensional displays},
  file = {/home/paris/gdrive/Zotero/Khagi and Kwon - 2020 - 3D CNN Design for the Classification of Alzheimer’s Disease Using Brain MRI and PET.pdf}
}

@article{khojaste-sarakhsiDeepLearningAlzheimers2022,
  title = {Deep Learning for {{Alzheimer}}'s Disease Diagnosis: {{A}} Survey},
  shorttitle = {Deep Learning for {{Alzheimer}}'s Disease Diagnosis},
  author = {{Khojaste-Sarakhsi}, M. and Haghighi, Seyedhamidreza Shahabi and Ghomi, S. M. T. Fatemi and Marchiori, Elena},
  year = 2022,
  month = aug,
  journal = {Artificial Intelligence in Medicine},
  volume = {130},
  pages = {102332},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2022.102332},
  urldate = {2025-06-09},
  abstract = {Alzheimer's Disease (AD) is an irreversible neurodegenerative disease that results in a progressive decline in cognitive abilities. Since AD starts several years before the onset of the symptoms, its early detection is challenging due to subtle changes in biomarkers mainly detectable in different neuroimaging modalities. Developing computer-aided diagnostic models based on deep learning can provide excellent opportunities for the analysis of different neuroimage modalities along with other non-image biomarkers. In this survey, we perform a comparative analysis of about 100 published papers since 2019 that employ basic deep architectures such as CNN, RNN, and generative models for AD diagnosis. Moreover, about 60 papers that have applied a trending topic or architecture for AD are investigated. Explainable models, normalizing flows, graph-based deep architectures, self-supervised learning, and attention mechanisms are considered. The main challenges in this body of literature have been categorized and explained from data-related, methodology-related, and clinical adoption aspects. We conclude our paper by addressing some future perspectives and providing recommendations to conduct further studies for AD diagnosis.},
  keywords = {Alzheimer's disease diagnosis,Convolutional neural networks,Deep learning,Deep neural networks,Generative networks,Recurrent neural networks}
}

@inproceedings{kimImNotSure2024,
  title = {"{{I}}'m {{Not Sure}}, {{But}}...": {{Examining}} the {{Impact}} of {{Large Language Models}}' {{Uncertainty Expression}} on {{User Reliance}} and {{Trust}}},
  shorttitle = {"{{I}}'m {{Not Sure}}, {{But}}..."},
  booktitle = {Proceedings of the 2024 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Kim, Sunnie S. Y. and Liao, Q. Vera and Vorvoreanu, Mihaela and Ballard, Stephanie and Vaughan, Jennifer Wortman},
  year = 2024,
  month = jun,
  series = {{{FAccT}} '24},
  pages = {822--835},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3630106.3658941},
  urldate = {2025-09-10},
  abstract = {Widely deployed large language models (LLMs) can produce convincing yet incorrect outputs, potentially misleading users who may rely on them as if they were correct. To reduce such overreliance, there have been calls for LLMs to communicate their uncertainty to end users. However, there has been little empirical work examining how users perceive and act upon LLMs' expressions of uncertainty. We explore this question through a large-scale, pre-registered, human-subject experiment (N=404) in which participants answer medical questions with or without access to responses from a fictional LLM-infused search engine. Using both behavioral and self-reported measures, we examine how different natural language expressions of uncertainty impact participants' reliance, trust, and overall task performance. We find that first-person expressions (e.g., ``I'm not sure, but...'') decrease participants' confidence in the system and tendency to agree with the system's answers, while increasing participants' accuracy. An exploratory analysis suggests that this increase can be attributed to reduced (but not fully eliminated) overreliance on incorrect answers. While we observe similar effects for uncertainty expressed from a general perspective (e.g., ``It's not clear, but...''), these effects are weaker and not statistically significant. Our findings suggest that using natural language expressions of uncertainty may be an effective approach for reducing overreliance on LLMs, but that the precise language used matters. This highlights the importance of user testing before deploying LLMs at scale.},
  isbn = {979-8-4007-0450-5},
  file = {/home/paris/gdrive/Zotero/Kim et al. - 2024 - I'm Not Sure, But... Examining the Impact of Large Language Models' Uncertainty Expression on Use.pdf}
}

@article{kleesiekDeepMRIBrain2016,
  title = {Deep {{MRI}} Brain Extraction: {{A 3D}} Convolutional Neural Network for Skull Stripping},
  shorttitle = {Deep {{MRI}} Brain Extraction},
  author = {Kleesiek, Jens and Urban, Gregor and Hubert, Alexander and Schwarz, Daniel and {Maier-Hein}, Klaus and Bendszus, Martin and Biller, Armin},
  year = 2016,
  month = apr,
  journal = {NeuroImage},
  volume = {129},
  pages = {460--469},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2016.01.024},
  abstract = {Brain extraction from magnetic resonance imaging (MRI) is crucial for many neuroimaging workflows. Current methods demonstrate good results on non-enhanced T1-weighted images, but struggle when confronted with other modalities and pathologically altered tissue. In this paper we present a 3D convolutional deep learning architecture to address these shortcomings. In contrast to existing methods, we are not limited to non-enhanced T1w images. When trained appropriately, our approach handles an arbitrary number of modalities including contrast-enhanced scans. Its applicability to MRI data, comprising four channels: non-enhanced and contrast-enhanced T1w, T2w and FLAIR contrasts, is demonstrated on a challenging clinical data set containing brain tumors (N=53), where our approach significantly outperforms six commonly used tools with a mean Dice score of 95.19. Further, the proposed method at least matches state-of-the-art performance as demonstrated on three publicly available data sets: IBSR, LPBA40 and OASIS, totaling N=135 volumes. For the IBSR (96.32) and LPBA40 (96.96) data set the convolutional neuronal network (CNN) obtains the highest average Dice scores, albeit not being significantly different from the second best performing method. For the OASIS data the second best Dice (95.02) results are achieved, with no statistical difference in comparison to the best performing tool. For all data sets the highest average specificity measures are evaluated, whereas the sensitivity displays about average results. Adjusting the cut-off threshold for generating the binary masks from the CNN's probability output can be used to increase the sensitivity of the method. Of course, this comes at the cost of a decreased specificity and has to be decided application specific. Using an optimized GPU implementation predictions can be achieved in less than one minute. The proposed method may prove useful for large-scale studies and clinical trials.},
  langid = {english},
  pmid = {26808333},
  keywords = {Brain extraction,Brain mask,Brain Neoplasms,Convolutional networks,Deep learning,Humans,Image Enhancement,Image Interpretation Computer-Assisted,Imaging Three-Dimensional,Machine Learning,Magnetic Resonance Imaging,MRI,Neural Networks Computer,Neuroimaging,Skull,Skull stripping}
}

@article{kociolekDoesImageNormalization2020,
  title = {Does Image Normalization and Intensity Resolution Impact Texture Classification?},
  author = {Kocio{\l}ek, Marcin and Strzelecki, Micha{\l} and Obuchowicz, Rafa{\l}},
  year = 2020,
  month = apr,
  journal = {Computerized Medical Imaging and Graphics},
  volume = {81},
  pages = {101716},
  issn = {0895-6111},
  doi = {10.1016/j.compmedimag.2020.101716},
  urldate = {2025-06-15},
  abstract = {Image texture is a very important component in many types of images, including medical images. Medical images are often corrupted by noise and affected by artifacts. Some of the texture-based features that should describe the structure of the tissue under examination may also reflect, for example, the uneven sensitivity of the scanner within the tissue region. This in turn may lead to an inappropriate description of the tissue or incorrect classification. To limit these phenomena, the analyzed regions of interest are normalized. In texture analysis methods, image intensity normalization is usually followed by a reduction in the number of levels coding the intensity. The aim of this work was to analyze the impact of different image normalization methods and the number of intensity levels on texture classification, taking into account noise and artifacts related to uneven background brightness distribution. Analyses were performed on four sets of images: modified Brodatz textures, kidney images obtained by means of dynamic contrast-enhanced magnetic resonance imaging, shoulder images acquired as T2-weighted magnetic resonance images and CT heart and thorax images. The results will be of use for choosing a particular method of image normalization, based on the types of noise and distortion present in the images.},
  keywords = {Image procession,Normalization,Texture features},
  annotation = {GSCC: 0000116 2025-06-15T15:47:20.339Z 0.43}
}

@article{koetzierGeneratingSyntheticData2024,
  title = {Generating {{Synthetic Data}} for {{Medical Imaging}}},
  author = {Koetzier, Lennart R. and Wu, Jie and Mastrodicasa, Domenico and Lutz, Aline and Chung, Matthew and Koszek, W. Adam and Pratap, Jayanth and Chaudhari, Akshay S. and Rajpurkar, Pranav and Lungren, Matthew P. and Willemink, Martin J.},
  year = 2024,
  month = sep,
  journal = {Radiology},
  volume = {312},
  number = {3},
  pages = {e232471},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.232471},
  urldate = {2025-11-04},
  abstract = {Synthetic data can address data scarcity and privacy issues, but generating realistic, identity-free medical images remains a challenge; adequate legislation with clinician involvement is necessary to ensure responsible use and clinical relevance and trust.           ,              Artificial intelligence (AI) models for medical imaging tasks, such as classification or segmentation, require large and diverse datasets of images. However, due to privacy and ethical issues, as well as data sharing infrastructure barriers, these datasets are scarce and difficult to assemble. Synthetic medical imaging data generated by AI from existing data could address this challenge by augmenting and anonymizing real imaging data. In addition, synthetic data enable new applications, including modality translation, contrast synthesis, and professional training for radiologists. However, the use of synthetic data also poses technical and ethical challenges. These challenges include ensuring the realism and diversity of the synthesized images while keeping data unidentifiable, evaluating the performance and generalizability of models trained on synthetic data, and high computational costs. Since existing regulations are not sufficient to guarantee the safe and ethical use of synthetic images, it becomes evident that updated laws and more rigorous oversight are needed. Regulatory bodies, physicians, and AI developers should collaborate to develop, maintain, and continually refine best practices for synthetic data. This review aims to provide an overview of the current knowledge of synthetic data in medical imaging and highlights current key challenges in the field to guide future research and development.             \copyright{} RSNA, 2024},
  langid = {english},
  file = {/home/paris/Zotero/storage/Y9YRZMDL/Koetzier et al. - 2024 - Generating Synthetic Data for Medical Imaging.pdf}
}

@inproceedings{konidarisGenerativeAdversarialNetworks2019,
  title = {Generative {{Adversarial Networks}} as an {{Advanced Data Augmentation Technique}} for {{MRI Data}}:},
  shorttitle = {Generative {{Adversarial Networks}} as an {{Advanced Data Augmentation Technique}} for {{MRI Data}}},
  booktitle = {Proceedings of the 14th {{International Joint Conference}} on {{Computer Vision}}, {{Imaging}} and {{Computer Graphics Theory}} and {{Applications}}},
  author = {Konidaris, Filippos and Tagaris, Thanos and Sdraka, Maria and Stafylopatis, Andreas},
  year = 2019,
  pages = {48--59},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {Prague, Czech Republic},
  doi = {10.5220/0007363900480059},
  urldate = {2025-08-20},
  abstract = {This paper presents a new methodology for data augmentation through the use of Generative Adversarial Networks. Traditional augmentation strategies are severely limited, especially in tasks where the images follow strict standards, as is the case in medical datasets. Experiments conducted on the ADNI dataset prove that augmentation through GANs outperforms traditional methods by a large margin, based both on the validation accuracy and the models' generalization capability on a holdout test set. Although traditional data augmentation did not seem to aid the classification process in any way, by adding GAN-based augmentation an increase of 11.68\% in accuracy was achieved. Furthermore, by combining traditional with GAN-based augmentation schemes, even higher accuracies can be reached.},
  isbn = {978-989-758-354-4},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Konidaris et al. - 2019 - Generative Adversarial Networks as an Advanced Data Augmentation Technique for MRI Data.pdf}
}

@article{krishnanEnhancingBrainTumor2024,
  title = {Enhancing Brain Tumor Detection in {{MRI}} with a Rotation Invariant {{Vision Transformer}}},
  author = {Krishnan, Palani Thanaraj and Krishnadoss, Pradeep and Khandelwal, Mukund and Gupta, Devansh and Nihaal, Anupoju and Kumar, T. Sunil},
  year = 2024,
  month = jun,
  journal = {Frontiers in Neuroinformatics},
  volume = {18},
  publisher = {Frontiers},
  issn = {1662-5196},
  doi = {10.3389/fninf.2024.1414925},
  urldate = {2025-08-20},
  abstract = {The Rotational Invariant Vision Transformer (RViT) is introduced in this research, a deep learning model specifically designed for the classification of brain tumors using MRI scans. RViT integrates rotated patch embeddings to improve the accuracy of brain tumor identification. When assessed on the Brain Tumor MRI Dataset from Kaggle, RViT displays superior performance in terms of sensitivity (1.0), specificity (0.975), F1-score (0.984), Matthew's Correlation Coefficient (MCC) (0.972), and attains an overall accuracy of 0.986. These findings not only surpass the standard Vision Transformer model but also outperform several techniques, signifying its effectiveness in the realm of medical imaging. The study affirms that the inclusion of rotational patch embeddings enhances the model's ability to handle diverse orientations, a common challenge in tumor imaging. Our results show that the specialized architecture and rotational invariance approach of RViT could enhance existing methodologies for brain tumor detection, with potential expansions to other intricate imaging tasks.},
  langid = {english},
  keywords = {Brain tumor classification,deep learning,MRI,Rotated Patch Embeddings,rotational invariance,vision transformers},
  file = {/home/paris/gdrive/Zotero/Krishnan et al. - 2024 - Enhancing brain tumor detection in MRI with a rotation invariant Vision Transformer.pdf}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  year = 2012,
  volume = {25},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-11-04},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\textbackslash\% and 18.9\textbackslash\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/home/paris/Zotero/storage/MZKLTZHR/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf}
}

@article{kruggelImpactScannerHardware2010,
  title = {Impact of Scanner Hardware and Imaging Protocol on Image Quality and Compartment Volume Precision in the {{ADNI}} Cohort},
  author = {Kruggel, Frithjof and Turner, Jessica and Muftuler, L. Tugan and Initiative, Alzheimer's Disease Neuroimaging},
  year = 2010,
  journal = {Neuroimage},
  volume = {49},
  number = {3},
  pages = {2123--2133},
  publisher = {Elsevier},
  urldate = {2025-10-15},
  file = {/home/paris/Zotero/storage/SB8TQB6M/Kruggel et al. - 2010 - Impact of scanner hardware and imaging protocol on image quality and compartment volume precision in.pdf}
}

@misc{kukackaRegularizationDeepLearning2017,
  title = {Regularization for {{Deep Learning}}: {{A Taxonomy}}},
  shorttitle = {Regularization for {{Deep Learning}}},
  author = {Kuka{\v c}ka, Jan and Golkov, Vladimir and Cremers, Daniel},
  year = 2017,
  month = oct,
  number = {arXiv:1710.10686},
  eprint = {1710.10686},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1710.10686},
  urldate = {2025-11-04},
  abstract = {Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/paris/Zotero/storage/6KBS6ENK/Kukačka et al. - 2017 - Regularization for Deep Learning A Taxonomy.pdf;/home/paris/Zotero/storage/RREV3LLV/1710.html}
}

@incollection{kumarAlzheimerDisease2025,
  title = {Alzheimer {{Disease}}},
  booktitle = {{{StatPearls}}},
  author = {Kumar, Anil and Sidhu, Jaskirat and Lui, Forshing and Tsao, Jack W.},
  year = 2025,
  publisher = {StatPearls Publishing},
  address = {Treasure Island (FL)},
  urldate = {2025-08-13},
  abstract = {Dementia is a general term used to describe a significant decline in cognitive ability that interferes with a person's activities of daily living. Alzheimer disease (AD) is the most prevalent type of dementia, accounting for at least two-thirds of cases in~individuals aged 65 and older.~AD is a neurodegenerative~condition with insidious onset and~progressive impairment of behavioral and cognitive functions. These functions~include memory, comprehension, language, attention, reasoning, and judgment. While~AD does not directly cause death, it~substantially~raises vulnerability to other complications,~which can eventually lead~to a person's death.~ According to~Centers for Disease Control and Prevention (CDC) data,~AD is ranked as the seventh leading cause of death in the United States in 2022,~while COVID-19~ranked fourth. Before the COVID-19 pandemic, AD was the sixth leading cause of death following stroke.. AD typically manifests~after age 65, referred to as late-onset AD (LOAD). However, early-onset AD (EOAD), occurring before 65, is less common~and seen in about 5\% of~AD patients. EOAD often~exhibits~atypical symptoms, and its diagnosis is usually delayed,~leading to a more aggressive disease course.~ Significant~progress~has been made in developing biomarkers for specific and early diagnosis of AD over the past decade. These biomarkers include neuroimaging markers obtained through amyloid and tau PET scans, cerebrospinal fluid (CSF), and plasma markers, such as amyloid, tau, and phospho-tau levels. There is no cure for~AD, although there are treatments available that may~alleviate and manage some of its symptoms. In recent years, there have been significant advancements in the development of medications that aim to moderate the progression of the disease, particularly with the discovery of new disease biomarkers. The symptoms of~AD can vary depending on the stage of the disease.~AD is classified into different stages based on the level of cognitive impairment and disability experienced by individuals. These stages include the preclinical or presymptomatic stage, mild cognitive impairment, and dementia stage. The dementia stage is further divided into mild, moderate, and severe stages~(see Graph. AD Stages from Preclinical to Severe Disease). This staging system is distinct from the diagnostic criteria outlined in the Diagnostic and Statistical Manual of Mental Disorders, 5th edition (DSM-5) for AD. Episodic short-term memory loss is the initial and most common presenting symptom of~typical AD. Individuals may have difficulty retaining new information while still~recalling long-term memories. Individuals may experience problem-solving, judgment, executive functioning,~and organizational skills impairments following short-term memory loss.~ They may struggle with tasks that require~multitasking and abstract thinking. In the early stages of the disease,~executive functioning impairments can range~from subtle to significant. Instrumental activities of daily living such as driving, financial management, cooking, and detailed~activity planning are affected relatively early in their dementia. These early signs of cognitive decline are followed~by language disorder and impaired visuospatial skills. Neuropsychiatric symptoms like apathy, social withdrawal, disinhibition, agitation, psychosis, and wandering are also common in the moderate to late stages. Difficulty performing learned motor tasks (dyspraxia), olfactory dysfunction, sleep disturbances, and extrapyramidal motor signs like dystonia, akathisia, and Parkinsonian symptoms occur late in the disease. Primitive reflexes, incontinence, and total dependence on caregivers follow this.},
  copyright = {Copyright \copyright{} 2025, StatPearls Publishing LLC.},
  langid = {english},
  lccn = {NBK499922},
  pmid = {29763097},
  file = {/home/paris/Zotero/storage/M44LBB9H/NBK499922.html}
}

@article{kumarAnalyzingHeterogeneityAlzheimer2024,
  title = {Analyzing Heterogeneity in {{Alzheimer Disease}} Using Multimodal Normative Modeling on Imaging-Based {{ATN}} Biomarkers},
  author = {Kumar, Sayantan and Earnest, Tom and Yang, Braden and Kothapalli, Deydeep and Aschenbrenner, Andrew J. and Hassenstab, Jason and Xiong, Chengie and Ances, Beau and Morris, John and Benzinger, Tammie L. S. and Gordon, Brian A. and Payne, Philip and Sotiras, Aristeidis},
  year = 2024,
  month = jun,
  journal = {bioRxiv},
  pages = {2023.08.15.553412},
  issn = {2692-8205},
  doi = {10.1101/2023.08.15.553412},
  urldate = {2026-01-14},
  abstract = {INTRODUCTION: Previous studies have applied normative modeling on a single neuroimaging modality to investigate Alzheimer Disease (AD) heterogeneity. We employed a deep learning-based multimodal normative framework to analyze individual-level variation across ATN (amyloid-tau-neurodegeneration) imaging biomarkers. METHODS: We selected cross-sectional discovery (n = 665) and replication cohorts (n = 430) with available T1-weighted MRI, amyloid and tau PET. Normative modeling estimated individual-level abnormal deviations in amyloid-positive individuals compared to amyloid-negative controls. Regional abnormality patterns were mapped at different clinical group levels to assess intra-group heterogeneity. An individual-level disease severity index (DSI) was calculated using both the spatial extent and magnitude of abnormal deviations across ATN. RESULTS: Greater intra-group heterogeneity in ATN abnormality patterns was observed in more severe clinical stages of AD. Higher DSI was associated with worse cognitive function and increased risk of disease progression. DISCUSSION: Subject-specific abnormality maps across ATN reveal the heterogeneous impact of AD on the brain.},
  pmcid = {PMC10473626},
  pmid = {37662280},
  file = {/home/paris/Zotero/storage/RGU87G9D/Kumar et al. - 2024 - Analyzing heterogeneity in Alzheimer Disease using multimodal normative modeling on imaging-based AT.pdf}
}

@inproceedings{labbihiAttentionMechanismsVs2025,
  title = {Attention {{Mechanisms}} vs. {{Frequency}} Filters in {{Medical Image Segmentation}}: A {{Comparative Study}}},
  shorttitle = {Attention {{Mechanisms}} vs. {{Frequency}} Filters in {{Medical Image Segmentation}}},
  booktitle = {Proceedings of the 2024 8th {{International Conference}} on {{Advances}} in {{Artificial Intelligence}}},
  author = {Labbihi, Ismayl and El Meslouhi, Othmane and Benaddy, Mohamed and Elamrani Abou Elassad, Zouhair and Kardouchi, Mustapha and Akhloufi, Moulay},
  year = 2025,
  month = mar,
  series = {{{ICAAI}} '24},
  pages = {315--321},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3704137.3704167},
  urldate = {2025-06-24},
  abstract = {Detecting and identifying tumors and cancers in the medical field is extremely important and complex, especially when using machines for this task. Traditional methods have shown limitations in medical imaging, prompting a shift towards deep learning methods like convolutional neural networks (CNNs). While CNNs proved great superiority in effectively extracting local features, they struggle to retain the global context. To address this problem and preserve the global context in natural language programs first, then in computer vision, transformers have emerged as an alternative relying on self-attention. However, transformers also face challenges in capturing fine details and suffer from high computational costs. In previous work, we proposed a novel technique that combines CNNs and frequency transformer to overcome these challenges. In that work, we change self-attention of transformer with the frequency filters based on Fast Fourier Transform (FFT) to minimize computational costs while preserving both global and local context. In this study, We will compare the effectiveness of using self-attention and the Frequency Filters in transformers by robustly comparing their results in medical image segmentation, providing insights into their potential for improvement.},
  isbn = {979-8-4007-1801-4}
}

@article{larkmanParallelMagneticResonance2007,
  title = {Parallel Magnetic Resonance Imaging},
  author = {Larkman, David J. and Nunes, Rita G.},
  year = 2007,
  journal = {Physics in Medicine \& Biology},
  volume = {52},
  number = {7},
  pages = {R15},
  publisher = {IOP Publishing},
  urldate = {2025-06-27},
  file = {/home/paris/gdrive/Zotero/Denosing/Larkman and Nunes - 2007 - Parallel magnetic resonance imaging.pdf}
}

@article{larosaStateArtVisual2023,
  title = {State of the {{Art}} of {{Visual Analytics}} for {{eXplainable Deep Learning}}},
  author = {La Rosa, B. and Blasilli, G. and Bourqui, R. and Auber, D. and Santucci, G. and Capobianco, R. and Bertini, E. and Giot, R. and Angelini, M.},
  year = 2023,
  month = feb,
  journal = {Computer Graphics Forum},
  volume = {42},
  number = {1},
  pages = {319--355},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.14733},
  urldate = {2025-06-24},
  abstract = {Abstract                            The use and creation of machine-learning-based solutions to solve problems or reduce their computational costs are becoming increasingly widespread in many domains. Deep Learning plays a large part in this growth. However, it has drawbacks such as a lack of explainability and behaving as a black-box model. During the last few years, Visual Analytics has provided several proposals to cope with these drawbacks, supporting the emerging eXplainable Deep Learning field. This survey aims to (i) systematically report the contributions of Visual Analytics for eXplainable Deep Learning; (ii) spot gaps and challenges; (iii) serve as an anthology of visual analytical solutions ready to be exploited and put into operation by the Deep Learning community (architects, trainers and end users) and (iv) prove the degree of maturity, ease of integration and results for specific domains. The survey concludes by identifying future research challenges and bridging activities that are helpful to strengthen the role of Visual Analytics as effective support for eXplainable Deep Learning and to foster the adoption of Visual Analytics solutions in the eXplainable Deep Learning community. An interactive explorable version of this survey is available online at               https://aware-diag-sapienza.github.io/VA4XDL               .},
  langid = {english}
}

@article{lazliImprovedAlzheimerDisease2025,
  title = {Improved {{Alzheimer Disease Diagnosis With}} a {{Machine Learning Approach}} and {{Neuroimaging}}: {{Case Study Development}}},
  shorttitle = {Improved {{Alzheimer Disease Diagnosis With}} a {{Machine Learning Approach}} and {{Neuroimaging}}},
  author = {Lazli, Lilia},
  year = 2025,
  month = apr,
  journal = {JMIRx Med},
  volume = {6},
  pages = {e60866},
  issn = {2563-6316},
  doi = {10.2196/60866},
  urldate = {2025-08-15},
  abstract = {Background Alzheimer disease (AD) is a severe neurological brain disorder. While not curable, earlier detection can help improve symptoms substantially. Machine learning (ML) models are popular and well suited for medical image processing tasks such as computer-aided diagnosis. These techniques can improve the process for an accurate diagnosis of AD. Objective In this paper, a complete computer-aided diagnosis system for the diagnosis of AD has been presented. We investigate the performance of some of the most used ML techniques for AD detection and classification using neuroimages from the Open Access Series of Imaging Studies (OASIS) and Alzheimer's Disease Neuroimaging Initiative (ADNI) datasets. Methods The system uses artificial neural networks (ANNs) and support vector machines (SVMs) as classifiers, and dimensionality reduction techniques as feature extractors. To retrieve features from the neuroimages, we used principal component analysis (PCA), linear discriminant analysis, and t-distributed stochastic neighbor embedding. These features are fed into feedforward neural networks (FFNNs) and SVM-based ML classifiers. Furthermore, we applied the vision transformer (ViT)--based ANNs in conjunction with data augmentation to distinguish patients with AD from healthy controls. Results Experiments were performed on magnetic resonance imaging and positron emission tomography scans. The OASIS dataset included a total of 300 patients, while the ADNI dataset included 231 patients. For OASIS, 90 (30\%) patients were healthy and 210 (70\%) were severely impaired by AD. Likewise for the ADNI database, a total of 149 (64.5\%) patients with AD were detected and 82 (35.5\%) patients were used as healthy controls. An important difference was established between healthy patients and patients with AD (P=.02). We examined the effectiveness of the three feature extractors and classifiers using 5-fold cross-validation and confusion matrix--based standard classification metrics, namely, accuracy, sensitivity, specificity, precision, F1-score, and area under the receiver operating characteristic curve (AUROC). Compared with the state-of-the-art performing methods, the success rate was satisfactory for all the created ML models, but SVM and FFNN performed best with the PCA extractor, while the ViT classifier performed best with more data. The data augmentation/ViT approach worked better overall, achieving accuracies of 93.2\% (sensitivity=87.2, specificity=90.5, precision=87.6, F1-score=88.7, and AUROC=92) for OASIS and 90.4\% (sensitivity=85.4, specificity=88.6, precision=86.9, F1-score=88, and AUROC=90) for ADNI. Conclusions Effective ML models using neuroimaging data could help physicians working on AD diagnosis and will assist them in prescribing timely treatment to patients with AD. Good results were obtained on the OASIS and ADNI datasets with all the proposed classifiers, namely, SVM, FFNN, and ViTs. However, the results show that the ViT model is much better at predicting AD than the other models when a sufficient amount of data are available to perform the training. This highlights that the data augmentation process could impact the overall performance of the ViT model.},
  pmcid = {PMC12036548},
  pmid = {40257754}
}

@inproceedings{lecunHandwrittenDigitRecognition1989,
  title = {Handwritten {{Digit Recognition}} with a {{Back-Propagation Network}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, R. and Hubbard, Wayne and Jackel, Lawrence},
  year = 1989,
  volume = {2},
  publisher = {Morgan-Kaufmann},
  urldate = {2025-10-31},
  abstract = {We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was  required, but architecture of the network was highly constrained  and specifically designed for the task. The input of the network  consists of normalized images of isolated digits. The method has  1 \% error rate and about a 9\% reject rate on zipcode digits provided  by the U.S. Postal Service.},
  file = {/home/paris/Zotero/storage/C63SFWS9/LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagation Network.pdf}
}

@inbook{leeIndependentComponentAnalysis1998,
  title = {Independent {{Component Analysis}}},
  booktitle = {Independent {{Component Analysis}}},
  author = {Lee, Te-Won},
  year = 1998,
  pages = {27--66},
  publisher = {Springer US},
  address = {Boston, MA},
  doi = {10.1007/978-1-4757-2851-4_2},
  urldate = {2025-07-01},
  collaborator = {Lee, Te-Won},
  isbn = {978-1-4419-5056-7 978-1-4757-2851-4},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Lee - 1998 - Independent Component Analysis.pdf}
}

@article{lemingChallengesImplementingComputeraided2023,
  title = {Challenges of Implementing Computer-Aided Diagnostic Models for Neuroimages in a Clinical Setting},
  author = {Leming, Matthew J. and Bron, Esther E. and Bruffaerts, Rose and Ou, Yangming and Iglesias, Juan Eugenio and Gollub, Randy L. and Im, Hyungsoon},
  year = 2023,
  month = jul,
  journal = {NPJ Digital Medicine},
  volume = {6},
  pages = {129},
  issn = {2398-6352},
  doi = {10.1038/s41746-023-00868-x},
  urldate = {2025-10-01},
  abstract = {Advances in artificial intelligence have cultivated a strong interest in developing and validating the clinical utilities of computer-aided diagnostic models. Machine learning for diagnostic neuroimaging has often been applied to detect psychological and neurological disorders, typically on small-scale datasets or data collected in a research setting. With the collection and collation of an ever-growing number of public datasets that researchers can freely access, much work has been done in adapting machine learning models to classify these neuroimages by diseases such as Alzheimer's, ADHD, autism, bipolar disorder, and so on. These studies often come with the promise of being implemented clinically, but despite intense interest in this topic in the laboratory, limited progress has been made in clinical implementation. In this review, we analyze challenges specific to the clinical implementation of diagnostic AI models for neuroimaging data, looking at the differences between laboratory and clinical settings, the inherent limitations of diagnostic AI, and the different incentives and skill sets between research institutions, technology companies, and hospitals. These complexities need to be recognized in the translation of diagnostic AI for neuroimaging from the laboratory to the clinic.},
  pmcid = {PMC10345121},
  pmid = {37443276},
  file = {/home/paris/Zotero/storage/6BS6GKKQ/Leming et al. - 2023 - Challenges of implementing computer-aided diagnostic models for neuroimages in a clinical setting.pdf}
}

@article{lemingChallengesImplementingComputeraided2023a,
  title = {Challenges of Implementing Computer-Aided Diagnostic Models for Neuroimages in a Clinical Setting},
  author = {Leming, Matthew J. and Bron, Esther E. and Bruffaerts, Rose and Ou, Yangming and Iglesias, Juan Eugenio and Gollub, Randy L. and Im, Hyungsoon},
  year = 2023,
  month = jul,
  journal = {npj Digital Medicine},
  volume = {6},
  number = {1},
  pages = {129},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-023-00868-x},
  urldate = {2026-01-14},
  abstract = {Advances in artificial intelligence have cultivated a strong interest in developing and validating the clinical utilities of computer-aided diagnostic models. Machine learning for diagnostic neuroimaging has often been applied to detect psychological and neurological disorders, typically on small-scale datasets or data collected in a research setting. With the collection and collation of an ever-growing number of public datasets that researchers can freely access, much work has been done in adapting machine learning models to classify these neuroimages by diseases such as Alzheimer's, ADHD, autism, bipolar disorder, and so on. These studies often come with the promise of being implemented clinically, but despite intense interest in this topic in the laboratory, limited progress has been made in clinical implementation. In this review, we analyze challenges specific to the clinical implementation of diagnostic AI models for neuroimaging data, looking at the differences between laboratory and clinical settings, the inherent limitations of diagnostic AI, and the different incentives and skill sets between research institutions, technology companies, and hospitals. These complexities need to be recognized in the translation of diagnostic AI for neuroimaging from the laboratory to the clinic.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Medical imaging,Translational research},
  file = {/home/paris/Zotero/storage/5DHKKKAT/Leming et al. - 2023 - Challenges of implementing computer-aided diagnostic models for neuroimages in a clinical setting.pdf}
}

@article{liApplicationsChallengesMachine2021,
  title = {Applications and {{Challenges}} of {{Machine Learning Methods}} in {{Alzheimer}}'s {{Disease Multi-Source Data Analysis}}},
  author = {Li, Xiong and Qiu, Yangping and Zhou, Juan and Xie, Ziruo},
  year = 2021,
  month = dec,
  journal = {Current Genomics},
  volume = {22},
  number = {8},
  pages = {564--582},
  issn = {1389-2029},
  doi = {10.2174/1389202923666211216163049},
  urldate = {2025-10-01},
  abstract = {Background Recent development in neuroimaging and genetic testing technologies have made it possible to measure pathological features associated with Alzheimer's disease (AD) in vivo. Mining potential molecular markers of AD from high-dimensional, multi-modal neuroimaging and omics data will provide a new basis for early diagnosis and intervention in AD. In order to discover the real pathogenic mutation and even understand the pathogenic mechanism of AD, lots of machine learning methods have been designed and successfully applied to the analysis and processing of large-scale AD biomedical data. Objective To introduce and summarize the applications and challenges of machine learning methods in Alzheimer's disease multi-source data analysis. Methods The literature selected in the review is obtained from Google Scholar, PubMed, and Web of Science. The keywords of literature retrieval include Alzheimer's disease, bioinformatics, image genetics, genome-wide association research, molecular interaction network, multi-omics data integration, and so on. Conclusion This study comprehensively introduces machine learning-based processing techniques for AD neuroimaging data and then shows the progress of computational analysis methods in omics data, such as the genome, proteome, and so on. Subsequently, machine learning methods for AD imaging analysis are also summarized. Finally, we elaborate on the current emerging technology of multi-modal neuroimaging, multi-omics data joint analysis, and present some outstanding issues and future research directions.},
  pmcid = {PMC8922327},
  pmid = {35386189},
  file = {/home/paris/Zotero/storage/BV68DBUF/Li et al. - 2021 - Applications and Challenges of Machine Learning Methods in Alzheimer's Disease Multi-Source Data Ana.pdf}
}

@article{liClassificationAlzheimersDisease2022,
  title = {Classification of {{Alzheimer}}'s Disease in {{MRI}} Images Using Knowledge Distillation Framework: An Investigation},
  shorttitle = {Classification of {{Alzheimer}}'s Disease in {{MRI}} Images Using Knowledge Distillation Framework},
  author = {Li, Yiru and Luo, Jianxu and Zhang, Jiachen},
  year = 2022,
  month = jul,
  journal = {International Journal of Computer Assisted Radiology and Surgery},
  volume = {17},
  number = {7},
  pages = {1235--1243},
  issn = {1861-6429},
  doi = {10.1007/s11548-022-02661-9},
  urldate = {2025-10-16},
  langid = {english}
}

@misc{liDatasetDistillationMedical2025,
  title = {Dataset {{Distillation}} in {{Medical Imaging}}: {{A Feasibility Study}}},
  shorttitle = {Dataset {{Distillation}} in {{Medical Imaging}}},
  author = {Li, Muyang and Cui, Can and Liu, Quan and Deng, Ruining and Yao, Tianyuan and Lionts, Marilyn and Huo, Yuankai},
  year = 2025,
  month = feb,
  number = {arXiv:2407.14429},
  eprint = {2407.14429},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.14429},
  urldate = {2025-10-16},
  abstract = {Data sharing in the medical image analysis field has potential yet remains underappreciated. The aim is often to share datasets efficiently with other sites to train models effectively. One possible solution is to avoid transferring the entire dataset while still achieving similar model performance. Recent progress in data distillation within computer science offers promising prospects for sharing medical data efficiently without significantly compromising model effectiveness. However, it remains uncertain whether these methods would be applicable to medical imaging, since medical and natural images are distinct fields. Moreover, it is intriguing to consider what level of performance could be achieved with these methods. To answer these questions, we conduct investigations on a variety of leading data distillation methods, in different contexts of medical imaging. We evaluate the feasibility of these methods with extensive experiments in two aspects: 1) Assess the impact of data distillation across multiple datasets characterized by minor or great variations. 2) Explore the indicator to predict the distillation performance. Our extensive experiments across multiple medical datasets reveal that data distillation can significantly reduce dataset size while maintaining comparable model performance to that achieved with the full dataset, suggesting that a small, representative sample of images can serve as a reliable indicator of distillation success. This study demonstrates that data distillation is a viable method for efficient and secure medical data sharing, with the potential to facilitate enhanced collaborative research and clinical applications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/Zotero/storage/KLTBQESV/Li et al. - 2025 - Dataset Distillation in Medical Imaging A Feasibility Study.pdf;/home/paris/Zotero/storage/6EBIJS8K/2407.html}
}

@inproceedings{liDiaMondDementiaDiagnosis2025,
  title = {{{DiaMond}}: {{Dementia Diagnosis}} with {{Multi-Modal Vision Transformers Using MRI}} and {{PET}}},
  shorttitle = {{{DiaMond}}},
  booktitle = {2025 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Li, Yitong and Ghahremani, Morteza and Wally, Youssef and Wachinger, Christian},
  year = 2025,
  month = feb,
  pages = {107--116},
  issn = {2642-9381},
  doi = {10.1109/WACV61041.2025.00021},
  urldate = {2025-10-24},
  abstract = {Diagnosing dementia, particularly for Alzheimer's Disease (AD) and frontotemporal dementia (FTD), is complex due to overlapping symptoms. While magnetic res-onance imaging (MRI) and positron emission tomography (PET) data are critical for the diagnosis, integrating these modalities in deep learning faces challenges, often resulting in suboptimal performance compared to using single modalities. Moreover, the potential of multi-modal approaches in differential diagnosis, which holds significant clinical importance, remains largely unexplored. We propose a novel framework, DiaMond, to address these is-sues with vision Transformers to effectively integrate MRI and PET. DiaMond is equipped with self-attention and a novel bi-attention mechanism that synergistically combine MRI and PET, alongside a multi-modal normalization to reduce redundant dependency, thereby boosting the performance. DiaMond significantly outperforms existing multi-modal methods across various datasets, achieving a balanced accuracy of 92.4\% in AD diagnosis, 65.2\% for AD-MCI-CN classification, and 76.5\% in differential diagnosis of AD and FTD. We also validated the robustness of Dia-Mond in a comprehensive ablation study. The code is avail-able at https://github.com/ai-med/DiaMond.},
  keywords = {Accuracy,Alzheimer's disease,attention mechanism,Computer vision,dementia diagnosis,Diamond,Differential diagnosis,Feature extraction,Magnetic resonance imaging,multi-modal learning,Positron emission tomography,Robustness,Transformers,vision transformers},
  file = {/home/paris/Zotero/storage/IPGINGFK/10944202.html}
}

@article{linConvolutionalNeuralNetworksBased2018,
  title = {Convolutional {{Neural Networks-Based MRI Image Analysis}} for the {{Alzheimer}}'s {{Disease Prediction From Mild Cognitive Impairment}}},
  author = {Lin, Weiming and Tong, Tong and Gao, Qinquan and Guo, Di and Du, Xiaofeng and Yang, Yonggui and Guo, Gang and Xiao, Min and Du, Min and Qu, Xiaobo and The Alzheimer's Disease Neuroimaging Initiative},
  year = 2018,
  month = nov,
  journal = {Frontiers in Neuroscience},
  volume = {12},
  publisher = {Frontiers},
  issn = {1662-453X},
  doi = {10.3389/fnins.2018.00777},
  urldate = {2025-08-19},
  abstract = {Mild cognitive impairment (MCI) is the prodromal stage of Alzheimer's disease (AD). Identifying MCI subjects who are at high risk of converting to AD is crucial for effective treatments. In this study, a deep learning approach based on convolutional neural networks (CNN), is designed to accurately predict MCI-to-AD conversion with magnetic resonance imaging (MRI) data. First, MRI images are prepared with age-correction and other processing. Second, local patches, which are assembled into 2.5 dimensions, are extracted from these images. Then, the patches from AD and normal controls (NC) are used to train a CNN to identify deep learning features of MCI subjects. After that, structural brain image features are mined with FreeSurfer to assist CNN. Finally, both types of features are fed into an extreme learning machine classifier to predict the AD conversion. The proposed approach is validated on the standardized MRI datasets from the Alzheimer's Disease Neuroimaging Initiative (ADNI) project. This approach achieves an accuracy of 79.9\% and an area under the receiver operating characteristic curve (AUC) of 86.1\% in leave-one-out cross validations. Compared with other state-of-the-art methods, the proposed one outperforms others with higher accuracy and AUC, while keeping a good balance between the sensitivity and specificity. Results demonstrate great potentials of the proposed CNN-based approach for the prediction of MCI-to-AD conversion with solely MRI data. Age correction and assisted structural brain image features can boost the prediction performance of CNN.},
  langid = {english},
  keywords = {Alzheimer's disease,Convolutional Neural Networks,deep learning,Magnetic Resonance Imaging,Mild Cognitive Impairment},
  file = {/home/paris/gdrive/Zotero/Lin et al. - 2018 - Convolutional Neural Networks-Based MRI Image Analysis for the Alzheimer’s Disease Prediction From M.pdf}
}

@article{lingSelfsupervisedDigitalHistopathology2023,
  title = {Self-Supervised Digital Histopathology Image Disentanglement for Arbitrary Domain Stain Transfer},
  author = {Ling, Yu and Tan, Weimin and Yan, Bo},
  year = 2023,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {42},
  number = {12},
  pages = {3625--3638},
  publisher = {IEEE},
  urldate = {2025-06-23}
}

@inproceedings{linHybridCNNSVMAlzheimers2018,
  title = {Hybrid {{CNN-SVM}} for {{Alzheimer}}'s {{Disease Classification}} from {{Structural MRI}} and the {{Alzheimer}}'s {{Disease Neuroimaging Initiative}} ({{ADNI}})},
  booktitle = {2018 {{International Conference}} on {{Biomedical Engineering}}, {{Machinery}} and {{Earth Science}}},
  author = {Lin, Lan and Zhang, Baiwen and Wu, Shuicai},
  year = 2018,
  month = sep,
  urldate = {2025-08-22},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Lin et al. - 2018 - Hybrid CNN-SVM for Alzheimer's Disease Classification from Structural MRI and the Alzheimer’s Diseas.pdf}
}

@inproceedings{liResearchOverfittingDeep2019,
  title = {Research on Overfitting of Deep Learning},
  booktitle = {2019 15th International Conference on Computational Intelligence and Security ({{CIS}})},
  author = {Li, Haidong and Li, Jiongcheng and Guan, Xiaoming and Liang, Binghao and Lai, Yuting and Luo, Xinglong},
  year = 2019,
  pages = {78--81},
  publisher = {IEEE},
  urldate = {2025-11-04}
}

@inproceedings{liuDataHeterogeneityModeling2025,
  title = {Data {{Heterogeneity Modeling}} for {{Trustworthy Machine Learning}}},
  booktitle = {Proceedings of the 31st {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining V}}.2},
  author = {Liu, Jiashuo and Cui, Peng},
  year = 2025,
  month = aug,
  eprint = {2506.00969},
  primaryclass = {cs},
  pages = {6086--6095},
  doi = {10.1145/3711896.3736560},
  urldate = {2025-10-24},
  abstract = {Data heterogeneity plays a pivotal role in determining the performance of machine learning (ML) systems. Traditional algorithms, which are typically designed to optimize average performance, often overlook the intrinsic diversity within datasets. This oversight can lead to a myriad of issues, including unreliable decision-making, inadequate generalization across different domains, unfair outcomes, and false scientific inferences. Hence, a nuanced approach to modeling data heterogeneity is essential for the development of dependable, data-driven systems. In this survey paper, we present a thorough exploration of heterogeneity-aware machine learning, a paradigm that systematically integrates considerations of data heterogeneity throughout the entire ML pipeline -- from data collection and model training to model evaluation and deployment. By applying this approach to a variety of critical fields, including healthcare, agriculture, finance, and recommendation systems, we demonstrate the substantial benefits and potential of heterogeneity-aware ML. These applications underscore how a deeper understanding of data diversity can enhance model robustness, fairness, and reliability and help model diagnosis and improvements. Moreover, we delve into future directions and provide research opportunities for the whole data mining community, aiming to promote the development of heterogeneity-aware ML.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/paris/Zotero/storage/6KEATK24/Liu and Cui - 2025 - Data Heterogeneity Modeling for Trustworthy Machine Learning.pdf;/home/paris/Zotero/storage/6ZJ5ZM4Z/2506.html}
}

@inproceedings{liuEarlyDiagnosisAlzheimers2014,
  title = {Early Diagnosis of {{Alzheimer}}'s Disease with Deep Learning},
  booktitle = {2014 {{IEEE}} 11th International Symposium on Biomedical Imaging ({{ISBI}})},
  author = {Liu, Siqi and Liu, Sidong and Cai, Weidong and Pujol, Sonia and Kikinis, Ron and Feng, Dagan},
  year = 2014,
  pages = {1015--1018},
  publisher = {IEEE},
  urldate = {2024-11-16}
}

@misc{liuLightweightDeepLearning2024,
  title = {Lightweight {{Deep Learning}} for {{Resource-Constrained Environments}}: {{A Survey}}},
  shorttitle = {Lightweight {{Deep Learning}} for {{Resource-Constrained Environments}}},
  author = {Liu, Hou-I. and Galindo, Marco and Xie, Hongxia and Wong, Lai-Kuan and Shuai, Hong-Han and Li, Yung-Hui and Cheng, Wen-Huang},
  year = 2024,
  month = apr,
  number = {arXiv:2404.07236},
  eprint = {2404.07236},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.07236},
  urldate = {2025-10-16},
  abstract = {Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model's accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and Large Language Models. Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/paris/Zotero/storage/22HGENQ8/Liu et al. - 2024 - Lightweight Deep Learning for Resource-Constrained Environments A Survey.pdf;/home/paris/Zotero/storage/SQXVV3VJ/2404.html}
}

@article{liValidationPlasmaAmyloidv2022,
  title = {Validation of {{Plasma Amyloid-$\beta$}} 42/40 for {{Detecting Alzheimer Disease Amyloid Plaques}}},
  author = {Li, Yan and Schindler, Suzanne E. and Bollinger, James G. and Ovod, Vitaliy and Mawuenyega, Kwasi G. and Weiner, Michael W. and Shaw, Leslie M. and Masters, Colin L. and Fowler, Christopher J. and Trojanowski, John Q. and Korecka, Magdalena and Martins, Ralph N. and Janelidze, Shorena and Hansson, Oskar and Bateman, Randall J.},
  year = 2022,
  month = feb,
  journal = {Neurology},
  volume = {98},
  number = {7},
  pages = {e688-e699},
  issn = {1526-632X},
  doi = {10.1212/WNL.0000000000013211},
  abstract = {BACKGROUND AND OBJECTIVES: To determine the diagnostic accuracy of a plasma A{$\beta$}42/A{$\beta$}40 assay in classifying amyloid PET status across global research studies using samples collected by multiple centers that utilize different blood collection and processing protocols. METHODS: Plasma samples (n = 465) were obtained from 3 large Alzheimer disease (AD) research cohorts in the United States (n = 182), Australia (n = 183), and Sweden (n = 100). Plasma A{$\beta$}42/A{$\beta$}40 was measured by a high precision immunoprecipitation mass spectrometry (IPMS) assay and compared to the reference standards of amyloid PET and CSF A{$\beta$}42/A{$\beta$}40. RESULTS: In the combined cohort of 465 participants, plasma A{$\beta$}42/A{$\beta$}40 had good concordance with amyloid PET status (receiver operating characteristic area under the curve [AUC] 0.84, 95\% confidence interval [CI] 0.80-0.87); concordance improved with the inclusion of APOE {$\varepsilon$}4 carrier status (AUC 0.88, 95\% CI 0.85-0.91). The AUC of plasma A{$\beta$}42/A{$\beta$}40 with CSF amyloid status was 0.85 (95\% CI 0.78-0.91) and improved to 0.93 (95\% CI 0.89-0.97) with APOE {$\varepsilon$}4 status. These findings were consistent across the 3 cohorts, despite differences in protocols. The assay performed similarly in both cognitively unimpaired and impaired individuals. DISCUSSION: Plasma A{$\beta$}42/A{$\beta$}40 is a robust measure for detecting amyloid plaques and can be utilized to aid in the diagnosis of AD, identify those at risk for future dementia due to AD, and improve the diversity of populations enrolled in AD research and clinical trials. CLASSIFICATION OF EVIDENCE: This study provides Class II evidence that plasma A{$\beta$}42/A{$\beta$}40, as measured by a high precision IPMS assay, accurately diagnoses brain amyloidosis in both cognitively unimpaired and impaired research participants.},
  langid = {english},
  pmcid = {PMC8865895},
  pmid = {34906975},
  keywords = {Alzheimer Disease,Amyloid beta-Peptides,Biomarkers,Humans,Peptide Fragments,Plaque Amyloid,Positron-Emission Tomography},
  file = {/home/paris/Zotero/storage/F4LMSDCF/Li et al. - 2022 - Validation of Plasma Amyloid-β 4240 for Detecting Alzheimer Disease Amyloid Plaques.pdf}
}

@article{longoExplainableArtificialIntelligence2024,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}) 2.0: {{A}} Manifesto of Open Challenges and Interdisciplinary Research Directions},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}}) 2.0},
  author = {Longo, Luca and Brcic, Mario and Cabitza, Federico and Choi, Jaesik and Confalonieri, Roberto and Ser, Javier Del and Guidotti, Riccardo and Hayashi, Yoichi and Herrera, Francisco and Holzinger, Andreas and Jiang, Richard and Khosravi, Hassan and Lecue, Freddy and Malgieri, Gianclaudio and P{\'a}ez, Andr{\'e}s and Samek, Wojciech and Schneider, Johannes and Speith, Timo and Stumpf, Simone},
  year = 2024,
  month = jun,
  journal = {Information Fusion},
  volume = {106},
  pages = {102301},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2024.102301},
  urldate = {2025-09-08},
  abstract = {Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.},
  keywords = {Actionable XAI,Causality,Concept-based explanations,Ethical AI,Explainable artificial intelligence,Falsifiability,Generative AI,Interdisciplinarity,Interpretability,Large language models,Manifesto,Multi-faceted explanations,Open challenges,Responsible AI,Trustworthy AI,XAI},
  file = {/home/paris/gdrive/Zotero/Longo et al. - 2024 - Explainable Artificial Intelligence (XAI) 2.0 A manifesto of open challenges and interdisciplinary.pdf;/home/paris/Zotero/storage/P78JI5QH/S1566253524000794.html}
}

@article{luSmallStudyEffects2022,
  title = {Small {{Study Effects}} in {{Diagnostic Imaging Accuracy}}},
  author = {Lu, Lucy and Phua, Qi Sheng and Bacchi, Stephen and Goh, Rudy and Gupta, Aashray K. and Kovoor, Joshua G. and Ovenden, Christopher D. and To, Minh-Son},
  year = 2022,
  month = aug,
  journal = {JAMA Network Open},
  volume = {5},
  number = {8},
  pages = {e2228776},
  issn = {2574-3805},
  doi = {10.1001/jamanetworkopen.2022.28776},
  urldate = {2025-10-15},
  abstract = {This meta-analysis evaluates the presence and extent of small study effects in meta-analyses assessing diagnostic imaging accuracy.},
  pmcid = {PMC9412222},
  pmid = {36006641},
  file = {/home/paris/Zotero/storage/SXEUP9UZ/Lu et al. - 2022 - Small Study Effects in Diagnostic Imaging Accuracy.pdf}
}

@article{m.dessoukySelectingExtractingEffective2013,
  title = {Selecting and {{Extracting Effective Features}} for {{Automated Diagnosis}} of {{Alzheimer}}\&apos;s {{Disease}}},
  author = {M.Dessouky, Mohamed and A. Elrashidy, Mohamed and M. Abdelkader, Hatem},
  year = 2013,
  month = nov,
  journal = {International Journal of Computer Applications},
  volume = {81},
  number = {4},
  pages = {17--28},
  issn = {09758887},
  doi = {10.5120/14000-2039},
  urldate = {2025-08-15},
  abstract = {In this paper, a Computer Aided Diagnosis (CAD) system is proposed to provide a comprehensive analytic method for extracting the most significant features of Alzheimer's disease (AD). It consists of three stages: feature selection, feature extraction, and classification. This proposal selects the features that have different intensity level at all images and discarding the features that have the same intensity level to reach the fewer subset of features that have the most impact distinctive of AD. Then reduces the features by proposing a new feature extraction algorithm that minimizes intra separately distance of AD features. Finally, a Linear Support Vector Machine (SVM) classifier was used to perform binary classifications among AD patients. The data set that used for testing the proposed model consists of 120 cross-sectional Structural MRI images from the Open Access Series of Imaging Studies (OASIS) database. Experiments have been conducted on Open Access Series of Imaging Studies (OASIS) database. The results show that the highest classification performance is obtained using the proposed model, and this is very promising compared to Principle Component Analysis (PCA) and Linear Discriminate Analysis (LDA).},
  langid = {english},
  file = {/home/paris/Zotero/storage/A2SFEX4K/document.pdf}
}

@misc{MachineLearningHealthcare,
  title = {Machine {{Learning}} in {{Healthcare}}: {{A Review}} of {{Current Applications}} and {{Future Trends}}},
  shorttitle = {Machine {{Learning}} in {{Healthcare}}},
  urldate = {2025-10-15},
  abstract = {Machine learning (ML) has been a main force behind important breakthroughs in patient tracking, personalized medicine, medical tests, and operating efficiency in the healthcare business in recent years. Machine learning algorithms provide unique insights into early disease identification, picture analysis, and prediction analytics, improving diagnosis accuracy and treatment results. These programs are able to examine big and complex information. By predicting treatment effectiveness and genetic risks, machine learning (ML) allows personalized medicine by allowing customized care through tailored therapy approaches. Furthermore, preventative health management is backed by ML-driven prediction analytics and online patient tracking, especially for chronic illnesses. Operationally, machine learning increases process efficiency and cuts costs, allowing for data- driven decision-making and individualized patient care. However, there are important ethics issues with machine learning acceptance in the healthcare business as well, such as data protection, computer bias, and legal problems. This study offers a full analysis of the state-of-the-art machine learning applications in healthcare, stressing their revolutionary potential while discussing the ethics issues and hurdles that must be addressed to ensure execution that is both responsible and fair.},
  howpublished = {https://ieeexplore.ieee.org/document/10968281},
  langid = {american},
  file = {/home/paris/Zotero/storage/L5APVNAL/10968281.html}
}

@article{manjonAdaptiveNonlocalMeans2010,
  title = {Adaptive Non-Local Means Denoising of {{MR}} Images with Spatially Varying Noise Levels},
  author = {Manj{\'o}n, Jos{\'e} V. and Coup{\'e}, Pierrick and {Mart{\'i}-Bonmat{\'i}}, Luis and Collins, D. Louis and Robles, Montserrat},
  year = 2010,
  journal = {Journal of Magnetic Resonance Imaging},
  volume = {31},
  number = {1},
  pages = {192--203},
  issn = {1522-2586},
  doi = {10.1002/jmri.22003},
  urldate = {2025-05-17},
  abstract = {Purpose: To adapt the so-called nonlocal means filter to deal with magnetic resonance (MR) images with spatially varying noise levels (for both Gaussian and Rician distributed noise). Materials and Methods: Most filtering techniques assume an equal noise distribution across the image. When this assumption is not met, the resulting filtering becomes suboptimal. This is the case of MR images with spatially varying noise levels, such as those obtained by parallel imaging (sensitivity-encoded), intensity inhomogeneity-corrected images, or surface coil-based acquisitions. We propose a new method where information regarding the local image noise level is used to adjust the amount of denoising strength of the filter. Such information is automatically obtained from the images using a new local noise estimation method. Results: The proposed method was validated and compared with the standard nonlocal means filter on simulated and real MRI data showing an improved performance in all cases. Conclusion: The new noise-adaptive method was demonstrated to outperform the standard filter when spatially varying noise is present in the images. J. Magn. Reson. Imaging 2010;31:192--203. \copyright{} 2009 Wiley-Liss, Inc.},
  copyright = {Copyright \copyright{} 2009 Wiley-Liss, Inc.},
  langid = {english},
  keywords = {denoising,nonlocal means,parallel MRI},
  annotation = {citeKey : AdNonLocal},
  file = {/home/paris/gdrive/Zotero/Denosing/Manjón et al. - 2010 - Adaptive non-local means denoising of MR images with spatially varying noise levels.pdf;/home/paris/Zotero/storage/24DK5EQT/jmri.html}
}

@article{manjonMRINoiseEstimation2015,
  title = {{{MRI}} Noise Estimation and Denoising Using Non-Local {{PCA}}},
  author = {Manj{\'o}n, Jos{\'e} V. and Coup{\'e}, Pierrick and Buades, Antonio},
  year = 2015,
  month = may,
  journal = {Medical Image Analysis},
  volume = {22},
  number = {1},
  pages = {35--47},
  issn = {1361-8415},
  doi = {10.1016/j.media.2015.01.004},
  urldate = {2025-05-18},
  abstract = {This paper proposes a novel method for MRI denoising that exploits both the sparseness and self-similarity properties of the MR images. The proposed method is a two-stage approach that first filters the noisy image using a non local PCA thresholding strategy by automatically estimating the local noise level present in the image and second uses this filtered image as a guide image within a rotationally invariant non-local means filter. The proposed method internally estimates the amount of local noise presents in the images that enables applying it automatically to images with spatially varying noise levels and also corrects the Rician noise induced bias locally. The proposed approach has been compared with related state-of-the-art methods showing competitive results in all the studied cases.},
  keywords = {Denoising,MRI,Non-local means,PCA,Sparseness},
  file = {/home/paris/gdrive/Zotero/Denosing/Manjón et al. - 2015 - MRI noise estimation and denoising using non-local PCA.pdf;/home/paris/Zotero/storage/ICQ3XGCH/S1361841515000171.html}
}

@article{manjonMulticomponentMRImage2009,
  title = {Multicomponent {{MR Image Denoising}}},
  author = {Manj{\'o}n, Jos{\'e} V. and Thacker, Neil A. and Lull, Juan J. and {Garcia-Mart{\'i}}, Gracian and {Mart{\'i}-Bonmat{\'i}}, Lu{\'i}s and Robles, Montserrat},
  editor = {Wang, Yue},
  year = 2009,
  month = jan,
  journal = {International Journal of Biomedical Imaging},
  volume = {2009},
  number = {1},
  publisher = {Wiley},
  issn = {1687-4188, 1687-4196},
  doi = {10.1155/2009/756897},
  urldate = {2025-05-17},
  abstract = {Magnetic Resonance images are normally corrupted by random noise from the measurement process complicating the automatic feature extraction and analysis of clinical data. It is because of this reason that denoising methods have been traditionally applied to improve MR image quality. Many of these methods use the information of a single image without taking into consideration the intrinsic multicomponent nature of MR images. In this paper we propose a new filter to reduce random noise in multicomponent MR images by spatially averaging similar pixels using information from all available image components to perform the denoising process. The proposed algorithm also uses a local Principal Component Analysis decomposition as a postprocessing step to remove more noise by using information not only in the spatial domain but also in the intercomponent domain dealing in a higher noise reduction without significantly affecting the original image resolution. The proposed method has been compared with similar state-of-art methods over synthetic and real clinical multicomponent MR images showing an improved performance in all cases analyzed.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Denosing/Manjón et al. - 2009 - Multicomponent MR Image Denoising.pdf}
}

@article{manReviewSyntheticImage2022,
  title = {A {{Review}} of {{Synthetic Image Data}} and {{Its Use}} in {{Computer Vision}}},
  author = {Man, Keith and Chahl, Javaan},
  year = 2022,
  month = nov,
  journal = {Journal of Imaging},
  volume = {8},
  number = {11},
  pages = {310},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2313-433X},
  doi = {10.3390/jimaging8110310},
  urldate = {2025-11-04},
  abstract = {Development of computer vision algorithms using convolutional neural networks and deep learning has necessitated ever greater amounts of annotated and labelled data to produce high performance models. Large, public data sets have been instrumental in pushing forward computer vision by providing the data necessary for training. However, many computer vision applications cannot rely on general image data provided in the available public datasets to train models, instead requiring labelled image data that is not readily available in the public domain on a large scale. At the same time, acquiring such data from the real world can be difficult, costly to obtain, and manual labour intensive to label in large quantities. Because of this, synthetic image data has been pushed to the forefront as a potentially faster and cheaper alternative to collecting and annotating real data. This review provides general overview of types of synthetic image data, as categorised by synthesised output, common methods of synthesising different types of image data, existing applications and logical extensions, performance of synthetic image data in different applications and the associated difficulties in assessing data performance, and areas for further research.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computer vision,image synthesis,synthetic data generation,synthetic image data},
  file = {/home/paris/Zotero/storage/S39RRVS7/Man and Chahl - 2022 - A Review of Synthetic Image Data and Its Use in Computer Vision.pdf}
}

@article{marcusBrainPETDiagnosis2014,
  title = {Brain {{PET}} in the {{Diagnosis}} of {{Alzheimer}}'s {{Disease}}},
  author = {Marcus, Charles and Mena, Esther and Subramaniam, Rathan M.},
  year = 2014,
  month = oct,
  journal = {Clinical Nuclear Medicine},
  volume = {39},
  number = {10},
  pages = {e413-e426},
  issn = {0363-9762},
  doi = {10.1097/RLU.0000000000000547},
  urldate = {2025-03-28},
  langid = {english},
  file = {/home/paris/Zotero/storage/W3CC864U/Marcus et al. - 2014 - Brain PET in the Diagnosis of Alzheimer’s Disease.pdf}
}

@article{marcusDeepLearningCritical,
  title = {Deep {{Learning}}: {{A Critical Appraisal}}},
  author = {Marcus, Gary},
  abstract = {Although deep learning has historical roots going back decades, neither the term ``deep learning'' nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic 2012 (Krizhevsky, Sutskever, \& Hinton, 2012)deep net model of Imagenet.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Marcus - Deep Learning A Critical Appraisal.pdf}
}

@misc{marques-silvaExplainabilityNOTGame2024,
  title = {Explainability Is {{NOT}} a {{Game}}},
  author = {{Marques-Silva}, Joao and Huang, Xuanxiang},
  year = 2024,
  month = feb,
  number = {arXiv:2307.07514},
  eprint = {2307.07514},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.07514},
  urldate = {2025-09-08},
  abstract = {Explainable artificial intelligence (XAI) aims to help human decisionmakers in understanding complex machine learning (ML) models. One of the hallmarks of XAI are measures of relative feature importance, which are theoretically justified through the use of Shapley values. This paper builds on recent work and offers a simple argument for why Shapley values can provide misleading measures of relative feature importance, by assigning more importance to features that are irrelevant for a prediction, and assigning less importance to features that are relevant for a prediction. The significance of these results is that they effectively challenge the many proposed uses of measures of relative feature importance in a fastgrowing range of high-stakes application domains.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Marques-Silva and Huang - 2024 - Explainability is NOT a Game.pdf}
}

@article{marquezNeuroimagingBiomarkersAlzheimers2019,
  title = {Neuroimaging {{Biomarkers}} for {{Alzheimer}}'s {{Disease}}},
  author = {M{\'a}rquez, Freddie and Yassa, Michael A.},
  year = 2019,
  month = jun,
  journal = {Molecular Neurodegeneration},
  volume = {14},
  number = {1},
  pages = {21},
  issn = {1750-1326},
  doi = {10.1186/s13024-019-0325-5},
  urldate = {2024-12-14},
  abstract = {Currently, over five million Americans suffer with Alzheimer's disease (AD). In the absence of a cure, this number could increase to 13.8 million by 2050. A critical goal of biomedical research is to establish indicators of AD during the preclinical stage (i.e. biomarkers) allowing for early diagnosis and intervention. Numerous advances have been made in developing biomarkers for AD using neuroimaging approaches. These approaches offer tremendous versatility in terms of targeting distinct age-related and pathophysiological mechanisms such as structural decline (e.g. volumetry, cortical thinning), functional decline (e.g. fMRI activity, network correlations), connectivity decline (e.g. diffusion anisotropy), and pathological aggregates (e.g. amyloid and tau PET). In this review, we survey the state of the literature on neuroimaging approaches to developing novel biomarkers for the amnestic form of AD, with an emphasis on combining approaches into multimodal biomarkers. We also discuss emerging methods including imaging epigenetics, neuroinflammation, and synaptic integrity using PET tracers. Finally, we review the complementary information that neuroimaging biomarkers provide, which highlights the potential utility of composite biomarkers as suitable outcome measures for proof-of-concept clinical trials with experimental therapeutics.},
  langid = {english},
  file = {/home/paris/Zotero/storage/TL9M999C/Márquez and Yassa - 2019 - Neuroimaging Biomarkers for Alzheimer’s Disease.pdf}
}

@article{marquezNeuroimagingBiomarkersAlzheimers2019a,
  title = {Neuroimaging {{Biomarkers}} for {{Alzheimer}}'s {{Disease}}},
  author = {M{\'a}rquez, Freddie and Yassa, Michael A.},
  year = 2019,
  month = dec,
  journal = {Molecular Neurodegeneration},
  volume = {14},
  number = {1},
  pages = {21},
  issn = {1750-1326},
  doi = {10.1186/s13024-019-0325-5},
  urldate = {2025-10-17},
  abstract = {Currently, over five million Americans suffer with Alzheimer's disease (AD). In the absence of a cure, this number could increase to 13.8 million by 2050. A critical goal of biomedical research is to establish indicators of AD during the preclinical stage (i.e. biomarkers) allowing for early diagnosis and intervention. Numerous advances have been made in developing biomarkers for AD using neuroimaging approaches. These approaches offer tremendous versatility in terms of targeting distinct age-related and pathophysiological mechanisms such as structural decline (e.g. volumetry, cortical thinning), functional decline (e.g. fMRI activity, network correlations), connectivity decline (e.g. diffusion anisotropy), and pathological aggregates (e.g. amyloid and tau PET). In this review, we survey the state of the literature on neuroimaging approaches to developing novel biomarkers for the amnestic form of AD, with an emphasis on combining approaches into multimodal biomarkers. We also discuss emerging methods including imaging epigenetics, neuroinflammation, and synaptic integrity using PET tracers. Finally, we review the complementary information that neuroimaging biomarkers provide, which highlights the potential utility of composite biomarkers as suitable outcome measures for proof-of-concept clinical trials with experimental therapeutics.},
  langid = {english},
  file = {/home/paris/Zotero/storage/V74ATDIH/Márquez and Yassa - 2019 - Neuroimaging Biomarkers for Alzheimer’s Disease.pdf}
}

@book{marti-bonmatiImagingBiomarkersDevelopment2016,
  title = {Imaging Biomarkers: Development and Clinical Integration},
  shorttitle = {Imaging Biomarkers},
  author = {{Mart{\'i}-Bonmat{\'i}}, Luis and {Alberich-Bayarri}, Angel},
  year = 2016,
  publisher = {Springer},
  urldate = {2025-05-22}
}

@article{martinInterpretableMachineLearning2023,
  title = {Interpretable Machine Learning for Dementia: {{A}} Systematic Review},
  shorttitle = {Interpretable Machine Learning for Dementia},
  author = {Martin, Sophie A. and Townend, Florence J. and Barkhof, Frederik and Cole, James H.},
  year = 2023,
  month = may,
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  number = {5},
  pages = {2135--2149},
  issn = {1552-5260},
  doi = {10.1002/alz.12948},
  urldate = {2025-10-01},
  abstract = {Introduction Machine learning research into automated dementia diagnosis is becoming increasingly popular but so far has had limited clinical impact. A key challenge is building robust and generalizable models that generate decisions that can be reliably explained. Some models are designed to be inherently ``interpretable,'' whereas post hoc ``explainability'' methods can be used for other models. Methods Here we sought to summarize the state-of-the-art of interpretable machine learning for dementia. Results We identified 92 studies using PubMed, Web of Science, and Scopus. Studies demonstrate promising classification performance but vary in their validation procedures and reporting standards and rely heavily on popular data sets. Discussion Future work should incorporate clinicians to validate explanation methods and make conclusive inferences about dementia-related disease pathology. Critically analyzing model explanations also requires an understanding of the interpretability methods itself. Patient-specific explanations are also required to demonstrate the benefit of interpretable machine learning in clinical practice.},
  pmcid = {PMC10955773},
  pmid = {36735865},
  file = {/home/paris/Zotero/storage/BKHA5QYH/Martin et al. - 2023 - Interpretable machine learning for dementia A systematic review.pdf}
}

@article{martinInterpretableMachineLearning2023a,
  title = {Interpretable Machine Learning for Dementia: {{A}} Systematic Review},
  shorttitle = {Interpretable Machine Learning for Dementia},
  author = {Martin, Sophie A. and Townend, Florence J. and Barkhof, Frederik and Cole, James H.},
  year = 2023,
  month = may,
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  number = {5},
  pages = {2135--2149},
  issn = {1552-5260},
  doi = {10.1002/alz.12948},
  urldate = {2025-10-01},
  abstract = {Introduction Machine learning research into automated dementia diagnosis is becoming increasingly popular but so far has had limited clinical impact. A key challenge is building robust and generalizable models that generate decisions that can be reliably explained. Some models are designed to be inherently ``interpretable,'' whereas post hoc ``explainability'' methods can be used for other models. Methods Here we sought to summarize the state-of-the-art of interpretable machine learning for dementia. Results We identified 92 studies using PubMed, Web of Science, and Scopus. Studies demonstrate promising classification performance but vary in their validation procedures and reporting standards and rely heavily on popular data sets. Discussion Future work should incorporate clinicians to validate explanation methods and make conclusive inferences about dementia-related disease pathology. Critically analyzing model explanations also requires an understanding of the interpretability methods itself. Patient-specific explanations are also required to demonstrate the benefit of interpretable machine learning in clinical practice.},
  pmcid = {PMC10955773},
  pmid = {36735865},
  file = {/home/paris/Zotero/storage/GZ8BD63C/Martin et al. - 2023 - Interpretable machine learning for dementia A systematic review.pdf}
}

@article{martinInterpretableMachineLearning2023b,
  title = {Interpretable Machine Learning for Dementia: {{A}} Systematic Review},
  shorttitle = {Interpretable Machine Learning for Dementia},
  author = {Martin, Sophie A. and Townend, Florence J. and Barkhof, Frederik and Cole, James H.},
  year = 2023,
  month = may,
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  number = {5},
  pages = {2135--2149},
  issn = {1552-5260, 1552-5279},
  doi = {10.1002/alz.12948},
  urldate = {2025-10-14},
  abstract = {Introduction: Machine learning research into automated dementia diagnosis is becoming increasingly popular but so far has had limited clinical impact. A key challenge is building robust and generalizable models that generate decisions that can be reliably explained. Some models are designed to be inherently ``interpretable,'' whereas post hoc ``explainability'' methods can be used for other models.},
  langid = {english},
  file = {/home/paris/Zotero/storage/X5QHEWZ5/Martin et al. - 2023 - Interpretable machine learning for dementia A systematic review.pdf}
}

@article{masoudiQuickGuideRadiology2021,
  title = {Quick Guide on Radiology Image Pre-Processing for Deep Learning Applications in Prostate Cancer Research},
  author = {Masoudi, Samira and Harmon, Stephanie A. A. and Mehralivand, Sherif and Walker, Stephanie M. and Raviprakash, Harish and Bagci, Ulas and Choyke, Peter L. and Turkbey, Baris},
  year = 2021,
  month = jan,
  journal = {Journal of Medical Imaging},
  volume = {8},
  number = {1},
  pages = {010901},
  publisher = {SPIE},
  issn = {2329-4302, 2329-4310},
  doi = {10.1117/1.JMI.8.1.010901},
  urldate = {2025-06-12},
  abstract = {Purpose: Deep learning has achieved major breakthroughs during the past decade in almost every field. There are plenty of publicly available algorithms, each designed to address a different task of computer vision in general. However, most of these algorithms cannot be directly applied to images in the medical domain. Herein, we are focused on the required preprocessing steps that should be applied to medical images prior to deep neural networks. Approach: To be able to employ the publicly available algorithms for clinical purposes, we must make a meaningful pixel/voxel representation from medical images which facilitates the learning process. Based on the ultimate goal expected from an algorithm (classification, detection, or segmentation), one may infer the required pre-processing steps that can ideally improve the performance of that algorithm. Required pre-processing steps for computed tomography (CT) and magnetic resonance (MR) images in their correct order are discussed in detail. We further supported our discussion by relevant experiments to investigate the efficiency of the listed preprocessing steps. Results: Our experiments confirmed how using appropriate image pre-processing in the right order can improve the performance of deep neural networks in terms of better classification and segmentation. Conclusions: This work investigates the appropriate pre-processing steps for CT and MR images of prostate cancer patients, supported by several experiments that can be useful for educating those new to the field (https://github.com/NIH-MIP/Radiology\_Image\_Preprocessing\_for\_Deep\_Learning).},
  file = {/home/paris/Zotero/storage/STYQRFZG/Masoudi et al. - 2021 - Quick guide on radiology image pre-processing for deep learning applications in prostate cancer rese.pdf}
}

@article{mccullochLOGICALCALCULUSIDEAS,
  title = {A {{LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY}}},
  author = {McCuLLocH, S and LrerR, Wa and Pitts, H},
  langid = {english},
  file = {/home/paris/Zotero/storage/HYMW2T4I/McCuLLocH et al. - A LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY.pdf}
}

@article{merkinMachineLearningArtificial2022,
  title = {Machine Learning, Artificial Intelligence and the Prediction of Dementia},
  author = {Merkin, Alexander and Krishnamurthi, Rita and Medvedev, Oleg N.},
  year = 2022,
  month = mar,
  journal = {Current Opinion in Psychiatry},
  volume = {35},
  number = {2},
  pages = {123},
  issn = {0951-7367},
  doi = {10.1097/YCO.0000000000000768},
  urldate = {2025-10-14},
  abstract = {Purpose of review~           Artificial intelligence and its division machine learning are emerging technologies that are increasingly applied in medicine. Artificial intelligence facilitates automatization of analytical modelling and contributes to prediction, diagnostics and treatment of diseases. This article presents an overview of the application of artificial intelligence in dementia research.           Recent findings~           Machine learning and its branch Deep Learning are widely used in research to support in diagnosis and prediction of dementia. Deep Learning models in certain tasks often result in better accuracy of detection and prediction of dementia than traditional machine learning methods, but they are more costly in terms of run times and hardware requirements. Both machine learning and Deep Learning models have their own strengths and limitations. Currently, there are few datasets with limited data available to train machine learning models. There are very few commercial applications of machine learning in medical practice to date, mostly represented by mobile applications, which include questionnaires and psychometric assessments with limited machine learning data processing.           Summary~           Application of machine learning technologies in detection and prediction of dementia may provide an advantage to psychiatry and neurology by promoting a better understanding of the nature of the disease and more accurate evidence-based processes that are reproducible and standardized.},
  langid = {american},
  file = {/home/paris/Zotero/storage/QNRQ5WAK/machine_learning,_artificial_intelligence_and_the.7.html}
}

@misc{michelucciIntroductionAutoencoders2022,
  title = {An {{Introduction}} to {{Autoencoders}}},
  author = {Michelucci, Umberto},
  year = 2022,
  month = jan,
  number = {arXiv:2201.03898},
  eprint = {2201.03898},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2201.03898},
  urldate = {2025-06-22},
  abstract = {In this article, we will look at autoencoders. This article covers the mathematics and the fundamental concepts of autoencoders. We will discuss what they are, what the limitations are, the typical use cases, and we will look at some examples. We will start with a general introduction to autoencoders, and we will discuss the role of the activation function in the output layer and the loss function. We will then discuss what the reconstruction error is. Finally, we will look at typical applications as dimensionality reduction, classification, denoising, and anomaly detection. This paper contains the notes of a PhD-level lecture on autoencoders given in 2021.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Michelucci - 2022 - An Introduction to Autoencoders.pdf;/home/paris/Zotero/storage/42JHL8U8/2201.html}
}

@misc{millerExplainableAIBeware2017,
  title = {Explainable {{AI}}: {{Beware}} of {{Inmates Running}} the {{Asylum Or}}: {{How I Learnt}} to {{Stop Worrying}} and {{Love}} the {{Social}} and {{Behavioural Sciences}}},
  shorttitle = {Explainable {{AI}}},
  author = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
  year = 2017,
  month = dec,
  number = {arXiv:1712.00547},
  eprint = {1712.00547},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1712.00547},
  urldate = {2025-09-08},
  abstract = {In his seminal book The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience; a phenomenon he refers to as the `inmates running the asylum'. This paper argues that explainable AI risks a similar fate. While the reemergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science; and if evaluation of these models is focused more on people than on technology. From a light scan of literature, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these fields that are relevant to explainable AI.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/paris/gdrive/Zotero/Miller et al. - 2017 - Explainable AI Beware of Inmates Running the Asylum Or How I Learnt to Stop Worrying and Love the.pdf}
}

@misc{millerExplanationArtificialIntelligence2018,
  title = {Explanation in {{Artificial Intelligence}}: {{Insights}} from the {{Social Sciences}}},
  shorttitle = {Explanation in {{Artificial Intelligence}}},
  author = {Miller, Tim},
  year = 2018,
  month = aug,
  number = {arXiv:1706.07269},
  eprint = {1706.07269},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1706.07269},
  urldate = {2025-09-06},
  abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a `good' explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/paris/gdrive/Zotero/Miller - 2018 - Explanation in Artificial Intelligence Insights from the Social Sciences.pdf}
}

@misc{millerSupportVectorMachine2014,
  title = {Support Vector Machine Classification of Dimensionally Reduced Structural {{MRI}} Images for Dementia},
  author = {Miller, V. A. and Erlien, S. and Piersol, J.},
  year = 2014,
  month = jun,
  number = {arXiv:1406.6568},
  eprint = {1406.6568},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1406.6568},
  urldate = {2025-08-15},
  abstract = {We classify very-mild to moderate dementia in patients (CDR ranging from 0 to 2) using a support vector machine classifier acting on dimensionally reduced feature set derived from MRI brain scans of the 416 subjects available in the OASIS-Brains dataset. We use image segmentation and principal component analysis to reduce the dimensionality of the data. Our resulting feature set contains 11 features for each subject. Performance of the classifiers is evaluated using 10-fold cross-validation. Using linear and (gaussian) kernels, we obtain a training classification accuracy of 86.4\% (90.1\%), test accuracy of 85.0\% (85.7\%), test precision of 68.7\% (68.5\%), test recall of 68.0\% (74.0\%), and test Matthews correlation coefficient of 0.594 (0.616).},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Physics - Medical Physics},
  file = {/home/paris/gdrive/Zotero/Miller et al. - 2014 - Support vector machine classification of dimensionally reduced structural MRI images for dementia.pdf}
}

@article{mishroSurveyStateoftheArtDenoising2022a,
  title = {A {{Survey}} on {{State-of-the-Art Denoising Techniques}} for {{Brain Magnetic Resonance Images}}},
  author = {Mishro, Pranaba K. and Agrawal, Sanjay and Panda, Rutuparna and Abraham, Ajith},
  year = 2022,
  journal = {IEEE Reviews in Biomedical Engineering},
  volume = {15},
  pages = {184--199},
  issn = {1941-1189},
  doi = {10.1109/RBME.2021.3055556},
  urldate = {2025-05-21},
  abstract = {The accuracy of the magnetic resonance (MR) image diagnosis depends on the quality of the image, which degrades mainly due to noise and artifacts. The noise is introduced because of erroneous imaging environment or distortion in the transmission system. Therefore, denoising methods play an important role in enhancing the image quality. However, a tradeoff between denoising and preserving the structural details is required. Most of the existing surveys are conducted on a specific MR image modality or on limited denoising schemes. In this context, a comprehensive review on different MR image denoising techniques is inevitable. This survey suggests a new direction in categorizing the MR image denoising techniques. The categorization of the different image models used in medical image processing serves as the basis of our classification. This study includes recent improvements on deep learning-based denoising methods alongwith important traditional MR image denoising methods. The major challenges and their scope of improvement are also discussed. Further, many more evaluation indices are considered for a fair comparison. An elaborate discussion on selecting appropriate method and evaluation metric as per the kind of data is presented. This study may encourage researchers for further work in this domain.},
  keywords = {biomedical image denoising,brain MRI,Filtering,Image denoising,Image edge detection,Magnetic resonance imaging,Noise reduction,Transforms,Wavelet coefficients,Wavelet domain},
  file = {/home/paris/gdrive/Zotero/Denosing/Mishro et al. - 2022 - A Survey on State-of-the-Art Denoising Techniques for Brain Magnetic Resonance Images.pdf;/home/paris/Zotero/storage/HDH2CQUS/9340274.html}
}

@article{mohanSurveyMagneticResonance2014,
  title = {A Survey on the Magnetic Resonance Image Denoising Methods},
  author = {Mohan, J. and Krishnaveni, V. and Guo, Yanhui},
  year = 2014,
  month = jan,
  journal = {Biomedical Signal Processing and Control},
  volume = {9},
  pages = {56--69},
  issn = {17468094},
  doi = {10.1016/j.bspc.2013.10.007},
  urldate = {2025-05-21},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Denosing/Mohan et al. - 2014 - A survey on the magnetic resonance image denoising methods.pdf}
}

@article{monteroIntraInterscannerCT2025,
  title = {Intra- and Inter-Scanner {{CT}} Variability and Their Impact on Diagnostic Tasks},
  author = {Montero, Isabel and {Sotoudeh-Paima}, Saman and Abadi, Ehsan and Samei, Ehsan},
  year = 2025,
  month = feb,
  journal = {Proceedings of SPIE--the International Society for Optical Engineering},
  volume = {13405},
  pages = {134054C},
  issn = {0277-786X},
  doi = {10.1117/12.3047016},
  urldate = {2025-10-15},
  abstract = {The increased development and production of Computed Tomography (CT) scanner technology has expanded patient access to advanced and affordable medical imaging technologies but has also introduced sources of variability in the clinical imaging landscape, which may influence patient care. This study examines the impact of intra-scanner and inter-scanner variability on image quality and quantitative imaging tasks, with a focus on the detectability index (d') as a measure of patient-specific task performance. We evaluated 813 clinical phantom image sets from the COPDGene study, aggregated by CT scanner make, model, and acquisition and reconstruction protocol. Each phantom image set was assessed for image quality metrics, including the Noise Power Spectrum (NPS) and in-plane Modulation Transfer Function (MTF). The d' index was calculated for 12 hypothetical lesion detection tasks, emulating clinically relevant lung and liver lesions of varying sizes and contrast levels. Qualitatively, analysis showed intra-scanner variability in NPS and MTF curves measured for identical acquisition and reconstruction settings. Inter-scanner comparisons demonstrated variability in d' measurements across different scanner makes and models, of similar acquisition and reconstruction settings. The study showed an intra-scanner variability of up to 13.7\% and an inter-scanner variability of up to 19.3\% in the d' index. These findings emphasize the need for considering scanner variability in patient-centered care and indicate that CT technology may influence the reliability of imaging tasks. The results of this study further motivate the development of virtual scanner models to better model and mitigate the variability observed in the clinical imaging landscape.},
  pmcid = {PMC12035824},
  pmid = {40302992},
  file = {/home/paris/Zotero/storage/XFY5C3RQ/Montero et al. - 2025 - Intra- and inter-scanner CT variability and their impact on diagnostic tasks.pdf}
}

@article{morenolopezEvaluationMRIDenoising2021,
  title = {Evaluation of {{MRI Denoising Methods Using Unsupervised Learning}}},
  author = {Moreno L{\'o}pez, Marc and Frederick, Joshua M. and Ventura, Jonathan},
  year = 2021,
  month = jun,
  journal = {Frontiers in Artificial Intelligence},
  volume = {4},
  publisher = {Frontiers},
  issn = {2624-8212},
  doi = {10.3389/frai.2021.642731},
  urldate = {2025-06-02},
  abstract = {In this paper we evaluate two unsupervised approaches to denoise Magnetic Resonance Images (MRI) in the complex image space using the raw information that k-space holds. The first method is based on Stein's Unbiased Risk Estimator, while the second approach is based on a blindspot network, which limits the network's receptive field. Both methods are tested on two different datasets, one containing real knee MRI and the other consists of synthetic brain MRI. These datasets contain information about the complex image space which will be used for denoising purposes. Both networks are compared against a state-of-the-art algorithm, Non-Local Means (NLM) using quantitative and qualitative measures. For most given metrics and qualitative measures, both networks outperformed NLM, and they prove to be reliable denoising methods.},
  langid = {english},
  keywords = {deep learning,denoising,K-Space,MRI,unsupervised},
  file = {/home/paris/gdrive/Zotero/Denosing/Moreno López et al. - 2021 - Evaluation of MRI Denoising Methods Using Unsupervised Learning.pdf}
}

@article{mosconiBrainGlucoseMetabolism2005,
  title = {Brain Glucose Metabolism in the Early and Specific Diagnosis of {{Alzheimer}}'s Disease},
  author = {Mosconi, Lisa},
  year = 2005,
  month = apr,
  journal = {European Journal of Nuclear Medicine and Molecular Imaging},
  volume = {32},
  number = {4},
  pages = {486--510},
  issn = {1619-7089},
  doi = {10.1007/s00259-005-1762-7},
  urldate = {2025-03-30},
  abstract = {The demographics of aging suggest a great need for the early diagnosis of dementia and the development of preventive strategies. Neuropathology and structural MRI studies have pointed to the medial temporal lobe (MTL) as the brain region earliest affected in Alzheimer's disease (AD). MRI findings provide strong evidence that in mild cognitive impairments (MCI), AD-related volume losses can be reproducibly detected in the hippocampus, the entorhinal cortex (EC) and, to a lesser extent, the parahippocampal gyrus; they also indicate that lateral temporal lobe changes are becoming increasingly useful in predicting the transition to dementia. Fluoro-2-deoxy-D-glucose positron emission tomography (FDG-PET) imaging has revealed glucose metabolic reductions in the parieto-temporal, frontal and posterior cingulate cortices to be the hallmark of AD. Overall, the pattern of cortical metabolic changes has been useful for the prediction of future AD as well as in distinguishing AD from other neurodegenerative diseases. FDG-PET on average achieves 90\% sensitivity in identifying AD, although specificity in differentiating AD from other dementias is lower. Moreover, recent MRI-guided FDG-PET studies have shown that MTL hypometabolism is the most specific and sensitive measure for the identification of MCI, while the utility of cortical deficits is controversial. This review highlights cross-sectional, prediction and longitudinal FDG-PET studies and attempts to put into perspective the value of FDG-PET in diagnosing AD-like changes, particularly at an early stage, and in providing diagnostic specificity. The examination of MTL structures, which has so far been exclusive to MRI protocols, is then examined as a possible strategy to improve diagnostic specificity. All told, there is considerable promise that early and specific diagnosis is feasible through a combination of imaging modalities.},
  langid = {english},
  keywords = {Alzheimer's disease,Brain metabolism,Differential diagnosis,Early diagnosis,Mild cognitive impairment,Positron emission tomography},
  file = {/home/paris/Zotero/storage/IBKGA85Y/Mosconi - 2005 - Brain glucose metabolism in the early and specific diagnosis of Alzheimer’s disease.pdf}
}

@article{mosconiBrainGlucoseMetabolism2005a,
  title = {Brain Glucose Metabolism in the Early and Specific Diagnosis of {{Alzheimer}}'s Disease},
  author = {Mosconi, Lisa},
  year = 2005,
  month = apr,
  journal = {European Journal of Nuclear Medicine and Molecular Imaging},
  volume = {32},
  number = {4},
  pages = {486--510},
  issn = {1619-7089},
  doi = {10.1007/s00259-005-1762-7},
  urldate = {2025-03-30},
  abstract = {The demographics of aging suggest a great need for the early diagnosis of dementia and the development of preventive strategies. Neuropathology and structural MRI studies have pointed to the medial temporal lobe (MTL) as the brain region earliest affected in Alzheimer's disease (AD). MRI findings provide strong evidence that in mild cognitive impairments (MCI), AD-related volume losses can be reproducibly detected in the hippocampus, the entorhinal cortex (EC) and, to a lesser extent, the parahippocampal gyrus; they also indicate that lateral temporal lobe changes are becoming increasingly useful in predicting the transition to dementia. Fluoro-2-deoxy-D-glucose positron emission tomography (FDG-PET) imaging has revealed glucose metabolic reductions in the parieto-temporal, frontal and posterior cingulate cortices to be the hallmark of AD. Overall, the pattern of cortical metabolic changes has been useful for the prediction of future AD as well as in distinguishing AD from other neurodegenerative diseases. FDG-PET on average achieves 90\% sensitivity in identifying AD, although specificity in differentiating AD from other dementias is lower. Moreover, recent MRI-guided FDG-PET studies have shown that MTL hypometabolism is the most specific and sensitive measure for the identification of MCI, while the utility of cortical deficits is controversial. This review highlights cross-sectional, prediction and longitudinal FDG-PET studies and attempts to put into perspective the value of FDG-PET in diagnosing AD-like changes, particularly at an early stage, and in providing diagnostic specificity. The examination of MTL structures, which has so far been exclusive to MRI protocols, is then examined as a possible strategy to improve diagnostic specificity. All told, there is considerable promise that early and specific diagnosis is feasible through a combination of imaging modalities.},
  langid = {english},
  keywords = {Alzheimer's disease,Brain metabolism,Differential diagnosis,Early diagnosis,Mild cognitive impairment,Positron emission tomography},
  file = {/home/paris/Zotero/storage/H5M7DKU4/Mosconi - 2005 - Brain glucose metabolism in the early and specific diagnosis of Alzheimer’s disease.pdf}
}

@article{motovilovaOverviewMethodsNoise2022,
  title = {Overview of {{Methods}} for {{Noise}} and {{Heat Reduction}} in {{MRI Gradient Coils}}},
  author = {Motovilova, Elizaveta and Winkler, Simone Angela},
  year = 2022,
  month = jul,
  journal = {Frontiers in physics},
  volume = {10},
  pages = {907619},
  issn = {2296-424X},
  doi = {10.3389/fphy.2022.907619},
  urldate = {2025-06-02},
  abstract = {Magnetic resonance imaging (MRI) gradient coils produce acoustic noise due to coil conductor vibrations caused by large Lorentz forces. Accurate sound pressure levels and modeling of heating are essential for the assessment of gradient coil safety. This work reviews the state-of-the-art numerical methods used in accurate gradient coil modeling and prediction of sound pressure levels (SPLs) and temperature rise. We review several approaches proposed for noise level reduction of high-performance gradient coils, with a maximum noise reduction of 20 decibels (dB) demonstrated. An efficient gradient cooling technique is also presented.},
  pmcid = {PMC9733908},
  pmid = {36506821},
  file = {/home/paris/gdrive/Zotero/Denosing/Motovilova and Winkler - 2022 - Overview of Methods for Noise and Heat Reduction in MRI Gradient Coils.pdf}
}

@article{muellerAlzheimersDiseaseNeuroimaging2005,
  title = {The {{Alzheimer}}'s Disease Neuroimaging Initiative},
  author = {Mueller, Susanne G. and Weiner, Michael W. and Thal, Leon J. and Petersen, Ronald C. and Jack, Clifford and Jagust, William and Trojanowski, John Q. and Toga, Arthur W. and Beckett, Laurel},
  year = 2005,
  journal = {Neuroimaging Clinics of North America},
  volume = {15},
  number = {4},
  pages = {869},
  publisher = {NIH Public Access},
  urldate = {2024-11-09},
  file = {/home/paris/Zotero/storage/VNQV2TVI/PMC2376747.html}
}

@article{muellerAlzheimersDiseaseNeuroimaging2005b,
  title = {The {{Alzheimer}}'s {{Disease Neuroimaging Initiative}}},
  author = {Mueller, Susanne G. and Weiner, Michael W. and Thal, Leon J. and Petersen, Ronald C. and Jack, Clifford and Jagust, William and Trojanowski, John Q. and Toga, Arthur W. and Beckett, Laurel},
  year = 2005,
  month = nov,
  journal = {Neuroimaging Clinics},
  volume = {15},
  number = {4},
  pages = {869--877},
  publisher = {Elsevier},
  issn = {1052-5149, 1557-9867},
  doi = {10.1016/j.nic.2005.09.008},
  urldate = {2025-10-17},
  langid = {english},
  file = {/home/paris/Zotero/storage/HLRU2FXI/Mueller et al. - 2005 - The Alzheimer's Disease Neuroimaging Initiative.pdf}
}

@article{muhammadUnveilingBlackBox2024,
  title = {Unveiling the Black Box: {{A}} Systematic Review of {{Explainable Artificial Intelligence}} in Medical Image Analysis},
  shorttitle = {Unveiling the Black Box},
  author = {Muhammad, Dost and Bendechache, Malika},
  year = 2024,
  month = aug,
  journal = {Computational and Structural Biotechnology Journal},
  volume = {24},
  pages = {542--560},
  issn = {2001-0370},
  doi = {10.1016/j.csbj.2024.08.005},
  urldate = {2025-10-27},
  abstract = {This systematic literature review examines state-of-the-art Explainable Artificial Intelligence (XAI) methods applied to medical image analysis, discussing current challenges and future research directions, and exploring evaluation metrics used to assess XAI approaches. With the growing efficiency of Machine Learning (ML) and Deep Learning (DL) in medical applications, there's a critical need for adoption in healthcare. However, their ``black-box'' nature, where decisions are made without clear explanations, hinders acceptance in clinical settings where decisions have significant medicolegal consequences. Our review highlights the advanced XAI methods, identifying how they address the need for transparency and trust in ML/DL decisions. We also outline the challenges faced by these methods and propose future research directions to improve XAI in healthcare., This paper aims to bridge the gap between cutting-edge computational techniques and their practical application in healthcare, nurturing a more transparent, trustworthy, and effective use of AI in medical settings. The insights guide both research and industry, promoting innovation and standardisation in XAI implementation in healthcare.},
  pmcid = {PMC11382209},
  pmid = {39252818},
  file = {/home/paris/Zotero/storage/MUG4SK6W/Muhammad and Bendechache - 2024 - Unveiling the black box A systematic review of Explainable Artificial Intelligence in medical image.pdf}
}

@article{MultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  year = 1989,
  month = jan,
  journal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  publisher = {Pergamon},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  urldate = {2025-10-14},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions ar\dots},
  langid = {american}
}

@misc{MVIMindNovelDeepLearning,
  title = {{{MVI-Mind}}: {{A Novel Deep-Learning Strategy Using Computed Tomography}} ({{CT}})-{{Based Radiomics}} for {{End-to-End High Efficiency Prediction}} of {{Microvascular Invasion}} in {{Hepatocellular Carcinoma}}},
  urldate = {2025-06-24},
  howpublished = {https://www.mdpi.com/2072-6694/14/12/2956},
  file = {/home/paris/gdrive/Zotero/MVI-Mind A Novel Deep-Learning Strategy Using Computed Tomography (CT)-Based Radiomics for End-to-E.pdf}
}

@article{nagImageRegistrationTechniques2017,
  title = {Image {{Registration Techniques}}: {{A Survey}}},
  shorttitle = {Image {{Registration Techniques}}},
  author = {Nag, Sayan},
  year = 2017,
  eprint = {1712.07540},
  primaryclass = {cs},
  doi = {10.17605/OSF.IO/RV65C},
  urldate = {2025-07-10},
  abstract = {Image Registration is the process of aligning two or more images of the same scene with reference to a particular image. The images are captured from various sensors at different times and at multiple view-points. Thus to get a better picture of any change of a scene or object over a considerable period of time image registration is important. Image registration finds application in medical sciences, remote sensing and in computer vision. This paper presents a detailed review of several approaches which are classified accordingly along with their contributions and drawbacks. The main steps of an image registration procedure are also discussed. Different performance measures are presented that determine the registration quality and accuracy. The scope for the future research are presented as well.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Multimedia},
  file = {/home/paris/gdrive/Zotero/Nag - 2017 - Image Registration Techniques A Survey.pdf;/home/paris/Zotero/storage/9QRWJA62/1712.html}
}

@misc{nampalleDeepMediXDeepLearningDriven2023,
  title = {{{DeepMediX}}: {{A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across}} the {{Spectrum}}},
  shorttitle = {{{DeepMediX}}},
  author = {Nampalle, Kishore Babu and Singh, Pradeep and Narayan, Uppala Vivek and Raman, Balasubramanian},
  year = 2023,
  month = jul,
  number = {arXiv:2307.00324},
  eprint = {2307.00324},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.00324},
  urldate = {2025-10-16},
  abstract = {In the rapidly evolving landscape of medical imaging diagnostics, achieving high accuracy while preserving computational efficiency remains a formidable challenge. This work presents \textbackslash texttt\textbraceleft DeepMediX\textbraceright, a groundbreaking, resource-efficient model that significantly addresses this challenge. Built on top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI scans and skin cancer images, with superior performance demonstrated on both binary and multiclass skin cancer datasets. It provides a solution to labor-intensive manual processes, the need for large datasets, and complexities related to image properties. DeepMediX's design also includes the concept of Federated Learning, enabling a collaborative learning approach without compromising data privacy. This approach allows diverse healthcare institutions to benefit from shared learning experiences without the necessity of direct data access, enhancing the model's predictive power while preserving the privacy and integrity of sensitive patient data. Its low computational footprint makes DeepMediX suitable for deployment on handheld devices, offering potential for real-time diagnostic support. Through rigorous testing on standard datasets, including the ISIC2018 for dermatological research, DeepMediX demonstrates exceptional diagnostic capabilities, matching the performance of existing models on almost all tasks and even outperforming them in some cases. The findings of this study underline significant implications for the development and deployment of AI-based tools in medical imaging and their integration into point-of-care settings. The source code and models generated would be released at https://github.com/kishorebabun/DeepMediX.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/paris/Zotero/storage/QGD9RXJR/Nampalle et al. - 2023 - DeepMediX A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum.pdf;/home/paris/Zotero/storage/C57EJCF9/2307.html}
}

@misc{narazaniPETAllYou2022,
  title = {Is a {{PET}} All You Need? {{A}} Multi-Modal Study for {{Alzheimer}}'s Disease Using {{3D CNNs}}},
  shorttitle = {Is a {{PET}} All You Need?},
  author = {Narazani, Marla and Sarasua, Ignacio and P{\"o}lsterl, Sebastian and Lizarraga, Aldana and Yakushev, Igor and Wachinger, Christian},
  year = 2022,
  month = jul,
  number = {arXiv:2207.02094},
  eprint = {2207.02094},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.02094},
  urldate = {2025-10-24},
  abstract = {Alzheimer's Disease (AD) is the most common form of dementia and often difficult to diagnose due to the multifactorial etiology of dementia. Recent works on neuroimaging-based computer-aided diagnosis with deep neural networks (DNNs) showed that fusing structural magnetic resonance images (sMRI) and fluorodeoxyglucose positron emission tomography (FDG-PET) leads to improved accuracy in a study population of healthy controls and subjects with AD. However, this result conflicts with the established clinical knowledge that FDG-PET better captures AD-specific pathologies than sMRI. Therefore, we propose a framework for the systematic evaluation of multi-modal DNNs and critically re-evaluate single- and multi-modal DNNs based on FDG-PET and sMRI for binary healthy vs. AD, and three-way healthy/mild cognitive impairment/AD classification. Our experiments demonstrate that a single-modality network using FDG-PET performs better than MRI (accuracy 0.91 vs 0.87) and does not show improvement when combined. This conforms with the established clinical knowledge on AD biomarkers, but raises questions about the true benefit of multi-modal DNNs. We argue that future work on multi-modal fusion should systematically assess the contribution of individual modalities following our proposed evaluation framework. Finally, we encourage the community to go beyond healthy vs. AD classification and focus on differential diagnosis of dementia, where fusing multi-modal image information conforms with a clinical need.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/Zotero/storage/LUKXAZHM/Narazani et al. - 2022 - Is a PET all you need A multi-modal study for Alzheimer's disease using 3D CNNs.pdf;/home/paris/Zotero/storage/J97GXYCP/2207.html}
}

@article{NewMethodsMRI2012,
  title = {New Methods for {{MRI}} Denoising Based on Sparseness and Self-Similarity},
  year = 2012,
  month = jan,
  journal = {Medical Image Analysis},
  volume = {16},
  number = {1},
  pages = {18--27},
  publisher = {Elsevier},
  issn = {1361-8415},
  doi = {10.1016/j.media.2011.04.003},
  urldate = {2025-05-17},
  abstract = {This paper proposes two new methods for the three-dimensional denoising of magnetic resonance images that exploit the sparseness and self-similarity p\dots},
  langid = {american},
  file = {/home/paris/gdrive/Zotero/Denosing/2012 - New methods for MRI denoising based on sparseness and self-similarity.pdf;/home/paris/Zotero/storage/RQUKPPH9/S1361841511000491.html}
}

@inproceedings{niazClassImbalanceProblems2022,
  title = {Class {{Imbalance Problems}} in {{Machine Learning}}: {{A Review}} of {{Methods And Future Challenges}}},
  shorttitle = {Class {{Imbalance Problems}} in {{Machine Learning}}},
  booktitle = {Proceedings of the 2nd {{International Conference}} on {{Computing Advancements}}},
  author = {Niaz, Nazim Uddin and Shahariar, K.M. Nadim and Patwary, Muhammed J. A.},
  year = 2022,
  month = mar,
  pages = {485--490},
  publisher = {ACM},
  address = {Dhaka Bangladesh},
  doi = {10.1145/3542954.3543024},
  urldate = {2025-10-14},
  isbn = {978-1-4503-9734-6},
  langid = {english}
}

@article{nielsenNeuralNetworksDeep2015,
  title = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Nielsen, Michael A.},
  year = 2015,
  publisher = {Determination Press},
  urldate = {2025-09-11},
  langid = {english},
  file = {/home/paris/Zotero/storage/Y7S7VKQF/neuralnetworksanddeeplearning.com.html}
}

@article{niranjankumarSVMBasedClassifierEarly2024,
  title = {{{SVM-Based Classifier For Early Detection Of Alzheimer}}'s {{Disease}}},
  author = {Niranjan Kumar, Parvatham},
  year = 2024,
  month = may,
  journal = {Educational Administration: Theory and Practice},
  pages = {1120--1131},
  doi = {10.53555/kuey.v30i5.3022},
  urldate = {2025-07-28},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Niranjan Kumar - 2024 - SVM-Based Classifier For Early Detection Of Alzheimer's Disease.pdf}
}

@article{nordbergUsePETAlzheimer2010,
  title = {The Use of {{PET}} in {{Alzheimer}} Disease},
  author = {Nordberg, Agneta and Rinne, Juha O. and Kadir, Ahmadul and L{\aa}ngstr{\"o}m, Bengt},
  year = 2010,
  journal = {Nature Reviews Neurology},
  volume = {6},
  number = {2},
  pages = {78--87},
  publisher = {Nature Publishing Group UK London},
  urldate = {2025-03-28}
}

@misc{novosadAccurateRobustSegmentation2019,
  title = {Accurate and Robust Segmentation of Neuroanatomy in {{T1-weighted MRI}} by Combining Spatial Priors with Deep Convolutional Neural Networks},
  author = {Novosad, Philip and Fonov, Vladimir and Collins, D. Louis},
  year = 2019,
  month = feb,
  number = {arXiv:1902.01478},
  eprint = {1902.01478},
  primaryclass = {q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.01478},
  urldate = {2026-01-16},
  abstract = {Neuroanatomical segmentation in magnetic resonance imaging (MRI) of the brain is a prerequisite for volume, thickness and shape measurements. This work introduces a new highly accurate and versatile method based on 3D convolutional neural networks for the automatic segmentation of neuroanatomy in T1-weighted MRI. In combination with a deep 3D fully convolutional architecture, efficient linear registration-derived spatial priors are used to incorporate additional spatial context into the network. An aggressive data augmentation scheme using random elastic deformations is also used to regularize the networks, allowing for excellent performance even in cases where only limited labelled training data are available. Applied to hippocampus segmentation in an elderly population (mean Dice coefficient = 92.1\%) and sub-cortical segmentation in a healthy adult population (mean Dice coefficient = 89.5\%), we demonstrate new state-of-the-art accuracies and a high robustness to outliers with the same architecture. Further validation on a multi-structure segmentation task in a scan-rescan dataset demonstrates accuracy (mean Dice coefficient = 86.6\%) similar to the scan-rescan reliability of expert manual segmentations (mean Dice coefficient = 86.9\%), and improved reliability compared to both expert manual segmentations and automated segmentations using FIRST. Furthermore, our method maintains a highly competitive runtime performance (e.g. requiring only 10 seconds for left/right hippocampal segmentation in 1x1x1 MNI stereotaxic space), orders of magnitude faster than conventional multi-atlas segmentation methods.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Quantitative Methods},
  file = {/home/paris/Zotero/storage/VKXKW4XM/Novosad et al. - 2019 - Accurate and robust segmentation of neuroanatomy in T1-weighted MRI by combining spatial priors with.pdf}
}

@article{novosadEfficientAccurateMethod2018,
  title = {An Efficient and Accurate Method for Robust Inter-Dataset Brain Extraction and Comparisons with 9 Other Methods},
  author = {Novosad, Philip and Collins, D. Louis and {Alzheimer's Disease Neuroimaging Initiative}},
  year = 2018,
  month = nov,
  journal = {Human Brain Mapping},
  volume = {39},
  number = {11},
  pages = {4241--4257},
  issn = {1097-0193},
  doi = {10.1002/hbm.24243},
  abstract = {Brain extraction is an important first step in many magnetic resonance neuroimaging studies. Due to variability in brain morphology and in the appearance of the brain due to differences in scanner acquisition parameters, the development of a generally applicable brain extraction algorithm has proven challenging. Learning-based brain extraction algorithms in particular perform well when the target and training images are sufficiently similar, but often perform worse when this condition is not met. In this study, we propose a new patch-based multi-atlas segmentation method for brain extraction which is specifically developed for accurate and robust processing across datasets. Using a diverse collection of labeled images from 5 different datasets, extensive comparisons were made with 9 other commonly used brain extraction methods, both before and after applying error correction (a machine learning method for automatically correcting segmentation errors) to each method. The proposed method performed equal to or better than the other methods in each of two segmentation scenarios: a challenging inter-dataset segmentation scenario in which no dataset-specific atlases were used (mean Dice coefficient 98.57\%, volumetric correlation 0.994 across datasets following error correction), and an intra-dataset segmentation scenario in which only dataset-specific atlases were used (mean Dice coefficient 99.02\%, volumetric correlation 0.998 across datasets following error correction). Furthermore, combined with error correction, the proposed method runs in less than one-tenth of the time required by the other top-performing methods in the challenging inter-dataset comparisons. Validation on an independent multi-centre dataset also confirmed the excellent performance of the proposed method.},
  langid = {english},
  pmcid = {PMC8022276},
  pmid = {29972616},
  keywords = {accurate,Adult,Aged,Algorithms,Atlases as Topic,Brain,brain extraction,Child,efficient,error correction,fast,Female,Humans,Magnetic Resonance Imaging,Male,multi-atlas segmentation,Multicenter Studies as Topic,Neuroimaging,patch-based label fusion,Pattern Recognition Automated,robust,skull stripping,Young Adult}
}

@article{nussbergerPublicAttitudesValue2022,
  title = {Public Attitudes Value Interpretability but Prioritize Accuracy in {{Artificial Intelligence}}},
  author = {Nussberger, Anne-Marie and Luo, Lan and Celis, L. Elisa and Crockett, M. J.},
  year = 2022,
  month = oct,
  journal = {Nature Communications},
  volume = {13},
  pages = {5821},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-33417-3},
  urldate = {2025-10-27},
  abstract = {As Artificial Intelligence (AI) proliferates across important social institutions, many of the most powerful AI systems available are difficult to interpret for end-users and engineers alike. Here, we sought to characterize public attitudes towards AI interpretability. Across seven studies (N\,=\,2475), we demonstrate robust and positive attitudes towards interpretable AI among non-experts that generalize across a variety of real-world applications and follow predictable patterns. Participants value interpretability positively across different levels of AI autonomy and accuracy, and rate interpretability as more important for AI decisions involving high stakes and scarce resources. Crucially, when AI interpretability trades off against AI accuracy, participants prioritize accuracy over interpretability under the same conditions driving positive attitudes towards interpretability in the first place: amidst high stakes and scarce resources. These attitudes could drive a proliferation of AI systems making high-impact ethical decisions that are difficult to explain and understand., For many AI systems, it is hard to interpret how they make decisions. Here, the authors show that non-experts value interpretability in AI, especially for decisions involving high stakes and scarce resources, but they sacrifice AI interpretability when it trades off against AI accuracy.},
  pmcid = {PMC9528860},
  pmid = {36192416},
  file = {/home/paris/Zotero/storage/N7EV6JT6/Nussberger et al. - 2022 - Public attitudes value interpretability but prioritize accuracy in Artificial Intelligence.pdf}
}

@patent{nyulMethodStandardizingMR2003,
  title = {Method for Standardizing the {{MR}} Image Intensity Scale},
  author = {Ny{\'u}l, L{\'a}szl{\'o} G. and Udupa, Jayaram K.},
  year = 2003,
  month = jun,
  publisher = {Google Patents},
  urldate = {2025-06-09},
  annotation = {GSCC: 0000038 2025-06-15T15:39:23.236Z 0},
  file = {/home/paris/Zotero/storage/AR9XIZJV/Nyúl and Udupa - 2003 - Method for standardizing the MR image intensity scale.pdf}
}

@article{nyulNewVariantsMethod2000,
  title = {New Variants of a Method of {{MRI}} Scale Standardization},
  author = {Ny{\'u}l, L{\'a}szl{\'o} G. and Udupa, Jayaram K. and Zhang, Xuan},
  year = 2000,
  journal = {IEEE transactions on medical imaging},
  volume = {19},
  number = {2},
  pages = {143--150},
  publisher = {IEEE},
  urldate = {2025-06-10},
  file = {/home/paris/Zotero/storage/N5348DIV/Nyúl et al. - 2000 - New variants of a method of MRI scale standardization.pdf}
}

@article{odusamiPixelLevelFusionApproach2023,
  title = {Pixel-{{Level Fusion Approach}} with {{Vision Transformer}} for {{Early Detection}} of {{Alzheimer}}'s {{Disease}}},
  author = {Odusami, Modupe and Maskeli{\=u}nas, Rytis and Dama{\v s}evi{\v c}ius, Robertas},
  year = 2023,
  month = jan,
  journal = {Electronics},
  volume = {12},
  number = {5},
  pages = {1218},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics12051218},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease (AD) has become a serious hazard to human health in recent years, and proper screening and diagnosis of AD remain a challenge. Multimodal neuroimaging input can help identify AD in the early mild cognitive impairment (EMCI) and late mild cognitive impairment (LMCI) stages from normal cognitive development using magnetic resonance imaging (MRI) and positron emission tomography (PET). MRI provides useful information on brain structural abnormalities, while PET data provide the difference between physiological and pathological changes in brain anatomy. The precision of diagnosing AD can increase when these data are combined. However, they are heterogeneous and appropriate, and an adequate number of features are required for AD classification. This paper proposed a multimodal fusion-based approach that uses a mathematical technique called discrete wavelet transform (DWT) to analyse the data, and the optimisation of this technique is achieved through transfer learning using a pre-trained neural network called VGG16. The final fused image is reconstructed using inverse discrete wavelet transform (IDWT). The fused images are classified using a pre-trained vision transformer. The evaluation of the benchmark Alzheimer's disease neuroimaging initiative (ADNI) dataset shows an accuracy of 81.25\% for AD/EMCI and AD/LMCI in MRI test data, as well as 93.75\% for AD/EMCI and AD/LMCI in PET test data. The proposed model performed better than existing studies when tested on PET data with an accuracy of 93.75\%.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Alzheimer's disease,data fusion,MRI,PET,vision transformer},
  file = {/home/paris/Zotero/storage/XCZM7GCK/Odusami et al. - 2023 - Pixel-Level Fusion Approach with Vision Transformer for Early Detection of Alzheimer’s Disease.pdf}
}

@article{olafronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  author = {{Olaf Ronneberger} and Ronneberger, Olaf and {Philipp Fischer} and Fischer, Philipp and {Thomas Brox} and Brox, Thomas},
  year = 2015,
  month = oct,
  pages = {234--241},
  doi = {10.1007/978-3-319-24574-4_28},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  annotation = {MAG ID: 1901129140},
  file = {/home/paris/gdrive/Zotero/Olaf Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf}
}

@article{opitzCloserLookClassification2024,
  title = {A {{Closer Look}} at {{Classification Evaluation Metrics}} and a {{Critical Reflection}} of {{Common Evaluation Practice}}},
  author = {Opitz, Juri},
  year = 2024,
  month = jun,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {12},
  pages = {820--836},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00675},
  urldate = {2025-08-26},
  abstract = {Classification systems are evaluated in a countless number of papers. However, we find that evaluation practice is often nebulous. Frequently, metrics are selected without arguments, and blurry terminology invites misconceptions. For instance, many works use so-called `macro' metrics to rank systems (e.g., `macro F1') but do not clearly specify what they would expect from such a `macro' metric. This is problematic, since picking a metric can affect research findings and thus any clarity in the process should be maximized. Starting from the intuitive concepts of bias and prevalence, we perform an analysis of common evaluation metrics. The analysis helps us understand the metrics' underlying properties, and how they align with expectations as found expressed in papers. Then we reflect on the practical situation in the field, and survey evaluation practice in recent shared tasks. We find that metric selection is often not supported with convincing arguments, an issue that can make a system ranking seem arbitrary. Our work aims at providing overview and guidance for more informed and transparent metric selection, fostering meaningful evaluation.},
  file = {/home/paris/gdrive/Zotero/Opitz - 2024 - A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Pr.pdf;/home/paris/Zotero/storage/RH7978WD/tacl_a_00675.html}
}

@article{orlhacGuideComBatHarmonization2022,
  title = {A {{Guide}} to {{ComBat Harmonization}} of {{Imaging Biomarkers}} in {{Multicenter Studies}}},
  author = {Orlhac, Fanny and Eertink, Jakoba J. and Cottereau, Anne-S{\'e}gol{\`e}ne and Zijlstra, Jos{\'e}e M. and Thieblemont, Catherine and Meignan, Michel and Boellaard, Ronald and Buvat, Ir{\`e}ne},
  year = 2022,
  month = feb,
  journal = {Journal of Nuclear Medicine},
  volume = {63},
  number = {2},
  pages = {172--179},
  issn = {0161-5505},
  doi = {10.2967/jnumed.121.262464},
  urldate = {2025-06-09},
  abstract = {The impact of PET image acquisition and reconstruction parameters on SUV measurements or radiomic feature values is widely documented. This scanner effect is detrimental to the design and validation of predictive or prognostic models and limits the use of large multicenter cohorts. To reduce the impact of this scanner effect, the ComBat method has been proposed and is now used in various contexts. The purpose of this article is to explain and illustrate the use of ComBat based on practical examples. We also give examples in which the ComBat assumptions are not met and, thus, in which ComBat should not be used.},
  pmcid = {PMC8805779},
  pmid = {34531263},
  annotation = {GSCC: 0000247 2025-06-15T15:39:27.349Z 1.40},
  file = {/home/paris/Zotero/storage/KMM6VUYP/Orlhac et al. - 2022 - A Guide to ComBat Harmonization of Imaging Biomarkers in Multicenter Studies.pdf}
}

@inproceedings{otapoEnhancedAlzheimersDiagnosis2025,
  title = {Enhanced {{Alzheimer}}'s {{Diagnosis}} with a {{Lightweight Transformer}}: {{A Multimodal Fusion}} of {{Sagittal MRI}} and {{Clinical Data}}},
  shorttitle = {Enhanced {{Alzheimer}}'s {{Diagnosis}} with a {{Lightweight Transformer}}},
  booktitle = {2025 32nd {{International Conference}} on {{Systems}}, {{Signals}} and {{Image Processing}} ({{IWSSIP}})},
  author = {Otapo, Akeem Temitope and Khodabandelou, Ghazaleh and Ming, Zuheng and Othmani, Alice},
  year = 2025,
  month = jun,
  pages = {1--5},
  issn = {2157-8702},
  doi = {10.1109/IWSSIP66997.2025.11151973},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease (AD) is a major global health challenge, and early diagnosis is crucial for effective treatment. However, traditional diagnostic methods struggle to extract meaningful patterns from medical data. This study proposes a deep learning approach that integrates brain magnetic resonance imaging and structured clinical data to improve classification accuracy. We fine-tune MobileViT, a hybrid model combining convolutional neural networks (CNNs) and transformers, to analyze sagittal MRI slices, which capture longitudinal brain structures but are underutilized due to lower classification performance and fewer labeled datasets. Additionally, we integrate TabNet to process structured clinical data, including patient age, Socioeconomic Status (SES), Mini-Mental State Examination (MMSE), Clinical Dementia Rating (CDR), and volumetric brain measures. By combining MRI and clinical data through multimodal learning, our approach achieves a peak test accuracy of 99\% on the OASIS-1 (416 participants) and OASIS-2 (150 participants) datasets, using a 70/15/15 train-validationtest split. This outperforms unimodal methods, where MRI-only and clinical-data-only models achieve 94\% and 97\% accuracy, respectively.},
  keywords = {Accuracy,Adaptation models,Alzheimer's disease,Brain modeling,Deep learning,Dementia,Magnetic resonance imaging,MobileViT,Multimodal classification,Particle measurements,Sagittal MRI slices,Socioeconomics,Transformers,Volume measurement},
  file = {/home/paris/Zotero/storage/HST22JGU/11151973.html}
}

@misc{OxygenExtractionFraction,
  title = {Oxygen {{Extraction Fraction}} - an Overview \textbar{} {{ScienceDirect Topics}}},
  urldate = {2025-04-01},
  howpublished = {https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/oxygen-extraction-fraction},
  file = {/home/paris/Zotero/storage/VJ3TQLXQ/oxygen-extraction-fraction.html}
}

@article{ozkanDeepLearningTechniques2024,
  title = {Deep {{Learning Techniques}} for {{Automated Dementia Diagnosis Using Neuroimaging Modalities}}: {{A Systematic Review}}},
  shorttitle = {Deep {{Learning Techniques}} for {{Automated Dementia Diagnosis Using Neuroimaging Modalities}}},
  author = {Ozkan, Dilek and Katar, Oguzhan and Ak, Murat and {Al-Antari}, Mugahed A. and Yasan Ak, Nehir and Yildirim, Ozal and Mir, Hasan S. and Tan, Ru-San and Rajendra Acharya, U.},
  year = 2024,
  journal = {IEEE Access},
  volume = {12},
  pages = {127879--127902},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3454709},
  urldate = {2025-08-16},
  abstract = {Dementia is a condition that often comes with aging and affects how people think, remember, and behave. Diagnosing dementia early is important because it can greatly improve patients' lives. This systematic review looks at how deep learning (DL) techniques have been used to diagnose dementia automatically from 2012 to 2023. We explore how different DL methods like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Deep Neural Networks (DNN) are used to diagnose types of dementia such as Alzheimer's, vascular dementia, and Lewy body dementia. We also discuss the difficulties of using DL for diagnosing dementia, like the lack of large and varied datasets and the challenge of applying models to different groups of people. These issues indicate the need for more dependable and understandable models that consider a wide range of patient characteristics and biomarkers. Longitudinal studies are also needed to understand how the disease progresses and how treatments work. Collaboration among researchers, doctors, and data scientists is crucial to ensure DL models are scientifically sound and effective in clinical settings. In summary, DL techniques show promise for automated dementia diagnosis and could improve how accurately and efficiently it is diagnosed in practice. However, further research is needed to address the challenges highlighted in this review.},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Ozkan et al. - 2024 - Deep Learning Techniques for Automated Dementia Diagnosis Using Neuroimaging Modalities A Systemati.pdf}
}

@article{pandeyComparativeAnalysisKNN2017,
  title = {Comparative Analysis of {{KNN}} Algorithm Using Various Normalization Techniques},
  author = {Pandey, Amit and Jain, Achin},
  year = 2017,
  journal = {International Journal of Computer Network and Information Security},
  volume = {10},
  number = {11},
  pages = {36},
  publisher = {{Modern Education and Computer Science Press}},
  urldate = {2025-06-10}
}

@article{panSynthesizingMissingPET2018,
  title = {Synthesizing {{Missing PET}} from {{MRI}} with {{Cycle-consistent Generative Adversarial Networks}} for {{Alzheimer}}'s {{Disease Diagnosis}}},
  author = {Pan, Yongsheng and Liu, Mingxia and Lian, Chunfeng and Zhou, Tao and Xia, Yong and Shen, Dinggang},
  year = 2018,
  journal = {Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention},
  volume = {11072},
  pages = {455--463},
  doi = {10.1007/978-3-030-00931-1_52},
  urldate = {2025-10-24},
  abstract = {Multi-modal neuroimages (e.g., MRI and PET) have been widely used for diagnosis of brain diseases such as Alzheimer's disease (AD) by providing complementary information. However, in practice, it is unavoidable to have missing data, i.e., missing PET data for many subjects in the ADNI dataset. A straightforward strategy to tackle this challenge is to simply discard subjects with missing PET, but this will significantly reduce the number of training subjects for learning reliable diagnostic models. On the other hand, since different modalities (i.e., MRI and PET) were acquired from the same subject, there often exist underlying relevance between different modalities. Accordingly, we propose a two-stage deep learning framework for AD diagnosis using both MRI and PET data. Specifically, in the first stage, we impute missing PET data based on their corresponding MRI data by using 3D Cycle-consistent Generative Adversarial Networks (3D-cGAN) to capture their underlying relationship. In the second stage, with the complete MRI and PET (i.e., after imputation for the case of missing PET), we develop a deep multi-instance neural network for AD diagnosis and also mild cognitive impairment (MCI) conversion prediction. Experimental results on subjects from ADNI demonstrate that our synthesized PET images with 3D-cGAN are reasonable, and also our two-stage deep learning method outperforms the state-of-the-art methods in AD diagnosis.},
  pmcid = {PMC8336606},
  pmid = {34355223},
  file = {/home/paris/Zotero/storage/TFWC3U66/Pan et al. - 2018 - Synthesizing Missing PET from MRI with Cycle-consistent Generative Adversarial Networks for Alzheime.pdf}
}

@misc{papenmeierHowModelAccuracy2019,
  title = {How Model Accuracy and Explanation Fidelity Influence User Trust},
  author = {Papenmeier, Andrea and Englebienne, Gwenn and Seifert, Christin},
  year = 2019,
  month = jul,
  number = {arXiv:1907.12652},
  eprint = {1907.12652},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1907.12652},
  urldate = {2025-09-09},
  abstract = {Machine learning systems have become popular in fields such as marketing, financing, or data mining. While they are highly accurate, complex machine learning systems pose challenges for engineers and users. Their inherent complexity makes it impossible to easily judge their fairness and the correctness of statistically learned relations between variables and classes. Explainable AI aims to solve this challenge by modelling explanations alongside with the classifiers, potentially improving user trust and acceptance. However, users should not be fooled by persuasive, yet untruthful explanations. We therefore conduct a user study in which we investigate the effects of model accuracy and explanation fidelity, i.e. how truthfully the explanation represents the underlying model, on user trust. Our findings show that accuracy is more important for user trust than explainability. Adding an explanation for a classification result can potentially harm trust, e.g. when adding nonsensical explanations. We also found that users cannot be tricked by high-fidelity explanations into having trust for a bad classifier. Furthermore, we found a mismatch between observed (implicit) and self-reported (explicit) trust.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Papenmeier et al. - 2019 - How model accuracy and explanation fidelity influence user trust.pdf;/home/paris/Zotero/storage/QDFK5ZUL/1907.html}
}

@misc{patroNormalizationPreprocessingStage2015,
  title = {Normalization: {{A Preprocessing Stage}}},
  shorttitle = {Normalization},
  author = {Patro, S. Gopal Krishna and Sahu, Kishore Kumar},
  year = 2015,
  month = mar,
  number = {arXiv:1503.06462},
  eprint = {1503.06462},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1503.06462},
  urldate = {2025-06-03},
  abstract = {As we know that the normalization is a pre-processing stage of any type problem statement. Especially normalization takes important role in the field of soft computing, cloud computing etc. for manipulation of data like scale down or scale up the range of data before it becomes used for further stage. There are so many normalization techniques are there namely Min-Max normalization, Z-score normalization and Decimal scaling normalization. So by referring these normalization techniques we are going to propose one new normalization technique namely, Integer Scaling Normalization. And we are going to show our proposed normalization technique using various data sets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Other Computer Science},
  annotation = {GSCC: 0001816 2025-06-15T15:39:51.770Z 3.39},
  file = {/home/paris/Zotero/storage/RX9RR9C5/Patro and Sahu - 2015 - Normalization A Preprocessing Stage.pdf;/home/paris/Zotero/storage/3377TDVR/1503.html}
}

@misc{patroNormalizationPreprocessingStage2015a,
  title = {Normalization: {{A Preprocessing Stage}}},
  shorttitle = {Normalization},
  author = {Patro, S. Gopal Krishna and Sahu, Kishore Kumar},
  year = 2015,
  month = mar,
  number = {arXiv:1503.06462},
  eprint = {1503.06462},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1503.06462},
  urldate = {2025-04-22},
  abstract = {As we know that the normalization is a pre-processing stage of any type problem statement. Especially normalization takes important role in the field of soft computing, cloud computing etc. for manipulation of data like scale down or scale up the range of data before it becomes used for further stage. There are so many normalization techniques are there namely Min-Max normalization, Z-score normalization and Decimal scaling normalization. So by referring these normalization techniques we are going to propose one new normalization technique namely, Integer Scaling Normalization. And we are going to show our proposed normalization technique using various data sets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Other Computer Science},
  file = {/home/paris/Zotero/storage/ZTZDY22J/Patro and Sahu - 2015 - Normalization A Preprocessing Stage.pdf;/home/paris/Zotero/storage/4UWX8LNT/1503.html}
}

@misc{PDFComparativeStudy,
  title = {({{PDF}}) {{A Comparative Study}} of {{PCA}} and {{LDA}} for {{Dimensionality Reduction}} in a 4-{{Way Classification Framework}}},
  journal = {ResearchGate},
  doi = {10.21203/rs.3.rs-4020987/v1},
  urldate = {2025-08-15},
  abstract = {PDF \textbar{} Alzheimer's disease (AD), recognized as the secondmost impactful neurological disorder and currently incurable, stands as the leading cause of... \textbar{} Find, read and cite all the research you need on ResearchGate},
  howpublished = {https://www.researchgate.net/publication/378806266\_A\_Comparative\_Study\_of\_PCA\_and\_LDA\_for\_Dimensionality\_Reduction\_in\_a\_4-Way\_Classification\_Framework},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/(PDF) A Comparative Study of PCA and LDA for Dimensionality Reduction in a 4-Way Classification Fram.pdf;/home/paris/Zotero/storage/E2EFGJQC/378806266_A_Comparative_Study_of_PCA_and_LDA_for_Dimensionality_Reduction_in_a_4-Way_Classifica.html}
}

@article{PDFDontKnow2025,
  title = {({{PDF}}) {{I Don}}'t {{Know}}, {{Is AI Also Used}} in {{Airbags}}?: {{An Empirical Study}} of {{Folk Concepts}} and {{People}}'s {{Expectations}} of {{Current}} and {{Future Artificial Intelligence}}},
  shorttitle = {({{PDF}}) {{I Don}}'t {{Know}}, {{Is AI Also Used}} in {{Airbags}}?},
  year = 2025,
  month = apr,
  journal = {ResearchGate},
  doi = {10.1515/icom-2021-0009},
  urldate = {2025-09-03},
  abstract = {PDF \textbar{} In 1991, researchers at the center for the Learning Sciences of Carnegie Mellon University were confronted with the confusing question of ``where... \textbar{} Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/2025 - (PDF) I Don’t Know, Is AI Also Used in Airbags An Empirical Study of Folk Concepts and People’s Ex.pdf;/home/paris/Zotero/storage/BA5DZ24N/352638184_I_Don't_Know_Is_AI_Also_Used_in_Airbags_An_Empirical_Study_of_Folk_Concepts_and_Peopl.html}
}

@misc{PDFEfficientDeep2025,
  title = {({{PDF}}) {{Efficient Deep Learning}}: {{A Survey}} of {{Model Compression}} and {{Optimization Techniques}} for {{Resource-Constrained Environments}}},
  shorttitle = {({{PDF}}) {{Efficient Deep Learning}}},
  year = 2025,
  month = aug,
  journal = {ResearchGate},
  doi = {10.13140/RG.2.2.24876.58240},
  urldate = {2025-10-16},
  abstract = {PDF \textbar{} The exponential growth in deep learning model sizes has created unprecedented challenges for deployment in resource-constrained environments. This... \textbar{} Find, read and cite all the research you need on ResearchGate},
  howpublished = {https://www.researchgate.net/publication/394538538\_Efficient\_Deep\_Learning\_A\_Survey\_of\_Model\_Compression\_and\_Optimization\_Techniques\_for\_Resource-Constrained\_Environments},
  langid = {english},
  file = {/home/paris/Zotero/storage/BGFT72IV/394538538_Efficient_Deep_Learning_A_Survey_of_Model_Compression_and_Optimization_Techniques_for.html}
}

@inproceedings{PDFImprovedClassification,
  title = {({{PDF}}) {{Improved Classification}} of {{Alzheimer}}'s {{Disease With Convolutional Neural Networks}}},
  booktitle = {{{ResearchGate}}},
  issn = {1037-2725},
  urldate = {2025-08-16},
  abstract = {PDF \textbar{} On Dec 2, 2023, S. Muhammed and others published Improved Classification of Alzheimer's Disease With Convolutional Neural Networks \textbar{} Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {/home/paris/Zotero/storage/PDDFWQZD/376978982_Improved_Classification_of_Alzheimer's_Disease_With_Convolutional_Neural_Networks.html}
}

@article{PDFSupportVector,
  title = {({{PDF}}) {{Support}} Vector Machine-Based Classification of {{Alzheimer}}'s Disease from Whole-Brain Anatomical {{MRI}}},
  journal = {ResearchGate},
  doi = {10.1007/s00234-008-0463-x},
  urldate = {2025-07-28},
  abstract = {PDF \textbar{} We present and evaluate a new automated method based on support vector machine (SVM) classification of whole-brain anatomical magnetic resonance... \textbar{} Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/(PDF) Support vector machine-based classification of Alzheimer's disease from whole-brain anatomical.pdf;/home/paris/Zotero/storage/PJX23VP4/23310655_Support_vector_machine-based_classification_of_Alzheimer's_disease_from_whole-brain_an.html}
}

@misc{PDFTransferLearning2025,
  title = {({{PDF}}) {{Transfer Learning}} as a {{Method}} for {{Optimizing Efficiency}} in {{Machine Learning Models}}},
  year = 2025,
  month = may,
  journal = {ResearchGate},
  urldate = {2025-10-16},
  abstract = {PDF \textbar{} As machine learning models continue to grow in complexity and scale, they often become computationally expensive, leading to inefficiencies in... \textbar{} Find, read and cite all the research you need on ResearchGate},
  howpublished = {https://www.researchgate.net/publication/386451881\_Transfer\_Learning\_as\_a\_Method\_for\_Optimizing\_Efficiency\_in\_Machine\_Learning\_Models},
  langid = {english},
  file = {/home/paris/Zotero/storage/6EXFNPXT/386451881_Transfer_Learning_as_a_Method_for_Optimizing_Efficiency_in_Machine_Learning_Models.html}
}

@misc{PDFVisionTransformers,
  title = {({{PDF}}) {{Vision Transformers}} in {{Medical Imaging}}: A {{Comprehensive Review}} of {{Advancements}} and {{Applications Across Multiple Diseases}}},
  urldate = {2025-08-20},
  howpublished = {https://www.researchgate.net/publication/390372350\_Vision\_Transformers\_in\_Medical\_Imaging\_a\_Comprehensive\_Review\_of\_Advancements\_and\_Applications\_Across\_Multiple\_Diseases},
  file = {/home/paris/Zotero/storage/IXVX5JG3/390372350_Vision_Transformers_in_Medical_Imaging_a_Comprehensive_Review_of_Advancements_and_App.html}
}

@article{pellegriniMachineLearningNeuroimaging2018,
  title = {Machine Learning of Neuroimaging for Assisted Diagnosis of Cognitive Impairment and Dementia: A Systematic Review},
  shorttitle = {Machine Learning of Neuroimaging for Assisted Diagnosis of Cognitive Impairment and Dementia},
  author = {Pellegrini, Enrico and Ballerini, Lucia and Hernandez, Maria del C. Valdes and Chappell, Francesca M. and {Gonz{\'a}lez-Castro}, Victor and Anblagan, Devasuda and Danso, Samuel and {Mu{\~n}oz-Maniega}, Susana and Job, Dominic and Pernet, Cyril},
  year = 2018,
  journal = {Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
  volume = {10},
  pages = {519--535},
  publisher = {Elsevier},
  urldate = {2025-08-11}
}

@misc{perezEffectivenessDataAugmentation2017,
  title = {The {{Effectiveness}} of {{Data Augmentation}} in {{Image Classification}} Using {{Deep Learning}}},
  author = {Perez, Luis and Wang, Jason},
  year = 2017,
  month = dec,
  number = {arXiv:1712.04621},
  eprint = {1712.04621},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1712.04621},
  urldate = {2025-11-04},
  abstract = {In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/paris/Zotero/storage/3M2BLUCT/Perez and Wang - 2017 - The Effectiveness of Data Augmentation in Image Classification using Deep Learning.pdf;/home/paris/Zotero/storage/HE6UPEA7/1712.html}
}

@article{petrellaNeuroimagingEarlyDiagnosis2003,
  title = {Neuroimaging and {{Early Diagnosis}} of {{Alzheimer Disease}}: {{A Look}} to the {{Future}}},
  shorttitle = {Neuroimaging and {{Early Diagnosis}} of {{Alzheimer Disease}}},
  author = {Petrella, Jeffrey R. and Coleman, R. Edward and Doraiswamy, P. Murali},
  year = 2003,
  month = feb,
  journal = {Radiology},
  volume = {226},
  number = {2},
  pages = {315--336},
  publisher = {Radiological Society of North America},
  issn = {0033-8419},
  doi = {10.1148/radiol.2262011600},
  urldate = {2024-12-20},
  abstract = {Alzheimer disease (AD), a progressive neurodegenerative disorder, is the most common cause of dementia in the elderly. Current consensus statements have emphasized the need for early recognition and the fact that a diagnosis of AD can be made with high accuracy by using clinical, neuropsychologic, and imaging assessments. Magnetic resonance (MR) or computed tomographic (CT) imaging is recommended for the routine evaluation of AD. Coronal MR images can be useful to document or quantify atrophy of the hippocampus and entorhinal cortex, both of which occur early in the disease process. Both volumetric and subtraction MR techniques can be used to quantify and monitor dementia progression and rates of regional atrophy. MR measures are also increasingly being used to monitor treatment effects in clinical trials of cognitive enhancers and antidementia agents. Positron emission tomography (PET) and single photon emission CT offer value in the differential diagnosis of AD from other cortical and subcortical dementias and may also offer prognostic value. In addition, PET studies have demonstrated that subtle abnormalities may be apparent in the prodromal stages of AD and in subjects who carry susceptibility genes. PET ligands are in late-stage development for demonstration of amyloid plaques, and human studies have already begun. Functional MR--based memory challenge tests are in development as well. \copyright{} RSNA, 2003}
}

@article{petrellaNeuroimagingEarlyDiagnosis2003a,
  title = {Neuroimaging and {{Early Diagnosis}} of {{Alzheimer Disease}}: {{A Look}} to the {{Future}}},
  shorttitle = {Neuroimaging and {{Early Diagnosis}} of {{Alzheimer Disease}}},
  author = {Petrella, Jeffrey R. and Coleman, R. Edward and Doraiswamy, P. Murali},
  year = 2003,
  month = feb,
  journal = {Radiology},
  volume = {226},
  number = {2},
  pages = {315--336},
  issn = {0033-8419, 1527-1315},
  doi = {10.1148/radiol.2262011600},
  urldate = {2024-12-17},
  langid = {english}
}

@article{pfaffSelfsupervisedMRIDenoising2023,
  title = {Self-Supervised {{MRI}} Denoising: Leveraging {{Stein}}'s Unbiased Risk Estimator and Spatially Resolved Noise Maps},
  shorttitle = {Self-Supervised {{MRI}} Denoising},
  author = {Pfaff, Laura and Hossbach, Julian and Preuhs, Elisabeth and Wagner, Fabian and Arroyo Camejo, Silvia and Kannengiesser, Stephan and Nickel, Dominik and Wuerfl, Tobias and Maier, Andreas},
  year = 2023,
  month = dec,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {22629},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-49023-2},
  urldate = {2025-06-02},
  abstract = {Thermal noise caused by the imaged object is an intrinsic limitation in magnetic resonance imaging (MRI), resulting in an impaired clinical value of the acquisitions. Recently, deep learning (DL)-based denoising methods achieved promising results by extracting complex feature representations from large data sets. Most approaches are trained in a supervised manner by directly mapping noisy to noise-free ground-truth data and, therefore, require extensive paired data sets, which can be expensive or infeasible to obtain for medical imaging applications. In this work, a DL-based denoising approach is investigated which operates on complex-valued reconstructed magnetic resonance (MR) images without noise-free target data. An extension of Stein's unbiased risk estimator (SURE) and spatially resolved noise maps quantifying the noise level with pixel accuracy were employed during the training process. Competitive denoising performance was achieved compared to supervised training with mean squared error (MSE) despite optimizing the model without noise-free target images. The proposed DL-based method can be applied for MR image enhancement without requiring noise-free target data for training. Integrating the noise maps as an additional input channel further enables the regulation of the desired level of denoising to adjust to the preference of the radiologist.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Biomedical engineering,Computer science,Magnetic resonance imaging},
  file = {/home/paris/gdrive/Zotero/Denosing/Pfaff et al. - 2023 - Self-supervised MRI denoising leveraging Stein’s unbiased risk estimator and spatially resolved noi.pdf}
}

@article{pierrickcoupeOptimizedBlockwiseNonlocal2008,
  title = {An {{Optimized Blockwise Nonlocal Means Denoising Filter}} for 3-{{D Magnetic Resonance Images}}},
  author = {{Pierrick Coup\'e} and Coup{\'e}, Pierrick and {Pierre Yger} and Yger, Pierre and {Sylvain Prima} and Prima, Sylvain and {Sylvain Prima} and {Pierre Hellier} and Hellier, Pierre and {Charles Kervrann} and Kervrann, Charles and {Christian Barillot} and Barillot, Christian and {Christian Barillot} and {Christian Barillot}},
  year = 2008,
  month = mar,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {27},
  number = {4},
  pages = {425--441},
  doi = {10.1109/tmi.2007.906087},
  abstract = {A critical issue in image restoration is the problem of noise removal while keeping the integrity of relevant image information. Denoising is a crucial step to increase image quality and to improve the performance of all the tasks needed for quantitative imaging analysis. The method proposed in this paper is based on a 3-D optimized blockwise version of the nonlocal (NL)-means filter (Buades, , 2005). The NL-means filter uses the redundancy of information in the image under study to remove the noise. The performance of the NL-means filter has been already demonstrated for 2-D images, but reducing the computational burden is a critical aspect to extend the method to 3-D images. To overcome this problem, we propose improvements to reduce the computational complexity. These different improvements allow to drastically divide the computational time while preserving the performances of the NL-means filter. A fully automated and optimized version of the NL-means filter is then presented. Our contributions to the NL-means filter are: 1) an automatic tuning of the smoothing parameter; 2) a selection of the most relevant voxels; 3) a blockwise implementation; and 4) a parallelized computation. Quantitative validation was carried out on synthetic datasets generated with BrainWeb (Collins, , 1998). The results show that our optimized NL-means filter outperforms the classical implementation of the NL-means filter, as well as two other classical denoising methods [anisotropic diffusion (Perona and Malik, 1990)] and total variation minimization process (Rudin, , 1992) in terms of accuracy (measured by the peak signal-to-noise ratio) with low computation time. Finally, qualitative results on real data are presented.},
  pmcid = {2881565},
  pmid = {18390341},
  annotation = {MAG ID: 2142592339},
  file = {/home/paris/gdrive/Zotero/Pierrick Coupé et al. - 2008 - An Optimized Blockwise Nonlocal Means Denoising Filter for 3-D Magnetic Resonance Images.pdf}
}

@article{plewesPhysicsMRIPrimer2012,
  title = {Physics of {{MRI}}: {{A}} Primer},
  shorttitle = {Physics of {{MRI}}},
  author = {Plewes, Donald B. and Kucharczyk, Walter},
  year = 2012,
  month = may,
  journal = {Journal of Magnetic Resonance Imaging},
  volume = {35},
  number = {5},
  pages = {1038--1054},
  issn = {1053-1807, 1522-2586},
  doi = {10.1002/jmri.23642},
  urldate = {2025-11-14},
  abstract = {Abstract                            This article is based on an introductory lecture given for the past many years during the ``MR Physics and Techniques for Clinicians'' course at the Annual Meeting of the ISMRM. This introduction is not intended to be a comprehensive overview of the field, as the subject of magnetic resonance imaging (MRI) physics is large and complex. Rather, it is intended to lay a conceptual foundation by which magnetic resonance image formation can be understood from an intuitive perspective. The presentation is nonmathematical, relying on simple models that take the reader progressively from the basic               spin               physics of nuclei, through descriptions of how the magnetic resonance signal is generated and detected in an MRI scanner, the foundations of nuclear magnetic resonance (NMR) relaxation, and a discussion of the Fourier transform and its relation to MR image formation. The article continues with a discussion of how magnetic field gradients are used to facilitate spatial encoding and concludes with a development of basic pulse sequences and the factors defining image contrast. J. Magn. Reson. Imaging 2012;35:1038-1054. \copyright{} 2012 Wiley Periodicals, Inc.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{plougPopulationPreferencesPerformance2021,
  title = {Population {{Preferences}} for {{Performance}} and {{Explainability}} of {{Artificial Intelligence}} in {{Health Care}}: {{Choice-Based Conjoint Survey}}},
  shorttitle = {Population {{Preferences}} for {{Performance}} and {{Explainability}} of {{Artificial Intelligence}} in {{Health Care}}},
  author = {Ploug, Thomas and Sundby, Anna and Moeslund, Thomas B and Holm, S{\o}ren},
  year = 2021,
  month = dec,
  journal = {Journal of Medical Internet Research},
  volume = {23},
  number = {12},
  pages = {e26611},
  issn = {1439-4456},
  doi = {10.2196/26611},
  urldate = {2025-10-27},
  abstract = {Background Certain types of artificial intelligence (AI), that is, deep learning models, can outperform health care professionals in particular domains. Such models hold considerable promise for improved diagnostics, treatment, and prevention, as well as more cost-efficient health care. They are, however, opaque in the sense that their exact reasoning cannot be fully explicated. Different stakeholders have emphasized the importance of the transparency/explainability of AI decision making. Transparency/explainability may come at the cost of performance. There is need for a public policy regulating the use of AI in health care that balances the societal interests in high performance as well as in transparency/explainability. A public policy should consider the wider public's interests in such features of AI. Objective This study elicited the public's preferences for the performance and explainability of AI decision making in health care and determined whether these preferences depend on respondent characteristics, including trust in health and technology and fears and hopes regarding AI. Methods We conducted a choice-based conjoint survey of public preferences for attributes of AI decision making in health care in a representative sample of the adult Danish population. Initial focus group interviews yielded 6 attributes playing a role in the respondents' views on the use of AI decision support in health care: (1) type of AI decision, (2) level of explanation, (3) performance/accuracy, (4) responsibility for the final decision, (5) possibility of discrimination, and (6) severity of the disease to which the AI is applied. In total, 100 unique choice sets were developed using fractional factorial design. In a 12-task survey, respondents were asked about their preference for AI system use in hospitals in relation to 3 different scenarios. Results Of the 1678 potential respondents, 1027 (61.2\%) participated. The respondents consider the physician having the final responsibility for treatment decisions the most important attribute, with 46.8\% of the total weight of attributes, followed by explainability of the decision (27.3\%) and whether the system has been tested for discrimination (14.8\%). Other factors, such as gender, age, level of education, whether respondents live rurally or in towns, respondents' trust in health and technology, and respondents' fears and hopes regarding AI, do not play a significant role in the majority of cases. Conclusions The 3 factors that are most important to the public are, in descending order of importance, (1) that physicians are ultimately responsible for diagnostics and treatment planning, (2) that the AI decision support is explainable, and (3) that the AI system has been tested for discrimination. Public policy on AI system use in health care should give priority to such AI system use and ensure that patients are provided with information.},
  pmcid = {PMC8713089},
  pmid = {34898454},
  file = {/home/paris/Zotero/storage/PRLI459L/Ploug et al. - 2021 - Population Preferences for Performance and Explainability of Artificial Intelligence in Health Care.pdf}
}

@article{preboskeCommonMRIAcquisition2006,
  title = {Common {{MRI}} Acquisition Non-Idealities Significantly Impact the Output of the Boundary Shift Integral Method of Measuring Brain Atrophy on Serial {{MRI}}},
  author = {Preboske, Gregory M. and Gunter, Jeff L. and Ward, Chadwick P. and Jack, Clifford R.},
  year = 2006,
  month = may,
  journal = {NeuroImage},
  volume = {30},
  number = {4},
  pages = {1196--1202},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2005.10.049},
  urldate = {2025-06-12},
  abstract = {Measuring rates of brain atrophy from serial magnetic resonance imaging (MRI) studies is an attractive way to assess disease progression in neurodegenerative disorders, particularly Alzheimer's disease (AD). A widely recognized approach is the boundary shift integral (BSI). The objective of this study was to evaluate how several common scan non-idealities affect the output of the BSI algorithm. We created three types of image non-idealities between the image volumes in a serial pair used to measure between-scan change: inconsistent image contrast between serial scans, head motion, and poor signal-to-noise (SNR). In theory the BSI volume difference measured between each pair of images should be zero and any deviation from zero should represent corruption of the BSI measurement by some non-ideality intentionally introduced into the second scan in the pair. Two different BSI measures were evaluated, whole brain and ventricle. As the severity of motion, noise, and non-congruent image contrast increased in the second scan, the calculated BSI values deviated progressively more from the expected value of zero. This study illustrates the magnitude of the error in measures of change in brain and ventricle volume across serial MRI scans that can result from commonly encountered deviations from ideal image quality. The magnitudes of some of the measurement errors seen in this study exceed the disease effect in AD shown in various publications, which range from 1\% to 2.78\% per year for whole brain atrophy and 5.4\% to 13.8\% per year for ventricle expansion (Table 1). For example, measurement error may exceed 100\% if image contrast properties dramatically differ between the two scans in a measurement pair. Methods to maximize consistency of image quality over time are an essential component of any quantitative serial MRI study.},
  keywords = {Alzheimer's disease,Image artifacts,Image processing,MRI},
  file = {/home/paris/Zotero/storage/Z86YF4JR/Preboske et al. - 2006 - Common MRI acquisition non-idealities significantly impact the output of the boundary shift integral.pdf}
}

@article{PreprocessingMRIImages2017,
  title = {Preprocessing {{MRI Images}} of {{Colorectal Cancer}}},
  year = 2017,
  month = jan,
  journal = {International Journal of Computer Science Issues},
  volume = {14},
  number = {1},
  pages = {48--59},
  issn = {16940814, 16940784},
  doi = {10.20943/01201701.4859},
  urldate = {2025-04-18},
  abstract = {The precision cancer diagnosis is possible owing to the sophisticated technologies based digital image processing tools. Among the various imaging modalities, Magnetic Resonance Imaging (MRI) is of paramount interest, especially for colorectal cancer imaging. Despite the fact that MRI is a superior technology, an MRI image does contain artifacts and distorted signals. Numerous algorithms and approaches have been studied and implemented for various cancer diagnostics. Yet, more augmented techniques need to be developed, since the study is complex and needs a maximum possible accuracy of detection. In this paper, the research work focuses on the various preprocessing techniques such as noise removal techniques and image enhancement techniques. These methods are analyzed for their performance using statistical parameters and the optimal method is determined for generating a noise-free edgesharp intensity enhanced MRI images of colon and rectum cancer, paving for precision diagnosis. The experimental results are analyzed in terms of various image quality metrics.},
  langid = {english},
  file = {/home/paris/Zotero/storage/GZLS4RVR/2017 - Preprocessing MRI Images of Colorectal Cancer.pdf}
}

@article{princeRecentGlobalTrends2016,
  title = {Recent Global Trends in the Prevalence and Incidence of Dementia, and Survival with Dementia},
  author = {Prince, Martin and Ali, Gemma-Claire and Guerchet, Ma{\"e}lenn and Prina, A. Matthew and Albanese, Emiliano and Wu, Yu-Tzu},
  year = 2016,
  month = jul,
  journal = {Alzheimer's Research \& Therapy},
  volume = {8},
  number = {1},
  pages = {23},
  issn = {1758-9193},
  doi = {10.1186/s13195-016-0188-8},
  urldate = {2025-10-17},
  abstract = {Current projections of the scale of the coming dementia epidemic assume that the age- and sex-specific prevalence of dementia will not vary over time, and that population ageing alone (increasing the number of older people at risk) drives the projected increases. The basis for this assumption is doubtful, and secular trends (that is, gradual decreases or increases in prevalence over long-term periods) are perfectly plausible.},
  langid = {english},
  keywords = {Dementia,Epidemiology,Global health,Meta-analysis,Projection,Systematic review,Trends,Worldwide},
  file = {/home/paris/Zotero/storage/QPYCCJYY/Prince et al. - 2016 - Recent global trends in the prevalence and incidence of dementia, and survival with dementia.pdf}
}

@article{quirozPlasmaNeurofilamentLight2020,
  title = {Plasma Neurofilament Light Chain in the Presenilin 1 {{E280A}} Autosomal Dominant {{Alzheimer}}'s Disease Kindred: A Cross-Sectional and Longitudinal Cohort Study},
  shorttitle = {Plasma Neurofilament Light Chain in the Presenilin 1 {{E280A}} Autosomal Dominant {{Alzheimer}}'s Disease Kindred},
  author = {Quiroz, Yakeel T. and Zetterberg, Henrik and Reiman, Eric M. and Chen, Yinghua and Su, Yi and {Fox-Fuller}, Joshua T. and Garcia, Gloria and Villegas, Andres and {Sepulveda-Falla}, Diego and Villada, Marina},
  year = 2020,
  journal = {The Lancet Neurology},
  volume = {19},
  number = {6},
  pages = {513--521},
  publisher = {Elsevier},
  urldate = {2024-12-15},
  file = {/home/paris/Zotero/storage/WMZTL4RN/PMC7417082.html}
}

@article{rabinoviciAssociationAmyloidPositron2019,
  title = {Association of {{Amyloid Positron Emission Tomography With Subsequent Change}} in {{Clinical Management Among Medicare Beneficiaries With Mild Cognitive Impairment}} or {{Dementia}}},
  author = {Rabinovici, Gil D. and Gatsonis, Constantine and Apgar, Charles and Chaudhary, Kiran and Gareen, Ilana and Hanna, Lucy and Hendrix, James and Hillner, Bruce E. and Olson, Cynthia and {Lesman-Segev}, Orit H. and Romanoff, Justin and Siegel, Barry A. and Whitmer, Rachel A. and Carrillo, Maria C.},
  year = 2019,
  month = apr,
  journal = {JAMA},
  volume = {321},
  number = {13},
  pages = {1286--1294},
  issn = {0098-7484},
  doi = {10.1001/jama.2019.2000},
  urldate = {2024-12-20},
  abstract = {Amyloid positron emission tomography (PET) detects amyloid plaques in the brain, a core neuropathological feature of Alzheimer disease.To determine if amyloid PET is associated with subsequent changes in the management of patients with mild cognitive impairment (MCI) or dementia of uncertain etiology.The Imaging Dementia---Evidence for Amyloid Scanning (IDEAS) study was a single-group, multisite longitudinal study that assessed the association between amyloid PET and subsequent changes in clinical management for Medicare beneficiaries with MCI or dementia. Participants were required to meet published appropriate use criteria stating that etiology of cognitive impairment was unknown, Alzheimer disease was a diagnostic consideration, and knowledge of PET results was expected to change diagnosis and management. A total of 946 dementia specialists at 595 US sites enrolled 16\,008 patients between February 2016 and September 2017. Patients were followed up through January 2018. Dementia specialists documented their diagnosis and management plan before PET and again 90 (\textpm 30) days after PET.Participants underwent amyloid PET at 343 imaging centers.The primary end point was change in management between the pre- and post-PET visits, as assessed by a composite outcome that included Alzheimer disease drug therapy, other drug therapy, and counseling about safety and future planning. The study was powered to detect a 30\% or greater change in the MCI and dementia groups. One of 2 secondary end points is reported: the proportion of changes in diagnosis (from Alzheimer disease to non--Alzheimer disease and vice versa) between pre- and post-PET visits.Among 16\,008 registered participants, 11\,409 (71.3\%) completed study procedures and were included in the analysis (median age, 75 years [interquartile range, 71-80]; 50.9\% women; 60.5\% with MCI). Amyloid PET results were positive in 3817 patients with MCI (55.3\%) and 3154 patients with dementia (70.1\%). The composite end point changed in 4159 of 6905 patients with MCI (60.2\% [95\% CI, 59.1\%-61.4\%]) and 2859 of 4504 patients with dementia (63.5\% [95\% CI, 62.1\%-64.9\%]), significantly exceeding the 30\% threshold in each group (P\,\&lt;\,.001, 1-sided). The etiologic diagnosis changed from Alzheimer disease to non--Alzheimer disease in 2860 of 11\,409 patients (25.1\% [95\% CI, 24.3\%-25.9\%]) and from non--Alzheimer disease to Alzheimer disease in 1201 of 11\,409 (10.5\% [95\% CI, 10.0\%-11.1\%]).Among Medicare beneficiaries with MCI or dementia of uncertain etiology evaluated by dementia specialists, the use of amyloid PET was associated with changes in clinical management within 90 days. Further research is needed to determine whether amyloid PET is associated with improved clinical outcomes.ClinicalTrials.gov Identifier: NCT02420756},
  file = {/home/paris/Zotero/storage/CSYPEYD4/2729371.html}
}

@article{raduaValidityModulationOptimal2014,
  title = {Validity of Modulation and Optimal Settings for Advanced Voxel-Based Morphometry},
  author = {Radua, Joaquim and {Canales-Rodr{\'i}guez}, Erick Jorge and {Pomarol-Clotet}, Edith and Salvador, Raymond},
  year = 2014,
  month = feb,
  journal = {NeuroImage},
  volume = {86},
  pages = {81--90},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2013.07.084},
  urldate = {2025-07-23},
  abstract = {Voxel-based morphometry (VBM) is a widely-used structural neuroimaging technique for comparing meso- and macroscopic regional brain volumes between patients and controls in vivo, but some of its steps, particularly the modulation, lack an experimental validation. The aims of this study were two-fold: a) to assess the effects of modulation to detect mesoscopic (i.e. between microscopic and macroscopic) abnormalities on published, classic VBM; and b) to suggest a set of potentially optimal settings for detecting mesoscopic abnormalities with new, advanced, high-resolution diffeomorphic VBM normalization algorithms. Sensitivity and false positive rate after modulating or not in classic VBM using different software packages and spatial statistics, and after setting a range of different parameters in advanced VBM (ANTS-SyN), were calculated in 10 VBM comparisons of 32 altered vs. 32 unaltered gray matter images from different healthy controls. Simulated brain abnormalities comprised mesoscopic volume differences mainly due to cortical thinning. In classic VBM, modulation was associated with a substantial decrease of the sensitivity to detect mesoscopic abnormalities (p{$<$}0.001). Optimal settings for advanced VBM included the omission of modulation, the use of large smoothing kernels, and the application of voxel-based or threshold-free cluster enhancement (TFCE) spatial statistics. The modulation-related decrease in sensitivity was due to an increase in variance, and it was more severe in higher-resolution normalization algorithms. Findings from this study suggest the use of unmodulated VBM to detect mesoscopic abnormalities such as cortical thinning.},
  keywords = {Cluster-based statistics,Diffeomorphic registration,Modulation,Normalization,Threshold-free cluster enhancement,Voxel-based morphometry},
  file = {/home/paris/gdrive/Zotero/Radua et al. - 2014 - Validity of modulation and optimal settings for advanced voxel-based morphometry.pdf;/home/paris/Zotero/storage/MNVNHPJ6/S1053811913008562.html}
}

@article{rasExplainableDeepLearning2022,
  title = {Explainable Deep Learning: {{A}} Field Guide for the Uninitiated},
  shorttitle = {Explainable Deep Learning},
  author = {Ras, Gabrielle and Xie, Ning and Van Gerven, Marcel and Doran, Derek},
  year = 2022,
  journal = {Journal of Artificial Intelligence Research},
  volume = {73},
  pages = {329--396},
  urldate = {2025-06-24},
  file = {/home/paris/gdrive/Zotero/Ras et al. - 2022 - Explainable deep learning A field guide for the uninitiated.pdf}
}

@misc{raviBuzzGenerativeAI2023,
  title = {The {{Buzz Around Generative AI}}: {{Autoencoders}}},
  shorttitle = {The {{Buzz Around Generative AI}}},
  author = {Ravi, Pooja},
  year = 2023,
  month = jul,
  journal = {Medium},
  urldate = {2025-06-22},
  abstract = {Welcome to part two of the Generative AI blog post series! In this blog, we will explore various autoencoders and the maths involved.},
  langid = {english}
}

@article{razaAdvancementsDeepLearning2025,
  title = {Advancements in Deep Learning for Early Diagnosis of {{Alzheimer}}'s Disease Using Multimodal Neuroimaging: Challenges and Future Directions},
  shorttitle = {Advancements in Deep Learning for Early Diagnosis of {{Alzheimer}}'s Disease Using Multimodal Neuroimaging},
  author = {Raza, Muhammad Liaquat and Hassan, Syed Tawassul and Jamil, Subia and Hyder, Noorulain and Batool, Kinza and Walji, Sajidah and Abbas, Muhammad Khizar},
  year = 2025,
  month = may,
  journal = {Frontiers in Neuroinformatics},
  volume = {19},
  publisher = {Frontiers},
  issn = {1662-5196},
  doi = {10.3389/fninf.2025.1557177},
  urldate = {2026-01-14},
  abstract = {IntroductionAlzheimer's disease is a progressive neurodegenerative disorder challenging early diagnosis and treatment. Recent advancements in deep learning algorithms applied to multimodal brain imaging offer promising solutions for improving diagnostic accuracy and predicting disease progression.MethodThis narrative review synthesizes current literature on deep learning applications in Alzheimer's disease diagnosis using multimodal neuroimaging. The review process involved a comprehensive search of relevant databases (PubMed, Embase, Google Scholar and ClinicalTrials.gov), selection of pertinent studies, and critical analysis of findings. We employed a best-evidence approach, prioritizing high-quality studies and identifying consistent patterns across the literature.ResultsDeep learning architectures, including convolutional neural networks, recurrent neural networks, and transformer-based models, have shown remarkable potential in analyzing multimodal neuroimaging data. These models can effectively process structural and functional imaging modalities, extracting relevant features and patterns associated with Alzheimer's pathology. Integration of multiple imaging modalities has demonstrated improved diagnostic accuracy compared to single-modality approaches. Deep learning models have also shown promise in predictive modeling, identifying potential biomarkers and forecasting disease progression.DiscussionWhile deep learning approaches show great potential, several challenges remain. Data heterogeneity, small sample sizes, and limited generalizability across diverse populations are significant hurdles. The clinical translation of these models requires careful consideration of interpretability, transparency, and ethical implications. The future of AI in neurodiagnostics for Alzheimer's disease looks promising, with potential applications in personalized treatment strategies.},
  langid = {english},
  keywords = {Alzheimer's disease,brain imaging analysis,deep learning,Disease progression prediction,multimodal neuroimaging},
  file = {/home/paris/Zotero/storage/2BJPVNRW/Raza et al. - 2025 - Advancements in deep learning for early diagnosis of Alzheimer’s disease using multimodal neuroimagi.pdf}
}

@article{rehmanConventionalDeepLearning2020,
  title = {Conventional and {{Deep Learning Methods}} for {{Skull Stripping}} in {{Brain MRI}}},
  author = {Rehman, Hafiz Zia Ur and Hwang, Hyunho and Lee, Sungon},
  year = 2020,
  month = jan,
  journal = {Applied Sciences},
  volume = {10},
  number = {5},
  pages = {1773},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10051773},
  urldate = {2025-07-07},
  abstract = {Skull stripping in brain magnetic resonance volume has recently been attracting attention due to an increased demand to develop an efficient, accurate, and general algorithm for diverse datasets of the brain. Accurate skull stripping is a critical step for neuroimaging diagnostic systems because neither the inclusion of non-brain tissues nor removal of brain parts can be corrected in subsequent steps, which results in unfixed error through subsequent analysis. The objective of this review article is to give a comprehensive overview of skull stripping approaches, including recent deep learning-based approaches. In this paper, the current methods of skull stripping have been divided into two distinct groups---conventional or classical approaches, and convolutional neural networks or deep learning approaches. The potentials of several methods are emphasized because they can be applied to standard clinical imaging protocols. Finally, current trends and future developments are addressed giving special attention to recent deep learning algorithms.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {brain extraction,brain segmentation,deep convolutional neural networks,skull stripping,U-Net},
  file = {/home/paris/gdrive/Zotero/Rehman et al. - 2020 - Conventional and Deep Learning Methods for Skull Stripping in Brain MRI.pdf}
}

@article{rehmanConventionalDeepLearning2020a,
  title = {Conventional and {{Deep Learning Methods}} for {{Skull Stripping}} in {{Brain MRI}}},
  author = {Rehman, Hafiz Zia Ur and Hwang, Hyunho and Lee, Sungon},
  year = 2020,
  month = jan,
  journal = {Applied Sciences},
  volume = {10},
  number = {5},
  pages = {1773},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10051773},
  urldate = {2026-01-16},
  abstract = {Skull stripping in brain magnetic resonance volume has recently been attracting attention due to an increased demand to develop an efficient, accurate, and general algorithm for diverse datasets of the brain. Accurate skull stripping is a critical step for neuroimaging diagnostic systems because neither the inclusion of non-brain tissues nor removal of brain parts can be corrected in subsequent steps, which results in unfixed error through subsequent analysis. The objective of this review article is to give a comprehensive overview of skull stripping approaches, including recent deep learning-based approaches. In this paper, the current methods of skull stripping have been divided into two distinct groups---conventional or classical approaches, and convolutional neural networks or deep learning approaches. The potentials of several methods are emphasized because they can be applied to standard clinical imaging protocols. Finally, current trends and future developments are addressed giving special attention to recent deep learning algorithms.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {brain extraction,brain segmentation,deep convolutional neural networks,skull stripping,U-Net},
  file = {/home/paris/Zotero/storage/KX7NPJPR/Rehman et al. - 2020 - Conventional and Deep Learning Methods for Skull Stripping in Brain MRI.pdf}
}

@article{reimanBrainImagingFluid2012,
  title = {Brain Imaging and Fluid Biomarker Analysis in Young Adults at Genetic Risk for Autosomal Dominant {{Alzheimer}}'s Disease in the Presenilin 1 {{E280A}} Kindred: A Case-Control Study},
  shorttitle = {Brain Imaging and Fluid Biomarker Analysis in Young Adults at Genetic Risk for Autosomal Dominant {{Alzheimer}}'s Disease in the Presenilin 1 {{E280A}} Kindred},
  author = {Reiman, Eric M. and Quiroz, Yakeel T. and Fleisher, Adam S. and Chen, Kewei and {Velez-Pardo}, Carlos and {Jimenez-Del-Rio}, Marlene and Fagan, Anne M. and Shah, Aarti R. and Alvarez, Sergio and Arbelaez, Andr{\'e}s},
  year = 2012,
  journal = {The Lancet Neurology},
  volume = {11},
  number = {12},
  pages = {1048--1056},
  publisher = {Elsevier},
  urldate = {2024-12-13}
}

@article{reinholdEvaluatingImpactIntensity2019,
  title = {Evaluating the {{Impact}} of {{Intensity Normalization}} on {{MR Image Synthesis}}},
  author = {Reinhold, Jacob C. and Dewey, Blake E. and Carass, Aaron and Prince, Jerry L.},
  year = 2019,
  month = mar,
  journal = {Proceedings of SPIE--the International Society for Optical Engineering},
  volume = {10949},
  pages = {109493H},
  issn = {0277-786X},
  doi = {10.1117/12.2513089},
  abstract = {Image synthesis learns a transformation from the intensity features of an input image to yield a different tissue contrast of the output image. This process has been shown to have application in many medical image analysis tasks including imputation, registration, and segmentation. To carry out synthesis, the intensities of the input images are typically scaled-i.e., normalized-both in training to learn the transformation and in testing when applying the transformation, but it is not presently known what type of input scaling is optimal. In this paper, we consider seven different intensity normalization algorithms and three different synthesis methods to evaluate the impact of normalization. Our experiments demonstrate that intensity normalization as a preprocessing step improves the synthesis results across all investigated synthesis algorithms. Furthermore, we show evidence that suggests intensity normalization is vital for successful deep learning-based MR image synthesis.},
  langid = {english},
  pmcid = {PMC6758567},
  pmid = {31551645},
  keywords = {brain MRI,image synthesis,intensity normalization},
  annotation = {GSCC: 0000239 2025-06-15T15:39:54.533Z 0.73},
  file = {/home/paris/Zotero/storage/FTCPBDP9/Reinhold et al. - 2019 - Evaluating the Impact of Intensity Normalization on MR Image Synthesis.pdf}
}

@misc{ResearchRabbit,
  title = {Research {{Rabbit}}},
  urldate = {2024-11-08},
  howpublished = {https://researchrabbitapp.com/home},
  file = {/home/paris/Zotero/storage/4NG5B2G3/home.html}
}

@misc{ReviewApplicationsMachine,
  title = {A {{Review}} on the {{Applications}} of {{Machine Learning}} and {{Deep Learning Techniques}} for {{Skin Cancer Detection}}},
  urldate = {2025-10-15},
  abstract = {Skin cancer is the most commonly reported type of cancer globally and one of the few cancers that can be effectively treated if detected in its early stages. Recent advancements in artificial intelligence (AI) have significantly improved skin cancer diagnosis through Machine Learning (ML) and Deep Learning (DL) models. This review explores ML and DL methodologies, including Random Forest, Convolutional Neural Networks (CNNs), Inception Networks, ResNets, and Support Vector Machines (SVMs), which have been widely used for automated diagnosis. However, existing AI-based systems face several challenges, including the need for balanced datasets, model interpretability issues, computational complexity, and difficulties in generalizing across diverse populations. Moreover, multimodal detection systems and Explainable AI (XAI) present additional challenges in making AI-driven diagnoses more reliable and transparent. This article discusses these challenges while also highlighting emerging techniques that integrate multiple data sources and individualized diagnostic tools to enhance precision. By addressing these challenges, this review aims to provide insights into the practical advancements and future directions of AI in skin cancer detection and treatment.},
  howpublished = {https://ieeexplore.ieee.org/document/10933289},
  langid = {american},
  file = {/home/paris/Zotero/storage/LVLQYD6W/10933289.html}
}

@article{richardsonReceiverOperatingCharacteristic2024,
  title = {The Receiver Operating Characteristic Curve Accurately Assesses Imbalanced Datasets},
  author = {Richardson, Eve and Trevizani, Raphael and Greenbaum, Jason A. and Carter, Hannah and Nielsen, Morten and Peters, Bjoern},
  year = 2024,
  month = may,
  journal = {Patterns},
  volume = {5},
  number = {6},
  pages = {100994},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2024.100994},
  urldate = {2025-09-27},
  abstract = {Many problems in biology require looking for a ``needle in a haystack,'' corresponding to a binary classification where there are a few positives within a much larger set of negatives, which is referred to as a class imbalance. The receiver operating characteristic (ROC) curve and the associated area under the curve (AUC) have been reported as ill-suited to evaluate prediction performance on imbalanced problems where there is more interest in performance on the positive minority class, while the precision-recall (PR) curve is preferable. We show via simulation and a real case study that this is a misinterpretation of the difference between the ROC and PR spaces, showing that the ROC curve is robust to class imbalance, while the PR curve is highly sensitive to class imbalance. Furthermore, we show that class imbalance cannot be easily disentangled from classifier performance measured via PR-AUC., {$\bullet$}For imbalanced datasets, recent papers report that the ROC-AUC is inflated{$\bullet$}Simulated and real-world data show that the ROC-AUC is invariant to class imbalance{$\bullet$}The effect of class imbalance on the PR-AUC cannot be trivially removed{$\bullet$}Partial ROC-AUCs allow performance evaluation over the upper score ranges, There is conflicting information about whether a popular metric, the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, should be used when a dataset has many more negatives than positives, and one is only interested in performance on the positive instances. Many practitioners prefer a metric called the precision-recall (PR)-AUC and are taught that the ROC-AUC will give an ``overly optimistic'' estimate of model performance. We show that the ROC-AUC is only inflated by an imbalance in simulations where changing the imbalance changes the score distribution. By contrast, the PR-AUC changes drastically with class imbalance; furthermore, one cannot subtract or normalize the PR-AUC by class imbalance to obtain a corrected performance estimate. Our work encourages the adoption of the ROC-AUC in such cases, allowing for fairer comparisons of models across datasets with different imbalances and furthering the understanding of the relationship between the ROC and PR spaces., In datasets where there are many more negative than positive instances, it has become common wisdom that the ROC-AUC is inflated and the PR-AUC should be used. The authors show that this is a misunderstanding: the ROC-AUC is invariant to class imbalance when the score distribution isn't changed by the imbalance, in contrast to the PR-AUC. The ROC-AUC and its early retrieval area allow an estimate of classifier performance vs. PR-AUC's estimate of classifier performance on a particular dataset.},
  pmcid = {PMC11240176},
  pmid = {39005487},
  file = {/home/paris/gdrive/Zotero/Richardson et al. - 2024 - The receiver operating characteristic curve accurately assesses imbalanced datasets.pdf}
}

@inproceedings{riveiroChallengesProvidingExplanations2022,
  title = {The Challenges of Providing Explanations of {{AI}} Systems When They Do Not Behave like Users Expect},
  booktitle = {Proceedings of the 30th {{ACM Conference}} on {{User Modeling}}, {{Adaptation}} and {{Personalization}}},
  author = {Riveiro, Maria and Thill, Serge},
  year = 2022,
  month = jul,
  series = {{{UMAP}} '22},
  pages = {110--120},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3503252.3531306},
  urldate = {2025-09-12},
  abstract = {Explanations in artificial intelligence (AI) ensure that users of complex AI systems understand why the system behaves as it does. Expectations that users may have about the system behaviour play a role since they co-determine appropriate content of the explanations. In this paper, we investigate user-desired content of explanations when the system behaves in unexpected ways. Specifically, we presented participants with various scenarios involving an automated text classifier and then asked them to indicate their preferred explanation in each scenario. One group of participants chose the type of explanation from a multiple-choice questionnaire, the other had to answer using free text. Participants show a pretty clear agreement regarding the preferred type of explanation when the output matches expectations: most do not require an explanation at all, while those that do would like one that explains what features of the input led to the output (a factual explanation). When the output does not match expectations, users also prefer different explanations. Interestingly, there is less of an agreement in the multiple-choice questionnaire. However, the free text responses indicate slightly favour an explanation that describes how the AI system's internal workings led to the observed output (i.e., a mechanistic explanation). Overall, we demonstrate that user expectations are a significant variable in determining the most suitable content of explanations (including whether an explanation is needed at all). We also find different results, especially when the output does not match expectations, depending on whether participants answered via multiple-choice or free text. This shows a sensitivity to precise experimental setups that may explain some of the variety in the literature.},
  isbn = {978-1-4503-9207-5},
  file = {/home/paris/gdrive/Zotero/Riveiro and Thill - 2022 - The challenges of providing explanations of AI systems when they do not behave like users expect.pdf}
}

@misc{rosenfeldConstructivePredictionGeneralization2019,
  title = {A {{Constructive Prediction}} of the {{Generalization Error Across Scales}}},
  author = {Rosenfeld, Jonathan S. and Rosenfeld, Amir and Belinkov, Yonatan and Shavit, Nir},
  year = 2019,
  month = dec,
  number = {arXiv:1909.12673},
  eprint = {1909.12673},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1909.12673},
  urldate = {2025-10-31},
  abstract = {The dependency of the generalization error of neural networks on model and dataset size is of critical importance both in practice and for understanding the theory of neural networks. Nevertheless, the functional form of this dependency remains elusive. In this work, we present a functional form which approximates well the generalization error in practice. Capitalizing on the successful concept of model scaling (e.g., width, depth), we are able to simultaneously construct such a form and specify the exact models which can attain it across model/data scales. Our construction follows insights obtained from observations conducted over a range of model/data scales, in various model types and datasets, in vision and language tasks. We show that the form both fits the observations well across scales, and provides accurate predictions from small- to large-scale models and data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/paris/Zotero/storage/7ZUPTN7Z/Rosenfeld et al. - 2019 - A Constructive Prediction of the Generalization Error Across Scales.pdf;/home/paris/Zotero/storage/GHSB4SFE/1909.html}
}

@misc{RS2NetEndtoendDeep,
  title = {{{RS2-Net}}: {{An}} End-to-End Deep Learning Framework for Rodent Skull Stripping in Multi-Center Brain {{MRI}} - {{ScienceDirect}}},
  urldate = {2026-01-17},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S1053811924002660},
  file = {/home/paris/Zotero/storage/BL88JP26/S1053811924002660.html}
}

@book{russellArtificialIntelligenceModern1995,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter},
  year = 1995,
  series = {Prentice {{Hall}} Series in Artificial Intelligence},
  publisher = {Prentice Hall},
  address = {Englewood Cliffs, N.J},
  isbn = {978-0-13-103805-9},
  langid = {english},
  lccn = {Q335 .R86 1995},
  keywords = {Artificial intelligence},
  file = {/home/paris/gdrive/Zotero/Russell and Norvig - 1995 - Artificial intelligence a modern approach.pdf}
}

@article{safdaralikhanOffloadingComputationalComplexity2024,
  title = {Offloading the Computational Complexity of Transfer Learning with Generic Features},
  author = {Safdar Ali Khan, Muhammad and Husen, Arif and Nisar, Shafaq and Ahmed, Hasnain and Shah Muhammad, Syed and Aftab, Shabib},
  year = 2024,
  month = mar,
  journal = {PeerJ Computer Science},
  volume = {10},
  pages = {e1938},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.1938},
  urldate = {2025-10-16},
  abstract = {Deep learning approaches are generally complex, requiring extensive computational resources and having high time complexity. Transfer learning is a state-of-the-art approach to reducing the requirements of high computational resources by using pre-trained models without compromising accuracy and performance. In conventional studies, pre-trained models are trained on datasets from different but similar domains with many domain-specific features. The computational requirements of transfer learning are directly dependent on the number of features that include the domain-specific and the generic features. This article investigates the prospects of reducing the computational requirements of the transfer learning models by discarding domain-specific features from a pre-trained model. The approach is applied to breast cancer detection using the dataset curated breast imaging subset of the digital database for screening mammography and various performance metrics such as precision, accuracy, recall, F1-score, and computational requirements. It is seen that discarding the domain-specific features to a specific limit provides significant performance improvements as well as minimizes the computational requirements in terms of training time (reduced by approx. 12\%), processor utilization (reduced approx. 25\%), and memory usage (reduced approx. 22\%). The proposed transfer learning strategy increases accuracy (approx. 7\%) and offloads computational complexity expeditiously.},
  pmcid = {PMC11041970},
  pmid = {38660182},
  file = {/home/paris/Zotero/storage/87VF76FF/Safdar Ali Khan et al. - 2024 - Offloading the computational complexity of transfer learning with generic features.pdf}
}

@article{salomeMRIntensityNormalization2023,
  title = {{{MR Intensity Normalization Methods Impact Sequence Specific Radiomics Prognostic Model Performance}} in {{Primary}} and {{Recurrent High-Grade Glioma}}},
  author = {Salome, Patrick and Sforazzini, Francesco and Brugnara, Gianluca and Kudak, Andreas and Dostal, Matthias and {Herold-Mende}, Christel and Heiland, Sabine and Debus, J{\"u}rgen and Abdollahi, Amir and Knoll, Maximilian},
  year = 2023,
  month = jan,
  journal = {Cancers},
  volume = {15},
  number = {3},
  pages = {965},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2072-6694},
  doi = {10.3390/cancers15030965},
  urldate = {2025-06-09},
  abstract = {Purpose: This study investigates the impact of different intensity normalization (IN) methods on the overall survival (OS) radiomics models' performance of MR sequences in primary (pHGG) and recurrent high-grade glioma (rHGG). Methods: MR scans acquired before radiotherapy were retrieved from two independent cohorts (rHGG C1: 197, pHGG C2: 141) from multiple scanners (15, 14). The sequences are T1 weighted (w), contrast-enhanced T1w (T1wce), T2w, and T2w-FLAIR. Sequence-specific significant features (SF) associated with OS, extracted from the tumour volume, were derived after applying 15 different IN methods. Survival analyses were conducted using Cox proportional hazard (CPH) and Poisson regression (POI) models. A ranking score was assigned based on the 10-fold cross-validated (CV) concordance index (C-I), mean square error (MSE), and the Akaike information criterion (AICs), to evaluate the methods' performance. Results: Scatter plots of the 10-CV C-I and MSE against the AIC showed an impact on the survival predictions between the IN methods and MR sequences (C1/C2 C-I range: 0.62--0.71/0.61--0.72, MSE range: 0.20--0.42/0.13--0.22). White stripe showed stable results for T1wce (C1/C2 C-I: 0.71/0.65, MSE: 0.21/0.14). Combat (0.68/0.62, 0.22/0.15) and histogram matching (HM, 0.67/0.64, 0.22/0.15) showed consistent prediction results for T2w models. They were also the top-performing methods for T1w in C2 (Combat: 0.67, 0.13; HM: 0.67, 0.13); however, only HM achieved high predictions in C1 (0.66, 0.22). After eliminating IN impacted SF using Spearman's rank-order correlation coefficient, a mean decrease in the C-I and MSE of 0.05 and 0.03 was observed in all four sequences. Conclusion: The IN method impacted the predictive power of survival models; thus, performance is sequence-dependent.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {high-grade glioma,image preprocessing,intensity harmonization,intensity standardization,multiparametric MRI,radiomics signatures},
  annotation = {GSCC: 0000013 2025-06-15T15:40:14.495Z 0},
  file = {/home/paris/Zotero/storage/ARTCT7ZT/Salome et al. - 2023 - MR Intensity Normalization Methods Impact Sequence Specific Radiomics Prognostic Model Performance i.pdf}
}

@incollection{samekExplainableDeepLearning2023,
  title = {Explainable Deep Learning: Concepts, Methods, and New Developments},
  shorttitle = {Explainable Deep Learning},
  booktitle = {Explainable {{Deep Learning AI}}},
  author = {Samek, Wojciech},
  year = 2023,
  pages = {7--33},
  publisher = {Elsevier},
  urldate = {2025-06-24}
}

@incollection{samPhysiologyAcetylcholine2025,
  title = {Physiology, {{Acetylcholine}}},
  booktitle = {{{StatPearls}}},
  author = {Sam, Christian and Bordoni, Bruno},
  year = 2025,
  publisher = {StatPearls Publishing},
  address = {Treasure Island (FL)},
  urldate = {2025-08-13},
  abstract = {Acetylcholine is a neurochemical that has a wide variety of functions in the brain and other organ systems of the body. Specifically, it is a neurotransmitter that acts as a chemical message that is released by neurons and allows them to communicate with one another and other specialized cells such as~myocytes~and cells found in glandular tissues. The name "acetylcholine" is derived from its chemical structure, as it is an ester of acetic acid and choline. Tissues of the body that use this chemical messenger or are responsive to it are referred to as cholinergic. There is a class of chemicals called anticholinergics that interfere with acetylcholine's action on tissues as well.~ While ACh operates as a neurotransmitter in many parts of the body, it is most commonly associated with the neuromuscular junction. The neuromuscular junction is where motor neurons located in the ventral spinal cord synapse with muscles in the body to activate them.~Acetylcholine also functions as a neurotransmitter in the autonomic nervous system,~acting both as~the neurotransmitter between preganglionic and postganglionic neurons as well as being the final release product from parasympathetic postganglionic neurons.},
  copyright = {Copyright \copyright{} 2025, StatPearls Publishing LLC.},
  langid = {english},
  lccn = {NBK557825},
  pmid = {32491757},
  file = {/home/paris/Zotero/storage/HEBZGLU4/NBK557825.html}
}

@article{SampleSizeDeterminationMethodologies2019,
  title = {Sample-{{Size Determination Methodologies}} for {{Machine Learning}} in {{Medical Imaging Research}}: {{A Systematic Review}}},
  shorttitle = {Sample-{{Size Determination Methodologies}} for {{Machine Learning}} in {{Medical Imaging Research}}},
  year = 2019,
  month = nov,
  journal = {Canadian Association of Radiologists Journal},
  volume = {70},
  number = {4},
  pages = {344--353},
  publisher = {No longer published by Elsevier},
  issn = {0846-5371},
  doi = {10.1016/j.carj.2019.06.002},
  urldate = {2025-10-15},
  abstract = {The required training sample size for a particular machine learning (ML) model applied to medical imaging data is often unknown. The purpose of this s\dots},
  langid = {american},
  file = {/home/paris/Zotero/storage/38EG9MDZ/S0846537119300506.html}
}

@article{saricaRandomForestAlgorithm2017,
  title = {Random {{Forest Algorithm}} for the {{Classification}} of {{Neuroimaging Data}} in {{Alzheimer}}'s {{Disease}}: {{A Systematic Review}}},
  shorttitle = {Random {{Forest Algorithm}} for the {{Classification}} of {{Neuroimaging Data}} in {{Alzheimer}}'s {{Disease}}},
  author = {Sarica, Alessia and Cerasa, Antonio and Quattrone, Aldo},
  year = 2017,
  month = oct,
  journal = {Frontiers in Aging Neuroscience},
  volume = {9},
  publisher = {Frontiers},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2017.00329},
  urldate = {2025-08-13},
  abstract = {Objective: Machine learning classification has been the most important computational development in the last years to satisfy the primary need of clinicians for automatic early diagnosis and prognosis. Nowadays, Random Forest (RF) algorithm has been successfully applied for reducing high dimensional and multi-source data in many scientific realms. Our aim was to explore the state of the art of the application of RF on single and multi-modal neuroimaging data for the prediction of Alzheimer's disease. Methods: A systematic review following PRISMA guidelines was conducted on this field of study. In particular, we constructed an advanced query using boolean operators as follows: ("random forest" OR "random forests") AND neuroimaging AND ("alzheimer's disease" OR alzheimer's OR alzheimer) AND (prediction OR classification). The query was then searched in four well-known scientific databases: Pubmed, Scopus, Google Scholar and Web of Science. Results: Twelve articles -- published between the 2007 and 2017 - have been included in this systematic review after a quantitative and qualitative selection. The lesson learnt from these works suggest that when RF was applied on multi-modal data for prediction of Alzheimer's disease (AD) conversion from the Mild Cognitive Impairment (MCI), it produces one of the best accuracies to date. Moreover, the RF has important advantages in terms of robustness to overfitting, ability to handle highly non-linear data, stability in the presence of outliers and opportunity for efficient parallel processing mainly when applied on multi-modality neuroimaging data, such as MRI morphometric, diffusion tensor imaging and PET images.Conclusions: We discussed the strengths of RF, considering also possible limitations and by encouraging further studies on the comparisons of this algorithm with other commonly used classification approaches, particularly in the early prediction of the progression from MCI to AD.},
  langid = {english},
  keywords = {Alzheimer's disease,Classification,Mild Cognitive Impairment,Neuroimaging,random forest},
  file = {/home/paris/Zotero/storage/XMULQJYD/Sarica et al. - 2017 - Random Forest Algorithm for the Classification of Neuroimaging Data in Alzheimer's Disease A System.pdf}
}

@article{sarkarDeepLearningMethods2024,
  title = {Deep {{Learning Methods}} for {{Chest X-Ray Imaging-Based COVID-19 Pneumonia Detection}}},
  author = {Sarkar, MD Roman and Ahamed, S. M. Sojib and Bari, Md Miftahul and Hasan, Md Mehedi and Shishir, Fuad Hasan},
  year = 2024,
  month = sep,
  journal = {Journal of Image Processing and Intelligent Remote Sensing},
  volume = {4},
  number = {5},
  pages = {55--62},
  doi = {10.55529/jipirs.45.55.62},
  urldate = {2025-06-24},
  abstract = {The COVID-19 pandemic currently underway has highlighted a need for fast and accurate screening tools to help identify the disease, particularly in resource-poor settings. In this paper, a deep convolutional neural network (CNN) model is proposed for the automatic detection of COVID-19 pneumonia using chest X-ray images that helps in reducing the cost and processing time compared to traditional testing procedures. It uses several deep-structured medical image data types and improvement of the deep learning model architecture to achieve good diagnostic accuracy. Our hybrid CNN architecture integrates VGG-16 for feature extraction and ResNet-50 for pattern complexity assessment in detecting fine changes characteristic of COVID-19 pneumonia. Our dataset for this study is a collection of few thousands labelled chest X-ray images categorized in three classes, which are COVID-19, viral pneumonia and healthy cases. More advanced data preprocessing methods such as normalized, augmentation, and filtered noise has also been carried out which enhances in the model performance. We have high accuracy, recall, and good F1-score in the experimental results proving model robustness are applicable in real-world clinical scenarios. These research results speak to the importance of AI for improving diagnosis workflows, especially in fast-to-deploy large scale scenarios needed during a pandemic to cope with healthcare burdens.},
  copyright = {Copyright (c) 2024 Authors},
  langid = {english},
  keywords = {AI Diagnostics.,Convolutional Neural Networks,COVID-19,Deep Learning,Medical Imaging},
  file = {/home/paris/gdrive/Zotero/Sarkar et al. - 2024 - Deep Learning Methods for Chest X-Ray Imaging-Based COVID-19 Pneumonia Detection.pdf}
}

@misc{schmidImageIntensityNormalization2023,
  title = {Image {{Intensity Normalization}} in {{Medical Imaging}}},
  author = {Schmid, Susanne},
  year = 2023,
  month = sep,
  journal = {Medium},
  urldate = {2025-06-03},
  abstract = {Image Intensity Normalization in Medical Imaging},
  langid = {english},
  annotation = {GSCC: 0000001 2025-06-15T15:40:17.763Z 0.01}
}

@article{schulzSkullStrippingTools2025,
  title = {Skull Stripping Tools in Pediatric {{T2-weighted MRI}} Scans: A Retrospective Evaluation of Segmentation Performance},
  shorttitle = {Skull Stripping Tools in Pediatric {{T2-weighted MRI}} Scans},
  author = {Schulz, Adrian and Dragendorf, Eric and Wendt, Katharina and Schomakers, Andr{\'e} and B{\"u}ltmann, Eva and Wolff, Dominik},
  year = 2025,
  journal = {Frontiers in Neuroscience},
  volume = {19},
  pages = {1715514},
  issn = {1662-4548},
  doi = {10.3389/fnins.2025.1715514},
  abstract = {INTRODUCTION: For brain maturity assessment of infants aged above 6 months, T2-weighted MRI scans are recommended. Prior to automated brain tissue analysis, skull stripping is typically applied. However, most skull stripping tools neither focus on T2-weighted scans nor on pediatric cohorts. Here, we present the evaluation results of seven common skull stripping tools in a comparably large pediatric cohort. METHODS: This study is based on 199 T2-weighted scans of children under the age of 5 years retrospectively acquired from the clinical routine at Hannover Medical School. We established a manually labeled ground truth under quality control of a senior neuroradiologist specialized in pediatric neuroradiology and evaluated seven skull stripping tools (BET, ROBEX, HD-BET, HD-BET-fast, SynthStrip, SynthStrip-noCSF and d-SynthStrip). Segmentation performance (Dice score, 95th percentile Hausdorff distance, sensitivity, specificity) and computation time were assessed on non-preprocessed and preprocessed scans (zero padding, contrast enhancement, artifact removal and normalization) as well as in different brain regions. For the best performing model, we manually assessed the top and bottom quartile of segmentations with respect to the integrity of different anatomical brain structures. RESULTS: Only BET, HD-BET, HD-BET-fast profited from data preprocessing. Considering this, all models had median Dice scores between 0.88 and 0.96, with SynthStrip performing best. All models segmented most accurately in the middle axial slices of the brain. Resampling lowered the performance of all models, except ROBEX. Mean computing times ranged from 2\,s (BET) to 132\,s (HD-BET) with SynthStrip requiring 7\,s. per scan. SynthStrip was prone to not entirely including the Sinus sagittalis superior, the upper Cerebrum, the temporal pole, the Cerebellum and the Chiasma opticum/pituitary gland. In contrast, the petrous bone and the skull in the middle axial slices have often been partly included. DISCUSSION: Due to its robustness and quick computation time, we recommend SynthStrip for skull stripping of pediatric T2-weighted MRI scans. We attribute the observed segmentation errors to the partial volume effect, which should be addressed in future research. Limitations of our study include the monocentric setting, the exclusion of pathological cases and the skewed age distribution in our cohort.},
  langid = {english},
  pmcid = {PMC12756446},
  pmid = {41488329},
  keywords = {dice score,evaluation,magnetic resonance imaging,pediatrics,retrospective studies,skull stripping,T2-weighted}
}

@misc{SciHubTitleDoi,
  title = {Sci-{{Hub}} : \textbraceleft title\textbraceright{} [\textbraceleft doi\textbraceright ]},
  urldate = {2025-10-14},
  howpublished = {https://sci-hub.se/https://ieeexplore.ieee.org/abstract/document/4667275/},
  file = {/home/paris/Zotero/storage/TMSQ945F/4667275.html}
}

@misc{SciHubTitleDoia,
  title = {Sci-{{Hub}} : \textbraceleft title\textbraceright{} [\textbraceleft doi\textbraceright ]},
  urldate = {2025-10-15},
  howpublished = {https://sci-hub.se/https://www.sciencedirect.com/science/article/pii/S1053811916001452},
  file = {/home/paris/Zotero/storage/IQCXWRQ8/S1053811916001452.html}
}

@misc{SciHubTitleDoib,
  title = {Sci-{{Hub}} : \textbraceleft title\textbraceright{} [\textbraceleft doi\textbraceright ]},
  urldate = {2025-10-16},
  howpublished = {https://sci-hub.se/https://ieeexplore.ieee.org/abstract/document/9795013/},
  file = {/home/paris/Zotero/storage/WMFDTPPK/9795013.html}
}

@misc{SciHubTitleDoic,
  title = {Sci-{{Hub}} : \textbraceleft title\textbraceright{} [\textbraceleft doi\textbraceright ]},
  urldate = {2025-11-04},
  howpublished = {https://sci-hub.se/https://ieeexplore.ieee.org/abstract/document/9023664/},
  file = {/home/paris/Zotero/storage/YCWRGCIX/9023664.html}
}

@article{segonneHybridApproachSkull2004,
  title = {A Hybrid Approach to the Skull Stripping Problem in {{MRI}}},
  author = {S{\'e}gonne, F. and Dale, A. M. and Busa, E. and Glessner, M. and Salat, D. and Hahn, H. K. and Fischl, B.},
  year = 2004,
  month = jul,
  journal = {NeuroImage},
  volume = {22},
  number = {3},
  pages = {1060--1075},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2004.03.032},
  abstract = {We present a novel skull-stripping algorithm based on a hybrid approach that combines watershed algorithms and deformable surface models. Our method takes advantage of the robustness of the former as well as the surface information available to the latter. The algorithm first localizes a single white matter voxel in a T1-weighted MRI image, and uses it to create a global minimum in the white matter before applying a watershed algorithm with a preflooding height. The watershed algorithm builds an initial estimate of the brain volume based on the three-dimensional connectivity of the white matter. This first step is robust, and performs well in the presence of intensity nonuniformities and noise, but may erode parts of the cortex that abut bright nonbrain structures such as the eye sockets, or may remove parts of the cerebellum. To correct these inaccuracies, a surface deformation process fits a smooth surface to the masked volume, allowing the incorporation of geometric constraints into the skull-stripping procedure. A statistical atlas, generated from a set of accurately segmented brains, is used to validate and potentially correct the segmentation, and the MRI intensity values are locally re-estimated at the boundary of the brain. Finally, a high-resolution surface deformation is performed that accurately matches the outer boundary of the brain, resulting in a robust and automated procedure. Studies by our group and others outperform other publicly available skull-stripping tools.},
  langid = {english},
  pmid = {15219578},
  keywords = {Algorithms,Brain,Data Interpretation Statistical,Humans,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Models Neurological}
}

@article{selvarajuGradCAMVisualExplanations2020,
  title = {Grad-{{CAM}}: {{Visual Explanations}} from {{Deep Networks}} via {{Gradient-based Localization}}},
  shorttitle = {Grad-{{CAM}}},
  author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  year = 2020,
  month = feb,
  journal = {International Journal of Computer Vision},
  volume = {128},
  number = {2},
  eprint = {1610.02391},
  primaryclass = {cs},
  pages = {336--359},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-019-01228-7},
  urldate = {2025-08-19},
  abstract = {We propose a technique for producing `visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent and explainable.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/paris/gdrive/Zotero/Selvaraju et al. - 2020 - Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization.pdf}
}

@article{serrano-pozoNeuropathologicalAlterationsAlzheimer2011,
  title = {Neuropathological {{Alterations}} in {{Alzheimer Disease}}},
  author = {{Serrano-Pozo}, Alberto and Frosch, Matthew P. and Masliah, Eliezer and Hyman, Bradley T.},
  year = 2011,
  month = sep,
  journal = {Cold Spring Harbor Perspectives in Medicine:},
  volume = {1},
  number = {1},
  pages = {a006189},
  issn = {2157-1422},
  doi = {10.1101/cshperspect.a006189},
  urldate = {2025-08-13},
  abstract = {The neuropathological hallmarks of Alzheimer disease (AD) include ``positive'' lesions such as amyloid plaques and cerebral amyloid angiopathy, neurofibrillary tangles, and glial responses, and ``negative'' lesions such as neuronal and synaptic loss. Despite their inherently cross-sectional nature, postmortem studies have enabled the staging of the progression of both amyloid and tangle pathologies, and, consequently, the development of diagnostic criteria that are now used worldwide. In addition, clinicopathological correlation studies have been crucial to generate hypotheses about the pathophysiology of the disease, by establishing that there is a continuum between ``normal'' aging and AD dementia, and that the amyloid plaque build-up occurs primarily before the onset of cognitive deficits, while neurofibrillary tangles, neuron loss, and particularly synaptic loss, parallel the progression of cognitive decline. Importantly, these cross-sectional neuropathological data have been largely validated by longitudinal in vivo studies using modern imaging biomarkers such as amyloid PET and volumetric MRI., Amyloid plaque build-up occurs primarily before the onset of cognitive deficits. Neurofibrillary tangles, neuron loss, and synaptic loss parallel the progression of cognitive decline.},
  pmcid = {PMC3234452},
  pmid = {22229116},
  file = {/home/paris/Zotero/storage/ZAF6RCHW/Serrano-Pozo et al. - 2011 - Neuropathological Alterations in Alzheimer Disease.pdf}
}

@article{serrano-pozoNeuropathologicalAlterationsAlzheimer2011a,
  title = {Neuropathological {{Alterations}} in {{Alzheimer Disease}}},
  author = {{Serrano-Pozo}, Alberto and Frosch, Matthew P. and Masliah, Eliezer and Hyman, Bradley T.},
  year = 2011,
  month = sep,
  journal = {Cold Spring Harbor Perspectives in Medicine:},
  volume = {1},
  number = {1},
  pages = {a006189},
  issn = {2157-1422},
  doi = {10.1101/cshperspect.a006189},
  urldate = {2025-08-12},
  abstract = {The neuropathological hallmarks of Alzheimer disease (AD) include ``positive'' lesions such as amyloid plaques and cerebral amyloid angiopathy, neurofibrillary tangles, and glial responses, and ``negative'' lesions such as neuronal and synaptic loss. Despite their inherently cross-sectional nature, postmortem studies have enabled the staging of the progression of both amyloid and tangle pathologies, and, consequently, the development of diagnostic criteria that are now used worldwide. In addition, clinicopathological correlation studies have been crucial to generate hypotheses about the pathophysiology of the disease, by establishing that there is a continuum between ``normal'' aging and AD dementia, and that the amyloid plaque build-up occurs primarily before the onset of cognitive deficits, while neurofibrillary tangles, neuron loss, and particularly synaptic loss, parallel the progression of cognitive decline. Importantly, these cross-sectional neuropathological data have been largely validated by longitudinal in vivo studies using modern imaging biomarkers such as amyloid PET and volumetric MRI., Amyloid plaque build-up occurs primarily before the onset of cognitive deficits. Neurofibrillary tangles, neuron loss, and synaptic loss parallel the progression of cognitive decline.},
  pmcid = {PMC3234452},
  pmid = {22229116},
  file = {/home/paris/Zotero/storage/ATG4I77N/Serrano-Pozo et al. - 2011 - Neuropathological Alterations in Alzheimer Disease.pdf}
}

@article{shahEvaluatingIntensityNormalization2011,
  title = {Evaluating Intensity Normalization on {{MRIs}} of Human Brain with Multiple Sclerosis},
  author = {Shah, Mohak and Xiao, Yiming and Subbanna, Nagesh and Francis, Simon and Arnold, Douglas L. and Collins, D. Louis and Arbel, Tal},
  year = 2011,
  month = apr,
  journal = {Medical Image Analysis},
  volume = {15},
  number = {2},
  pages = {267--282},
  issn = {13618415},
  doi = {10.1016/j.media.2010.12.003},
  urldate = {2025-06-09},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  annotation = {GSCC: 0000255 2025-06-15T15:40:20.342Z 0},
  file = {/home/paris/Zotero/storage/DF5CUESX/Shah et al. - 2011 - Evaluating intensity normalization on MRIs of human brain with multiple sclerosis.pdf}
}

@misc{sharsharNotOnlyGrey2025,
  title = {Not {{Only Grey Matter}}: {{OmniBrain}} for {{Robust Multimodal Classification}} of {{Alzheimer}}'s {{Disease}}},
  shorttitle = {Not {{Only Grey Matter}}},
  author = {Sharshar, Ahmed and Ashraf, Yasser and Bakr, Tameem and Hassan, Salma and Elgendy, Hosam and Yaqub, Mohammad and Guizani, Mohsen},
  year = 2025,
  month = jul,
  number = {arXiv:2507.20872},
  eprint = {2507.20872},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.20872},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease affects over 55 million people worldwide and is projected to more than double by 2050, necessitating rapid, accurate, and scalable diagnostics. However, existing approaches are limited because they cannot achieve clinically acceptable accuracy, generalization across datasets, robustness to missing modalities, and explainability all at the same time. This inability to satisfy all these requirements simultaneously undermines their reliability in clinical settings. We propose OmniBrain, a multimodal framework that integrates brain MRI, radiomics, gene expression, and clinical data using a unified model with cross-attention and modality dropout. OmniBrain achieves \$92.2 \textbackslash pm 2.4\textbackslash\%\$accuracy on the ANMerge dataset and generalizes to the MRI-only ADNI dataset with \$70.4 \textbackslash pm 2.7\textbackslash\%\$ accuracy, outperforming unimodal and prior multimodal approaches. Explainability analyses highlight neuropathologically relevant brain regions and genes, enhancing clinical trust. OmniBrain offers a robust, interpretable, and practical solution for real-world Alzheimer's diagnosis.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/paris/Zotero/storage/K62C6XCH/Sharshar et al. - 2025 - Not Only Grey Matter OmniBrain for Robust Multimodal Classification of Alzheimer's Disease.pdf;/home/paris/Zotero/storage/P7TFD4LQ/2507.html}
}

@article{shattuckMagneticResonanceImage2001,
  title = {Magnetic Resonance Image Tissue Classification Using a Partial Volume Model},
  author = {Shattuck, D. W. and {Sandor-Leahy}, S. R. and Schaper, K. A. and Rottenberg, D. A. and Leahy, R. M.},
  year = 2001,
  month = may,
  journal = {NeuroImage},
  volume = {13},
  number = {5},
  pages = {856--876},
  issn = {1053-8119},
  doi = {10.1006/nimg.2000.0730},
  abstract = {We describe a sequence of low-level operations to isolate and classify brain tissue within T1-weighted magnetic resonance images (MRI). Our method first removes nonbrain tissue using a combination of anisotropic diffusion filtering, edge detection, and mathematical morphology. We compensate for image nonuniformities due to magnetic field inhomogeneities by fitting a tricubic B-spline gain field to local estimates of the image nonuniformity spaced throughout the MRI volume. The local estimates are computed by fitting a partial volume tissue measurement model to histograms of neighborhoods about each estimate point. The measurement model uses mean tissue intensity and noise variance values computed from the global image and a multiplicative bias parameter that is estimated for each region during the histogram fit. Voxels in the intensity-normalized image are then classified into six tissue types using a maximum a posteriori classifier. This classifier combines the partial volume tissue measurement model with a Gibbs prior that models the spatial properties of the brain. We validate each stage of our algorithm on real and phantom data. Using data from the 20 normal MRI brain data sets of the Internet Brain Segmentation Repository, our method achieved average kappa indices of kappa = 0.746 +/- 0.114 for gray matter (GM) and kappa = 0.798 +/- 0.089 for white matter (WM) compared to expert labeled data. Our method achieved average kappa indices kappa = 0.893 +/- 0.041 for GM and kappa = 0.928 +/- 0.039 for WM compared to the ground truth labeling on 12 volumes from the Montreal Neurological Institute's BrainWeb phantom.},
  langid = {english},
  pmid = {11304082},
  keywords = {Adult,Algorithms,Anisotropy,Brain,Brain Mapping,Cerebrospinal Fluid,Diffusion,Humans,Image Enhancement,Image Processing Computer-Assisted,Imaging Three-Dimensional,Magnetic Resonance Imaging,Mathematical Computing,Phantoms Imaging,Reference Values}
}

@article{shinoharaStatisticalNormalizationTechniques2014,
  title = {Statistical Normalization Techniques for Magnetic Resonance Imaging},
  author = {Shinohara, Russell T. and Sweeney, Elizabeth M. and Goldsmith, Jeff and Shiee, Navid and Mateen, Farrah J. and Calabresi, Peter A. and Jarso, Samson and Pham, Dzung L. and Reich, Daniel S. and Crainiceanu, Ciprian M.},
  year = 2014,
  month = jan,
  journal = {NeuroImage: Clinical},
  volume = {6},
  pages = {9--19},
  issn = {2213-1582},
  doi = {10.1016/j.nicl.2014.08.008},
  urldate = {2025-06-03},
  abstract = {While computed tomography and other imaging techniques are measured in absolute units with physical meaning, magnetic resonance images are expressed in arbitrary units that are difficult to interpret and differ between study visits and subjects. Much work in the image processing literature on intensity normalization has focused on histogram matching and other histogram mapping techniques, with little emphasis on normalizing images to have biologically interpretable units. Furthermore, there are no formalized principles or goals for the crucial comparability of image intensities within and across subjects. To address this, we propose a set of criteria necessary for the normalization of images. We further propose simple and robust biologically motivated normalization techniques for multisequence brain imaging that have the same interpretation across acquisitions and satisfy the proposed criteria. We compare the performance of different normalization methods in thousands of images of patients with Alzheimer's disease, hundreds of patients with multiple sclerosis, and hundreds of healthy subjects obtained in several different studies at dozens of imaging centers.},
  keywords = {Image analysis,Magnetic resonance imaging,Normalization,Statistics},
  annotation = {GSCC: 0000438 2025-06-15T15:40:22.585Z 0.73},
  file = {/home/paris/Zotero/storage/GMW5BUIU/Shinohara et al. - 2014 - Statistical normalization techniques for magnetic resonance imaging.pdf;/home/paris/Zotero/storage/FCKIKR5N/S221315821400117X.html}
}

@article{shortenSurveyImageData2019,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = 2019,
  month = dec,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  urldate = {2025-11-04},
  langid = {english},
  file = {/home/paris/Zotero/storage/FFRVJ6SV/Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learning.pdf}
}

@article{shuklaPositronEmissionTomography2006,
  title = {Positron Emission Tomography: {{An}} Overview},
  shorttitle = {Positron Emission Tomography},
  author = {Shukla, A. K. and Kumar, Utham},
  year = 2006,
  journal = {Journal of Medical Physics / Association of Medical Physicists of India},
  volume = {31},
  number = {1},
  pages = {13--21},
  issn = {0971-6203},
  doi = {10.4103/0971-6203.25665},
  urldate = {2025-03-28},
  abstract = {The rate of glucose utilization in tumor cells is significantly enhanced as compared to normal cells and this biochemical characteristic is utilized in PET imaging using FDG as a major workhorse. The PET systems as well as cyclotrons producing positron emitting radiopharmaceuticals have undergone continuous technological refinements. While PET (CT) systems enable fusion images as well as precise attenuation correction, the self-shielded cyclotrons developed provide dedicated systems for in-house production of a large number of PET radiopharmaceuticals. The application of PET images in oncology includes those of pulmonary, colorectal, breast, lymphoma, head \& neck, bone, ovarian and GI cancers. The PET has been recognized as promising diagnostic tool to predict biological and physiological changes at the molecular level and hence offer a potential area for future applications including Stem Cell research.},
  pmcid = {PMC3003889},
  pmid = {21206635},
  file = {/home/paris/Zotero/storage/P26VWQUA/Shukla and Kumar - 2006 - Positron emission tomography An overview.pdf}
}

@article{siFullyEndtoendDeeplearningbased2021,
  title = {Fully End-to-End Deep-Learning-Based Diagnosis of Pancreatic Tumors},
  author = {Si, Ke and Xue, Ying and Yu, Xiazhen and Zhu, Xinpei and Li, Qinghai and Gong, Wei and Liang, Tingbo and Duan, Shumin},
  year = 2021,
  month = jan,
  journal = {Theranostics},
  volume = {11},
  number = {4},
  pages = {1982--1990},
  publisher = {Ivyspring International Publisher},
  issn = {1838-7640},
  doi = {10.7150/thno.52508},
  urldate = {2025-06-24},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Si et al. - 2021 - Fully end-to-end deep-learning-based diagnosis of pancreatic tumors.pdf}
}

@article{singhExplainableDeepLearning2020,
  title = {Explainable Deep Learning Models in Medical Image Analysis},
  author = {Singh, Amitojdeep and Sengupta, Sourya and Lakshminarayanan, Vasudevan},
  year = 2020,
  journal = {Journal of imaging},
  volume = {6},
  number = {6},
  pages = {52},
  publisher = {MDPI},
  urldate = {2025-06-24},
  file = {/home/paris/Zotero/storage/9Q2CTIXZ/52.html}
}

@inproceedings{singhMultiModalDeepFeature2023,
  title = {Multi-{{Modal Deep Feature Integration}} for {{Alzheimer}}'s {{Disease Staging}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine}} ({{BIBM}})},
  author = {Singh, Amritpal and Shi, Wenqi and Wang, May D.},
  year = 2023,
  month = dec,
  pages = {1--6},
  issn = {2156-1133},
  doi = {10.1109/BIBM58861.2023.10431906},
  urldate = {2025-10-24},
  abstract = {Alzheimer's disease (AD) is one of the leading causes of dementia and 7th leading cause of death in the United States. The provisional diagnosis of AD relies on comprehensive examinations, including medical history, neurological and psychiatric examinations, cognitive assessments, and neuroimaging studies. Integrating diverse sets of clinical data, including electronic health records (EHRs), medical imaging, and genomic data, enables a holistic view of AD staging analysis. In this study, we propose an end-to-end deep learning architecture to jointly learn from magnetic resonance imaging (MRI), positron emission tomography (PET), EHRs, and genomics data to classify patients into AD, mild cognitive disorders, and controls. We conduct extensive experiments to explore different feature-level and intermediate-level fusion methods. Our findings suggest intermediate multiplicative fusion achieves the best stage prediction performance on the external validation dataset. Compared with unimodal baselines, we can observe that integrative approaches that leverage all four modalities demonstrate superior performance to baselines reliant solely on one or two modalities. In an age-wise comparison, we observe a unique pattern that all fusion methods exhibited superior performance in the earlier age brackets (50--70 years), with performance diminishing as the age group advanced (70--90 years). The proposed integration framework has the potential to augment our understanding of disease diagnosis and progression by leveraging complementary information from multimodal patient data.},
  keywords = {Alzheimer's disease,Alzheimer's Disease,Bioinformatics,Deep architecture,Feature Fusion,Genomics,Joint Representation,Magnetic resonance imaging,Medical diagnosis,Multimodal Integration,Positron emission tomography,Stage Prediction},
  file = {/home/paris/Zotero/storage/GN7ST6A2/10431906.html}
}

@inproceedings{singhPreprocessingMedicalImages2023,
  title = {Preprocessing of {{Medical Images}} Using {{Deep Learning}}: {{A Comprehensive Review}}},
  shorttitle = {Preprocessing of {{Medical Images}} Using {{Deep Learning}}},
  booktitle = {2023 {{Second International Conference}} on {{Augmented Intelligence}} and {{Sustainable Systems}} ({{ICAISS}})},
  author = {Singh, Nongmeikapam Thoiba and Kaur, Charnpreet and Chaudhary, Amrita and Goyal, Shefali},
  year = 2023,
  month = aug,
  pages = {521--527},
  doi = {10.1109/ICAISS58487.2023.10250462},
  urldate = {2025-06-06},
  abstract = {Medical image preprocessing is a vital component in improving the quality and interpretability of medical images, which directly impacts accurate diagnosis and treatment planning. The advancements in deep learning techniques have paved the way for creative solutions to the problems posed by medical image preprocessing. This review article seeks to offer a thorough examination of contemporary deep-learning methods used for the preprocessing of medical images. The study delves into various preprocessing tasks, including denoising, image enhancement, registration, and segmentation, and examines how deep learning techniques have effectively tackled these tasks. It highlights the significant contributions of deep learning-based preprocessing methods in enhancing image quality, reducing noise, improving contrast, and extracting precise anatomical structures. Moreover, the study emphasizes the impact of deep learning-based preprocessing methods on clinical decision-making. By improving the quality and interpretability of medical images, these techniques empower radiologists and clinicians to make accurate diagnoses, plan treatments, and monitor disease progression more effectively. The review also explores the potential applications of deep learning-based preprocessing methods across different clinical imaging practices, including CT, ultrasound, and MRI.},
  keywords = {convolutional neural networks (CNNs),Decision making,Deep learning,generative adversarial networks (GANs),Image preprocessing,Image quality,Image registration,image segmentation,Image segmentation,imaging modalities,noise reduction,Noise reduction,tumor detection},
  annotation = {GSCC: 0000009 2025-06-15T15:40:24.528Z 0.09},
  file = {/home/paris/Zotero/storage/R2HRYY9N/10250462.html}
}

@article{slackReliablePostHoc,
  title = {Reliable {{Post}} Hoc {{Explanations}}: {{Modeling Uncertainty}} in {{Explainability}}},
  author = {Slack, Dylan and Hilgard, Sophie and Singh, Sameer and Lakkaraju, Himabindu},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Slack et al. - Reliable Post hoc Explanations Modeling Uncertainty in Explainability.pdf}
}

@misc{SlaveAlgorithmWhy,
  title = {Slave to the {{Algorithm}}? {{Why}} a '{{Right}} to an {{Explanation}}' {{Is Probably Not}} the {{Remedy You Are Looking}} for {{International}} 16 {{Duke Law}} \& {{Technology Review}} 2017-2018},
  urldate = {2025-09-03},
  howpublished = {https://heinonline.org/HOL/LandingPage?handle=hein.journals/dltr16\&div=3\&id=\&page=}
}

@article{sm.DeepLearningDrivenAlzheimers2025,
  title = {Deep {{Learning-Driven Alzheimer}}'s {{Disease Classification}}: {{Custom CNN}} and {{Pretrained Architectures}} for {{Accurate MRI Analysis}}},
  shorttitle = {Deep {{Learning-Driven Alzheimer}}'s {{Disease Classification}}},
  author = {S M., VijayaLakshmy and D., Kanimozhi and V C., Nathiya},
  year = 2025,
  month = mar,
  journal = {Journal of Soft Computing Paradigm},
  volume = {7},
  number = {1},
  pages = {31--43},
  issn = {2582-2640},
  doi = {10.36548/jscp.2025.1.003},
  urldate = {2025-08-16},
  abstract = {Millions of people worldwide suffer from Alzheimer's Disease (AD), a progressive neurological disorder. An early and accurate diagnosis is necessary to treat the disease more effectively. This study investigates the application of deep learning methods in classifying the Alzheimer's disease using medical imaging data. A Custom Convolutional Neural Network (CNN) was developed, and it outperformed the performance of the several state-of-the-art pretrained models, including DenseNet121, VGG16, InceptionV3, and ResNet50, with an exceptional accuracy of 98.18\%. The research demonstrates the potential of deep learning algorithms in improving the medical diagnoses by using both transfer learning techniques and custom designed architectures.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/S M. et al. - 2025 - Deep Learning-Driven Alzheimer’s Disease Classification Custom CNN and Pretrained Architectures for.pdf}
}

@article{smallApolipoproteinType41995,
  title = {Apolipoprotein {{E Type}} 4 {{Allele}} and {{Cerebral Glucose Metabolism}} in {{Relatives}} at {{Risk}} for {{Familial Alzheimer Disease}}},
  author = {Small, Gary W. and Mazziotta, John C. and Collins, Mark T. and Baxter, Lewis R. and Phelps, Michael E. and Mandelkern, Mark A. and Kaplan, Andrea and La Rue, Asenath and Adamson, Cara F. and Chang, Linda and Guze, Barry H. and Corder, Elizabeth H. and Saunders, Ann M. and Haines, Jonathan L. and {Pericak-Vance}, Margaret A. and Roses, Allen D.},
  year = 1995,
  month = mar,
  journal = {JAMA},
  volume = {273},
  number = {12},
  pages = {942--947},
  issn = {0098-7484},
  doi = {10.1001/jama.1995.03520360056039},
  urldate = {2025-03-30},
  abstract = {Objective.---Cerebral parietal hypometabolism and left-right asymmetry occur early in the course of Alzheimer disease (AD), and the apolipoprotein E type 4 alal- (APOE {$\varepsilon$}4) is a risk factor for familial AD. To determine if APOE {$\varepsilon$}4 is associated with lowered brain function in nondemented relatives at risk for familial AD, we studied 12 relatives with APOE {$\varepsilon$}4 and 19 relatives without APOE {$\varepsilon$}4. We also compared them with seven patients with probable AD.Design.---After grouping subjects according to diagnosis and genotype, brain function measures were compared among groups.Setting.---University medical center.Patients.---At-risk subjects had mild memory complaints, normal cognitive performance, and at least two relatives with AD. Subjects with APOE {$\varepsilon$}4 did not differ from those without APOE {$\varepsilon$}4 in mean age at examination (56.4 vs 55.5 years) or in neuropsychological performance (mean Mini-Mental State Examination score, 28.8 vs 29.3).Main Outcome Measures.---Cerebral glucose metabolism was measured using positron emission tomography and fludeoxyglucose F 18.Results.---Parietal metabolism was significantly lower and left-right parietal asymmetry was significantly higher in at-risk subjects with APOE {$\varepsilon$}4 compared with those without APOE {$\varepsilon$}4. Patients with dementia had significantly lower parietal metabolism than did at-risk subjects with APOE {$\varepsilon$}4.Conclusions.---These results suggest that the inheritance of APOE {$\varepsilon$}4 is associated with reduced cerebral parietal metabolism and increased asymmetry in nondemented relatives at risk for probable AD. Longitudinal study will determine if glucose metabolic measures provide a means to monitor experimental treatment responses during the early phases of the disorder.(JAMA. 1995;273:942-947)},
  file = {/home/paris/Zotero/storage/Y6M79IEZ/387632.html}
}

@article{smithFastRobustAutomated2002,
  title = {Fast Robust Automated Brain Extraction},
  author = {Smith, Stephen M.},
  year = 2002,
  month = nov,
  journal = {Human Brain Mapping},
  volume = {17},
  number = {3},
  pages = {143--155},
  issn = {1065-9471},
  doi = {10.1002/hbm.10062},
  abstract = {An automated method for segmenting magnetic resonance head images into brain and non-brain has been developed. It is very robust and accurate and has been tested on thousands of data sets from a wide variety of scanners and taken with a wide variety of MR sequences. The method, Brain Extraction Tool (BET), uses a deformable model that evolves to fit the brain's surface by the application of a set of locally adaptive model forces. The method is very fast and requires no preregistration or other pre-processing before being applied. We describe the new method and give examples of results and the results of extensive quantitative testing against "gold-standard" hand segmentations, and two other popular automated methods.},
  langid = {english},
  pmcid = {PMC6871816},
  pmid = {12391568},
  keywords = {Algorithms,Animals,Brain,Humans,Magnetic Resonance Imaging},
  file = {/home/paris/Zotero/storage/TBMJWT35/Smith - 2002 - Fast robust automated brain extraction.pdf}
}

@article{songDiagnosticClassificationBiomarker2021,
  title = {Diagnostic {{Classification}} and {{Biomarker Identification}} of {{Alzheimer}}'s {{Disease}} with {{Random Forest Algorithm}}},
  author = {Song, Minseok and Jung, Hyeyoom and Lee, Seungyong and Kim, Donghyeon and Ahn, Minkyu},
  year = 2021,
  month = apr,
  journal = {Brain Sciences},
  volume = {11},
  number = {4},
  pages = {453},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3425},
  doi = {10.3390/brainsci11040453},
  urldate = {2025-08-15},
  abstract = {Random Forest (RF) is a bagging ensemble model and has many important advantages, such as robustness to noise, an effective structure for complex multimodal data and parallel computing, and also provides important features that help investigate biomarkers. Despite these benefits, RF is not used actively to predict Alzheimer's disease (AD) with brain MRIs. Recent studies have reported RF's effectiveness in predicting AD, but the test sample sizes were too small to draw any solid conclusions. Thus, it is timely to compare RF with other learning model methods, including deep learning, particularly with large amounts of data. In this study, we tested RF and various machine learning models with regional volumes from 2250 brain MRIs: 687 normal controls (NC), 1094 mild cognitive impairment (MCI), and 469 AD that ADNI (Alzheimer's Disease Neuroimaging Initiative database) provided. Three types of features sets (63, 29, and 22 features) were selected, and classification accuracies were computed with RF, Support vector machine (SVM), Multi-layer perceptron (MLP), and Convolutional neural network (CNN). As a result, RF, MLP, and CNN showed high performances of 90.2\%, 89.6\%, and 90.5\% with 63 features. Interestingly, when 22 features were used, RF showed the smallest decrease in accuracy, -3.8\%, and the standard deviation did not change significantly, while MLP and CNN yielded decreases in accuracy of -6.8\% and -4.5\% with changes in the standard deviation from 3.3\% to 4.0\% for MLP and 2.1\% to 7.0\% for CNN, indicating that RF predicts AD more reliably with fewer features. In addition, we investigated the importance of the features that RF provides, and identified the hippocampus, amygdala, and inferior lateral ventricle as the major contributors in classifying NC, MCI, and AD. On average, AD showed smaller hippocampus and amygdala volumes and a larger volume of inferior lateral ventricle than those of MCI and NC.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Alzheimer's disease,convolutional neural network,feature importance,Gini index,machine learning,magnetic resonance imaging,mild-cognitive impairment,Random Forest},
  file = {/home/paris/gdrive/Zotero/Song et al. - 2021 - Diagnostic Classification and Biomarker Identification of Alzheimer’s Disease with Random Forest Alg.pdf}
}

@article{songEffectiveMultimodalImage2021,
  title = {An Effective Multimodal Image Fusion Method Using {{MRI}} and {{PET}} for {{Alzheimer}}'s Disease Diagnosis},
  author = {Song, Juan and Zheng, Jian and Li, Ping and Lu, Xiaoyuan and Zhu, Guangming and Shen, Peiyi},
  year = 2021,
  journal = {Frontiers in digital health},
  volume = {3},
  pages = {637386},
  publisher = {Frontiers Media SA},
  urldate = {2025-10-24},
  file = {/home/paris/Zotero/storage/29BU2AGB/Song et al. - 2021 - An effective multimodal image fusion method using MRI and PET for Alzheimer's disease diagnosis.pdf}
}

@article{souzaOpenMultivendorMultifieldstrength2018,
  title = {An Open, Multi-Vendor, Multi-Field-Strength Brain {{MR}} Dataset and Analysis of Publicly Available Skull Stripping Methods Agreement},
  author = {Souza, Roberto and Lucena, Oeslle and Garrafa, Julia and Gobbi, David and Saluzzi, Marina and Appenzeller, Simone and Rittner, Let{\'i}cia and Frayne, Richard and Lotufo, Roberto},
  year = 2018,
  month = apr,
  journal = {NeuroImage},
  series = {Segmenting the {{Brain}}},
  volume = {170},
  pages = {482--494},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2017.08.021},
  urldate = {2026-01-16},
  abstract = {This paper presents an open, multi-vendor, multi-field strength magnetic resonance (MR) T1-weighted volumetric brain imaging dataset, named Calgary-Campinas-359 (CC-359). The dataset is composed of images of older healthy adults (29--80 years) acquired on scanners from three vendors (Siemens, Philips and General Electric) at both 1.5~T and 3~T. CC-359 is comprised of 359 datasets, approximately 60 subjects per vendor and magnetic field strength. The dataset is approximately age and gender balanced, subject to the constraints of the available images. It provides consensus brain extraction masks for all volumes generated using supervised classification. Manual segmentation results for twelve randomly selected subjects performed by an expert are also provided. The CC-359 dataset allows investigation of 1) the influences of both vendor and magnetic field strength on quantitative analysis of brain MR; 2) parameter optimization for automatic segmentation methods; and potentially 3) machine learning classifiers with big data, specifically those based on deep learning methods, as these approaches require a large amount of data. To illustrate the utility of this dataset, we compared to the results of a supervised classifier, the results of eight publicly available skull stripping methods and one publicly available consensus algorithm. A linear mixed effects model analysis indicated that vendor (p-value{$<$}0.001) and magnetic field strength (p-value{$<$}0.001) have statistically significant impacts on skull stripping results.},
  keywords = {Brain extraction,Brain MR image analysis,Brain segmentation,MP-RAGE,Public database,Skull stripping},
  file = {/home/paris/Zotero/storage/L4QXGH5M/S1053811917306687.html}
}

@misc{SpeithReviewTaxonomies,
  title = {Speith: {{A}} Review of Taxonomies of Explainable Artificial... - {{Google Scholar}}},
  urldate = {2025-09-10},
  howpublished = {https://scholar.google.com/scholar\_lookup?title=A\%20review\%20of\%20taxonomies\%20of\%20explainable\%20artificial\%20intelligence\%20\%20methods\&publication\_year=2022\&author=T.\%20Speith},
  file = {/home/paris/Zotero/storage/SPBITMSD/scholar_lookup.html}
}

@inproceedings{speithReviewTaxonomiesExplainable2022,
  title = {A {{Review}} of {{Taxonomies}} of {{Explainable Artificial Intelligence}} ({{XAI}}) {{Methods}}},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Speith, Timo},
  year = 2022,
  month = jun,
  series = {{{FAccT}} '22},
  pages = {2239--2250},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3531146.3534639},
  urldate = {2025-09-10},
  abstract = {The recent surge in publications related to explainable artificial intelligence (XAI) has led to an almost insurmountable wall if one wants to get started or stay up to date with XAI. For this reason, articles and reviews that present taxonomies of XAI methods seem to be a welcomed way to get an overview of the field. Building on this idea, there is currently a trend of producing such taxonomies, leading to several competing approaches to construct them. In this paper, we will review recent approaches to constructing taxonomies of XAI methods and discuss general challenges concerning them as well as their individual advantages and limitations. Our review is intended to help scholars be aware of challenges current taxonomies face. As we will argue, when charting the field of XAI, it may not be sufficient to rely on one of the approaches we found. To amend this problem, we will propose and discuss three possible solutions: a new taxonomy that incorporates the reviewed ones, a database of XAI methods, and a decision tree to help choose fitting methods.},
  isbn = {978-1-4503-9352-2},
  file = {/home/paris/gdrive/Zotero/Speith - 2022 - A Review of Taxonomies of Explainable Artificial Intelligence (XAI) Methods.pdf}
}

@article{sperlingDefiningPreclinicalStages2011,
  title = {Toward Defining the Preclinical Stages of {{Alzheimer}}'s Disease: {{Recommendations}} from the {{National Institute}} on {{Aging-Alzheimer}}'s {{Association}} Workgroups on Diagnostic Guidelines for {{Alzheimer}}'s Disease},
  shorttitle = {Toward Defining the Preclinical Stages of {{Alzheimer}}'s Disease},
  author = {Sperling, Reisa A. and Aisen, Paul S. and Beckett, Laurel A. and Bennett, David A. and Craft, Suzanne and Fagan, Anne M. and Iwatsubo, Takeshi and Jack, Clifford R. and Kaye, Jeffrey and Montine, Thomas J. and Park, Denise C. and Reiman, Eric M. and Rowe, Christopher C. and Siemers, Eric and Stern, Yaakov and Yaffe, Kristine and Carrillo, Maria C. and Thies, Bill and {Morrison-Bogorad}, Marcelle and Wagster, Molly V. and Phelps, Creighton H.},
  year = 2011,
  month = may,
  journal = {Alzheimer's \& Dementia},
  volume = {7},
  number = {3},
  pages = {280--292},
  issn = {1552-5260},
  doi = {10.1016/j.jalz.2011.03.003},
  urldate = {2024-12-20},
  abstract = {The pathophysiological process of Alzheimer's disease (AD) is thought to begin many years before the diagnosis of AD dementia. This long ``preclinical'' phase of AD would provide a critical opportunity for therapeutic intervention; however, we need to further elucidate the link between the pathological cascade of AD and the emergence of clinical symptoms. The National Institute on Aging and the Alzheimer's Association convened an international workgroup to review the biomarker, epidemiological, and neuropsychological evidence, and to develop recommendations to determine the factors which best predict the risk of progression from ``normal'' cognition to mild cognitive impairment and AD dementia. We propose a conceptual framework and operational research criteria, based on the prevailing scientific evidence to date, to test and refine these models with longitudinal clinical research studies. These recommendations are solely intended for research purposes and do not have any clinical implications at this time. It is hoped that these recommendations will provide a common rubric to advance the study of preclinical AD, and ultimately, aid the field in moving toward earlier intervention at a stage of AD when some disease-modifying therapies may be most efficacious.},
  keywords = {Amyloid,Biomarker,Neurodegeneration,Preclinical Alzheimer's disease,Prevention},
  file = {/home/paris/Zotero/storage/TAXFHSVK/Sperling et al. - 2011 - Toward defining the preclinical stages of Alzheimer’s disease Recommendations from the National Ins.pdf;/home/paris/Zotero/storage/DCW2TA9H/S1552526011000999.html}
}

@misc{StateoftheArtTraditionalMachine,
  title = {State-of-the-{{Art Traditional}} to the {{Machine-}} and {{Deep-Learning-Based Skull Stripping Techniques}}, {{Models}}, and {{Algorithms}} - {{PubMed}}},
  urldate = {2026-01-16},
  howpublished = {https://pubmed.ncbi.nlm.nih.gov/32666364/},
  file = {/home/paris/Zotero/storage/G3L7CQQD/32666364.html}
}

@article{stonningtonInterpretingScanData2008,
  title = {Interpreting Scan Data Acquired from Multiple Scanners: {{A}} Study with {{Alzheimer}}'s Disease},
  shorttitle = {Interpreting Scan Data Acquired from Multiple Scanners},
  author = {Stonnington, Cynthia M. and Tan, Geoffrey and Kl{\"o}ppel, Stefan and Chu, Carlton and Draganski, Bogdan and Jack, Clifford R. and Chen, Kewei and Ashburner, John and Frackowiak, Richard S. J.},
  year = 2008,
  month = feb,
  journal = {NeuroImage},
  volume = {39},
  number = {3},
  pages = {1180--1185},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2007.09.066},
  urldate = {2025-06-12},
  abstract = {Large, multi-site studies utilizing MRI-derived measures from multiple scanners present an opportunity to advance research by pooling data. On the other hand, it remains unclear whether or not the potential confound introduced by different scanners and upgrades will devalue the integrity of any results. Although there are studies of scanner differences for the purpose of calibration and quality control, the current literature is devoid of studies that describe the analysis of multi-scanner data with regard to the interaction of scanner(s) with effects of interest. We investigated a data-set of 136 subjects, 62 patients with mild to moderate Alzheimer's disease and 74 cognitively normal elderly controls, with MRI scans from one center that were acquired over 10~years with 6 different scanners and multiple upgrades over time. We used a whole-brain voxel-wise analysis to evaluate the effect of scanner, effect of disease, and the interaction of scanner and disease for the 6 different scanners. The effect of disease in patients showed the expected significant reduction of grey matter in the medial temporal lobe. Scanner differences were substantially less than the group differences and only significant in the thalamus. There was no significant interaction of scanner with disease group. We describe the rationale for concluding that our results were not confounded by scanner differences. Similar analyses in other multi-scanner data-sets could be used to justify the pooling of data when needed, such as in studies of rare disorders or in multi-center designs.},
  keywords = {Alzheimer's disease,Magnetic resonance imaging (MRI),Multi-scanner,Voxel based morphometry},
  file = {/home/paris/Zotero/storage/CQGNTRYG/Stonnington et al. - 2008 - Interpreting scan data acquired from multiple scanners A study with Alzheimer's disease.pdf}
}

@article{stroblBiasRandomForest2007,
  title = {Bias in Random Forest Variable Importance Measures: {{Illustrations}}, Sources and a Solution},
  shorttitle = {Bias in Random Forest Variable Importance Measures},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
  year = 2007,
  month = jan,
  journal = {BMC Bioinformatics},
  volume = {8},
  number = {1},
  pages = {25},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-8-25},
  urldate = {2025-08-15},
  abstract = {Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.},
  langid = {english},
  keywords = {Bootstrap Sampling,Importance Measure,Random Forest,Variable Importance,Variable Selection},
  file = {/home/paris/gdrive/Zotero/Strobl et al. - 2007 - Bias in random forest variable importance measures Illustrations, sources and a solution 1.pdf}
}

@article{stroblBiasRandomForest2007a,
  title = {Bias in Random Forest Variable Importance Measures: {{Illustrations}}, Sources and a Solution},
  shorttitle = {Bias in Random Forest Variable Importance Measures},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
  year = 2007,
  month = jan,
  journal = {BMC Bioinformatics},
  volume = {8},
  pages = {25},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-8-25},
  urldate = {2025-08-15},
  abstract = {Background Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Results Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. Conclusion We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research.},
  pmcid = {PMC1796903},
  pmid = {17254353},
  file = {/home/paris/gdrive/Zotero/Strobl et al. - 2007 - Bias in random forest variable importance measures Illustrations, sources and a solution.pdf}
}

@article{sukHierarchicalFeatureRepresentation2014,
  title = {Hierarchical Feature Representation and Multimodal Fusion with Deep Learning for {{AD}}/{{MCI}} Diagnosis},
  author = {Suk, Heung-Il and Lee, Seong-Whan and Shen, Dinggang and Initiative, Alzheimer's Disease Neuroimaging},
  year = 2014,
  journal = {NeuroImage},
  volume = {101},
  pages = {569--582},
  publisher = {Elsevier},
  urldate = {2025-10-24}
}

@article{sunHistogrambasedNormalizationTechnique2015,
  title = {Histogram-Based Normalization Technique on Human Brain Magnetic Resonance Images from Different Acquisitions},
  author = {Sun, Xiaofei and Shi, Lin and Luo, Yishan and Yang, Wei and Li, Hongpeng and Liang, Peipeng and Li, Kuncheng and Mok, Vincent C. T. and Chu, Winnie C. W. and Wang, Defeng},
  year = 2015,
  month = jul,
  journal = {Biomedical Engineering Online},
  volume = {14},
  pages = {73},
  issn = {1475-925X},
  doi = {10.1186/s12938-015-0064-y},
  abstract = {BACKGROUND: Intensity normalization is an important preprocessing step in brain magnetic resonance image (MRI) analysis. During MR image acquisition, different scanners or parameters would be used for scanning different subjects or the same subject at a different time, which may result in large intensity variations. This intensity variation will greatly undermine the performance of subsequent MRI processing and population analysis, such as image registration, segmentation, and tissue volume measurement. METHODS: In this work, we proposed a new histogram normalization method to reduce the intensity variation between MRIs obtained from different acquisitions. In our experiment, we scanned each subject twice on two different scanners using different imaging parameters. With noise estimation, the image with lower noise level was determined and treated as the high-quality reference image. Then the histogram of the low-quality image was normalized to the histogram of the high-quality image. The normalization algorithm includes two main steps: (1) intensity scaling (IS), where, for the high-quality reference image, the intensities of the image are first rescaled to a range between the low intensity region (LIR) value and the high intensity region (HIR) value; and (2) histogram normalization (HN),where the histogram of low-quality image as input image is stretched to match the histogram of the reference image, so that the intensity range in the normalized image will also lie between LIR and HIR. RESULTS: We performed three sets of experiments to evaluate the proposed method, i.e., image registration, segmentation, and tissue volume measurement, and compared this with the existing intensity normalization method. It is then possible to validate that our histogram normalization framework can achieve better results in all the experiments. It is also demonstrated that the brain template with normalization preprocessing is of higher quality than the template with no normalization processing. CONCLUSIONS: We have proposed a histogram-based MRI intensity normalization method. The method can normalize scans which were acquired on different MRI units. We have validated that the method can greatly improve the image analysis performance. Furthermore, it is demonstrated that with the help of our normalization method, we can create a higher quality Chinese brain template.},
  langid = {english},
  pmcid = {PMC4517549},
  pmid = {26215471},
  keywords = {Adult,Algorithms,Brain,Female,Humans,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Male,Organ Size,Reference Standards,Young Adult},
  annotation = {GSCC: 0000143 2025-06-15T15:40:27.808Z 0.28},
  file = {/home/paris/Zotero/storage/NEESJTSR/Sun et al. - 2015 - Histogram-based normalization technique on human brain magnetic resonance images from different acqu.pdf}
}

@inproceedings{sunRevisitingUnreasonableEffectiveness2017,
  title = {Revisiting {{Unreasonable Effectiveness}} of {{Data}} in {{Deep Learning Era}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  year = 2017,
  month = oct,
  pages = {843--852},
  publisher = {IEEE},
  address = {Venice},
  doi = {10.1109/ICCV.2017.97},
  urldate = {2025-10-31},
  abstract = {The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10\texttimes{} or 100\texttimes? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pretraining) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-theart results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.},
  isbn = {978-1-5386-1032-9},
  langid = {english},
  file = {/home/paris/Zotero/storage/GSX6H5PL/Sun et al. - 2017 - Revisiting Unreasonable Effectiveness of Data in Deep Learning Era.pdf}
}

@article{SurveyExplainableArtificial2024,
  title = {A Survey of Explainable Artificial Intelligence in Healthcare: {{Concepts}}, Applications, and Challenges},
  shorttitle = {A Survey of Explainable Artificial Intelligence in Healthcare},
  year = 2024,
  month = jan,
  journal = {Informatics in Medicine Unlocked},
  volume = {51},
  pages = {101587},
  publisher = {Elsevier},
  issn = {2352-9148},
  doi = {10.1016/j.imu.2024.101587},
  urldate = {2025-10-15},
  abstract = {Explainable AI (XAI) has the potential to transform healthcare by making AI-driven medical decisions more transparent, reliable, and ethically complia\dots},
  langid = {american}
}

@article{taiyebkhosroshahiExplainableArtificialIntelligence2025,
  title = {Explainable {{Artificial Intelligence}} in {{Neuroimaging}} of {{Alzheimer}}'s {{Disease}}},
  author = {Taiyeb Khosroshahi, Mahdieh and Morsali, Soroush and Gharakhanlou, Sohrab and Motamedi, Alireza and Hassanbaghlou, Saeid and Vahedi, Hadi and Pedrammehr, Siamak and Kabir, Hussain Mohammed Dipu and Jafarizadeh, Ali},
  year = 2025,
  month = mar,
  journal = {Diagnostics},
  volume = {15},
  number = {5},
  pages = {612},
  issn = {2075-4418},
  doi = {10.3390/diagnostics15050612},
  urldate = {2025-10-01},
  abstract = {Alzheimer's disease (AD) remains a significant global health challenge, affecting millions worldwide and imposing substantial burdens on healthcare systems. Advances in artificial intelligence (AI), particularly in deep learning and machine learning, have revolutionized neuroimaging-based AD diagnosis. However, the complexity and lack of interpretability of these models limit their clinical applicability. Explainable Artificial Intelligence (XAI) addresses this challenge by providing insights into model decision-making, enhancing transparency, and fostering trust in AI-driven diagnostics. This review explores the role of XAI in AD neuroimaging, highlighting key techniques such as SHAP, LIME, Grad-CAM, and Layer-wise Relevance Propagation (LRP). We examine their applications in identifying critical biomarkers, tracking disease progression, and distinguishing AD stages using various imaging modalities, including MRI and PET. Additionally, we discuss current challenges, including dataset limitations, regulatory concerns, and standardization issues, and propose future research directions to improve XAI's integration into clinical practice. By bridging the gap between AI and clinical interpretability, XAI holds the potential to refine AD diagnostics, personalize treatment strategies, and advance neuroimaging-based research.},
  pmcid = {PMC11899653},
  pmid = {40075859},
  file = {/home/paris/Zotero/storage/E4QJWRBI/Taiyeb Khosroshahi et al. - 2025 - Explainable Artificial Intelligence in Neuroimaging of Alzheimer’s Disease.pdf}
}

@article{tartagliaNeuroimagingDementia2011,
  title = {Neuroimaging in {{Dementia}}},
  author = {Tartaglia, Maria Carmela and Rosen, Howard J. and Miller, Bruce L.},
  year = 2011,
  month = jan,
  journal = {Neurotherapeutics},
  volume = {8},
  number = {1},
  pages = {82--92},
  issn = {1878-7479},
  doi = {10.1007/s13311-010-0012-2},
  urldate = {2024-12-14},
  abstract = {Dementia is a common illness with an incidence that is rising as the aged population increases. There are a number of neurodegenerative diseases that cause dementia, including Alzheimer's disease, dementia with Lewy bodies, and frontotemporal dementia, which is subdivided into the behavioral variant, the semantic variant, and nonfluent variant. Numerous other neurodegenerative illnesses have an associated dementia, including corticobasal degeneration, Creutzfeldt--Jakob disease, Huntington's disease, progressive supranuclear palsy, multiple system atrophy, Parkinson's disease dementia, and amyotrophic lateral sclerosis. Vascular dementia and AIDS dementia are secondary dementias. Diagnostic criteria have relied on a constellation of symptoms, but the definite diagnosis remains a pathologic one. As treatments become available and target specific molecular abnormalities, differentiating amongst the various primary dementias early on becomes essential. The role of imaging in dementia has traditionally been directed at ruling out treatable and reversible etiologies and not to use imaging to better understand the pathophysiology of the different dementias. Different brain imaging techniques allow the examination of the structure, biochemistry, metabolic state, and functional capacity of the brain. All of the major neurodegenerative disorders have relatively specific imaging findings that can be identified. New imaging techniques carry the hope of revolutionizing the diagnosis of neurodegenerative disease so as to obtain a complete molecular, structural, and metabolic characterization, which could be used to improve diagnosis and to stage each patient and follow disease progression and response to treatment. Structural and functional imaging modalities contribute to the diagnosis and understanding of the different dementias.},
  keywords = {Alzheimer's disease,Dementia,frontotemporal dementia,MRI,PET},
  file = {/home/paris/Zotero/storage/9EW4K4V4/Tartaglia et al. - 2011 - Neuroimaging in Dementia.pdf;/home/paris/Zotero/storage/9ZK9RIGJ/S1878747923015544.html}
}

@article{tengSurveyInterpretabilityDeep2022,
  title = {A Survey on the Interpretability of Deep Learning in Medical Diagnosis},
  author = {Teng, Qiaoying and Liu, Zhe and Song, Yuqing and Han, Kai and Lu, Yang},
  year = 2022,
  month = dec,
  journal = {Multimedia Systems},
  volume = {28},
  number = {6},
  pages = {2335--2355},
  issn = {0942-4962, 1432-1882},
  doi = {10.1007/s00530-022-00960-4},
  urldate = {2025-10-24},
  langid = {english}
}

@article{thalPhasesAvdepositionHuman2002,
  title = {Phases of {{A$\beta$-deposition}} in the Human Brain and Its Relevance for the Development of {{AD}}},
  author = {Thal, Dietmar R. and R{\"u}b, Udo and Orantes, Mario and Braak, Heiko},
  year = 2002,
  month = jun,
  journal = {Neurology},
  volume = {58},
  number = {12},
  pages = {1791--1800},
  publisher = {Wolters Kluwer},
  doi = {10.1212/WNL.58.12.1791},
  urldate = {2025-03-30},
  abstract = {Background: The deposition of the amyloid {$\beta$} protein (A{$\beta$}) is a histopathologic hallmark of AD. The regions of the medial temporal lobe (MTL) are hierarchically involved in A{$\beta$}-deposition.Objective: To clarify whether there is a hierarchical involvement of the regions of the entire brain as well and whether there are differences in the expansion of A{$\beta$}-pathology between clinically proven AD cases and nondemented cases with AD-related pathology, the authors investigated 47 brains from demented and nondemented patients with AD-related pathology covering all phases of {$\beta$}-amyloidosis in the MTL (A{$\beta$}MTL phases) and four control brains without any AD-related pathology.Methods: A{$\beta$} deposits were detected by the use of the Campbell-Switzer silver technique and by immunohistochemistry in sections covering all brain regions and brainstem nuclei. It was analyzed how often distinct regions exhibited A{$\beta$} deposits.Results: In the first of five phases in the evolution of {$\beta$}-amyloidosis A{$\beta$} deposits are found exclusively in the neocortex. The second phase is characterized by the additional involvement of allocortical brain regions. In phase 3, diencephalic nuclei, the striatum, and the cholinergic nuclei of the basal forebrain exhibit A{$\beta$} deposits as well. Several brainstem nuclei become additionally involved in phase 4. Phase 5, finally, is characterized by cerebellar A{$\beta$}-deposition. The 17 clinically proven AD cases exhibit A{$\beta$}-phases 3, 4, or 5. The nine nondemented cases with AD-related A{$\beta$} pathology show A{$\beta$}-phases 1, 2, or 3.Conclusions: A{$\beta$}-deposition in the entire brain follows a distinct sequence in which the regions are hierarchically involved. A{$\beta$}-deposition, thereby, expands anterogradely into regions that receive neuronal projections from regions already exhibiting A{$\beta$}. There are also indications that clinically proven AD cases with full-blown {$\beta$}-amyloidosis may be preceded in early stages by nondemented cases exhibiting AD-related A{$\beta$} pathology.}
}

@misc{thompsonComputationalLimitsDeep2022,
  title = {The {{Computational Limits}} of {{Deep Learning}}},
  author = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
  year = 2022,
  month = jul,
  number = {arXiv:2007.05558},
  eprint = {2007.05558},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2007.05558},
  urldate = {2025-10-16},
  abstract = {Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image classification, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article catalogs the extent of this dependency, showing that progress across a wide variety of applications is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/paris/Zotero/storage/2QVPCM5T/Thompson et al. - 2022 - The Computational Limits of Deep Learning.pdf;/home/paris/Zotero/storage/ZRQYETF3/2007.html}
}

@article{thulasimaniReviewDatasetsOptimization2024,
  title = {A {{Review}} of {{Datasets}}, {{Optimization Strategies}}, and {{Learning Algorithms}} for {{Analyzing Alzheimer}}'s {{Dementia Detection}}},
  author = {Thulasimani, Vanaja and Shanmugavadivel, Kogilavani and Cho, Jaehyuk and Veerappampalayam Easwaramoorthy, Sathishkumar},
  year = 2024,
  month = nov,
  journal = {Neuropsychiatric Disease and Treatment},
  volume = {20},
  pages = {2203--2225},
  issn = {1176-6328},
  doi = {10.2147/NDT.S496307},
  urldate = {2025-10-01},
  abstract = {Alzheimer's Dementia (AD) is a progressive neurological disorder that affects memory and cognitive function, necessitating early detection for its effective management. This poses a significant challenge to global public health. The early and accurate detection of dementia is crucial for several reasons. First, timely detection facilitates early intervention and planning of treatment. Second, precise diagnostic methods are essential for distinguishing dementia from other cognitive disorders and medical conditions that may present with similar symptoms. Continuous analysis and improvements in detection methods have contributed to advancements in medical research. It helps to identify new biomarkers, refine existing diagnostic tools, and foster the development of innovative technologies, ultimately leading to more accurate and efficient diagnostic approaches for dementia. This paper presents a critical analysis of multimodal imaging datasets, learning algorithms, and optimisation techniques utilised in the context of Alzheimer's dementia detection. The focus is on understanding the advancements and challenges in employing diverse imaging modalities, such as MRI (Magnetic Resonance Imaging), PET (Positron Emission Tomography), and EEG (ElectroEncephaloGram). This study evaluated various machine learning algorithms, deep learning models, transfer learning techniques, and generative adversarial networks for the effective analysis of multi-modality imaging data for dementia detection. In addition, a critical examination of optimisation techniques encompassing optimisation algorithms and hyperparameter tuning strategies for processing and analysing images is presented in this study to discern their influence on model performance and generalisation. Thorough examination and enhancement of methods for dementia detection are fundamental for addressing the healthcare challenges posed by dementia, facilitating timely interventions, improving diagnostic accuracy, and advancing research in neurodegenerative diseases.},
  pmcid = {PMC11586527},
  pmid = {39588176},
  file = {/home/paris/Zotero/storage/ZXCCJ7CG/Thulasimani et al. - 2024 - A Review of Datasets, Optimization Strategies, and Learning Algorithms for Analyzing Alzheimer’s Dem.pdf}
}

@incollection{tianDeepLearningImage2019,
  title = {Deep {{Learning}} for {{Image Denoising}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Image Denoising}}},
  booktitle = {Genetic and {{Evolutionary Computing}}},
  author = {Tian, Chunwei and Xu, Yong and Fei, Lunke and Yan, Ke},
  editor = {Pan, Jeng-Shyang and Lin, Jerry Chun-Wei and Sui, Bixia and Tseng, Shih-Pang},
  year = 2019,
  volume = {834},
  pages = {563--572},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-13-5841-8_59},
  urldate = {2025-05-27},
  isbn = {978-981-13-5840-1 978-981-13-5841-8},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Denosing/Tian et al. - 2019 - Deep Learning for Image Denoising A Survey.pdf}
}

@article{tianDeepLearningImage2020,
  title = {Deep Learning on Image Denoising: {{An}} Overview},
  shorttitle = {Deep Learning on Image Denoising},
  author = {Tian, Chunwei and Fei, Lunke and Zheng, Wenxian and Xu, Yong and Zuo, Wangmeng and Lin, Chia-Wen},
  year = 2020,
  journal = {Neural Networks},
  volume = {131},
  pages = {251--275},
  publisher = {Elsevier},
  urldate = {2025-05-27},
  file = {/home/paris/gdrive/Zotero/Denosing/Tian et al. - 2020 - Deep learning on image denoising An overview.pdf}
}

@article{tinauerSkullstrippingInducesShortcut2025,
  title = {Skull-Stripping Induces Shortcut Learning in {{MRI-based Alzheimer}}'s Disease Classification},
  author = {Tinauer, Christian and Sackl, Maximilian and Stollberger, Rudolf and Schmidt, Reinhold and Ropele, Stefan and Langkammer, Christian},
  year = 2025,
  month = dec,
  journal = {Insights into Imaging},
  volume = {16},
  number = {1},
  pages = {283},
  issn = {1869-4101},
  doi = {10.1186/s13244-025-02158-4},
  abstract = {OBJECTIVES: High classification accuracy of Alzheimer's disease (AD) from structural MRI has been achieved using deep neural networks, yet the specific image features contributing to these decisions remain unclear. In this study, the contributions of T1-weighted (T1w) gray-white matter texture, volumetric information, and preprocessing-particularly skull-stripping-were systematically assessed. MATERIALS AND METHODS: A dataset of 990 matched T1w MRIs from AD patients and cognitively normal controls from the ADNI database was used. Preprocessing was varied through skull-stripping and intensity binarization to isolate texture and shape contributions. A 3D convolutional neural network was trained on each configuration, and classification performance was compared using exact McNemar tests with discrete Bonferroni-Holm correction. Feature relevance was analyzed using Layer-wise Relevance Propagation, image similarity metrics, and spectral clustering of relevance maps. RESULTS: Despite substantial differences in image content, classification accuracy, sensitivity, and specificity remained stable across preprocessing conditions. Models trained on binarized images preserved performance, indicating minimal reliance on gray-white matter texture. Instead, volumetric features-particularly brain contours introduced through skull-stripping-were consistently used by the models. CONCLUSION: This behavior reflects a shortcut learning phenomenon, where preprocessing artifacts act as potentially unintended cues. The resulting Clever Hans effect emphasizes the critical importance of interpretability tools to reveal hidden biases and to ensure robust and trustworthy deep learning in medical imaging. CRITICAL RELEVANCE STATEMENT: We investigated the mechanisms underlying deep learning-based disease classification using a widely utilized Alzheimer's disease dataset, and our findings reveal a reliance on features induced through skull-stripping, highlighting the need for careful preprocessing to ensure clinically relevant and interpretable models. KEY POINTS: Shortcut learning is induced by skull-stripping applied to T1-weighted MRIs. Explainable deep learning and spectral clustering estimate the bias. Highlights the importance of understanding the dataset, image preprocessing and deep learning model, for interpretation and validation.},
  langid = {english},
  pmcid = {PMC12722621},
  pmid = {41428317},
  keywords = {Alzheimer's disease,Explainable deep learning,Preprocessing bias,Shortcut learning}
}

@article{tjoaSurveyExplainableArtificial2021,
  title = {A {{Survey}} on {{Explainable Artificial Intelligence}} ({{XAI}}): {{Toward Medical XAI}}},
  shorttitle = {A {{Survey}} on {{Explainable Artificial Intelligence}} ({{XAI}})},
  author = {Tjoa, Erico and Guan, Cuntai},
  year = 2021,
  month = nov,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {32},
  number = {11},
  pages = {4793--4813},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2020.3027314},
  urldate = {2025-10-27},
  abstract = {Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide ``obviously'' interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.},
  keywords = {Artificial intelligence,Explainable artificial intelligence (XAI),interpretability,Machine learning,machine learning (ML),Machine learning algorithms,medical information system,Medical information systems,survey},
  file = {/home/paris/Zotero/storage/7CTM787C/Tjoa and Guan - 2021 - A Survey on Explainable Artificial Intelligence (XAI) Toward Medical XAI.pdf}
}

@inproceedings{tomasiBilateralFilteringGray1998,
  title = {Bilateral Filtering for Gray and Color Images},
  booktitle = {Sixth International Conference on Computer Vision ({{IEEE Cat}}. {{No}}. {{98CH36271}})},
  author = {Tomasi, Carlo and Manduchi, Roberto},
  year = 1998,
  pages = {839--846},
  publisher = {IEEE},
  urldate = {2025-06-29},
  file = {/home/paris/gdrive/Zotero/Tomasi and Manduchi - 1998 - Bilateral filtering for gray and color images.pdf}
}

@incollection{tommasiTestbedCrossDatasetAnalysis2015,
  title = {A {{Testbed}} for {{Cross-Dataset Analysis}}},
  booktitle = {Computer {{Vision}} - {{ECCV}} 2014 {{Workshops}}},
  author = {Tommasi, Tatiana and Tuytelaars, Tinne},
  editor = {Agapito, Lourdes and Bronstein, Michael M. and Rother, Carsten},
  year = 2015,
  volume = {8927},
  pages = {18--31},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-16199-0_2},
  urldate = {2025-06-03},
  isbn = {978-3-319-16198-3 978-3-319-16199-0},
  langid = {english},
  annotation = {GSCC: 0000112 2025-06-15T15:40:30.192Z 0.21},
  file = {/home/paris/Zotero/storage/SYF8882C/Tommasi and Tuytelaars - 2015 - A Testbed for Cross-Dataset Analysis.pdf}
}

@article{tongClassBalancedDeepLearning2024,
  title = {Class-{{Balanced Deep Learning}} with {{Adaptive Vector Scaling Loss}} for {{Dementia Stage Detection}}},
  author = {Tong, Boning and Zhou, Zhuoping and Tarzanagh, Davoud Ataee and Hou, Bojian and Saykin, Andrew J. and Moore, Jason and Ritchie, Marylyn and Shen, Li},
  year = 2024,
  journal = {Machine learning in medical imaging. MLMI (Workshop)},
  volume = {14349},
  pages = {144--154},
  doi = {10.1007/978-3-031-45676-3_15},
  abstract = {Alzheimer's disease (AD) leads to irreversible cognitive decline, with Mild Cognitive Impairment (MCI) as its prodromal stage. Early detection of AD and related dementia is crucial for timely treatment and slowing disease progression. However, classifying cognitive normal (CN), MCI, and AD subjects using machine learning models faces class imbalance, necessitating the use of balanced accuracy as a suitable metric. To enhance model performance and balanced accuracy, we introduce a novel method called VS-Opt-Net. This approach incorporates the recently developed vector-scaling (VS) loss into a machine learning pipeline named STREAMLINE. Moreover, it employs Bayesian optimization for hyperparameter learning of both the model and loss function. VS-Opt-Net not only amplifies the contribution of minority examples in proportion to the imbalance level but also addresses the challenge of generalization in training deep networks. In our empirical study, we use MRI-based brain regional measurements as features to conduct the CN vs MCI and AD vs MCI binary classifications. We compare the balanced accuracy of our model with other machine learning models and deep neural network loss functions that also employ class-balanced strategies. Our findings demonstrate that after hyperparameter optimization, the deep neural network using the VS loss function substantially improves balanced accuracy. It also surpasses other models in performance on the AD dataset. Moreover, our feature importance analysis highlights VS-Opt-Net's ability to elucidate biomarker differences across dementia stages.},
  langid = {english},
  pmcid = {PMC10924683},
  pmid = {38463442},
  keywords = {Alzheimer's Disease,Class-Balanced Deep Learning,Hyperparameter Optimization,Mild Cognitive Impairment,Neuroimaging}
}

@article{turrisiDeepLearningbasedAlzheimers2024,
  title = {Deep Learning-Based {{Alzheimer}}'s Disease Detection: Reproducibility and the Effect of Modeling Choices},
  shorttitle = {Deep Learning-Based {{Alzheimer}}'s Disease Detection},
  author = {Turrisi, Rosanna and Verri, Alessandro and Barla, Annalisa},
  year = 2024,
  month = sep,
  journal = {Frontiers in Computational Neuroscience},
  volume = {18},
  pages = {1360095},
  issn = {1662-5188},
  doi = {10.3389/fncom.2024.1360095},
  urldate = {2026-01-14},
  abstract = {Introduction Machine Learning (ML) has emerged as a promising approach in healthcare, outperforming traditional statistical techniques. However, to establish ML as a reliable tool in clinical practice, adherence to best practices in data handling, and modeling design and assessment is crucial. In this work, we summarize and strictly adhere to such practices to ensure reproducible and reliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection, a challenging problem in healthcare. Additionally, we investigate the impact of modeling choices, including different data augmentation techniques and model complexity, on overall performance. Methods We utilize Magnetic Resonance Imaging (MRI) data from the ADNI corpus to address a binary classification problem using 3D Convolutional Neural Networks (CNNs). Data processing and modeling are specifically tailored to address data scarcity and minimize computational overhead. Within this framework, we train 15 predictive models, considering three different data augmentation strategies and five distinct 3D CNN architectures with varying convolutional layers counts. The augmentation strategies involve affine transformations, such as zoom, shift, and rotation, applied either concurrently or separately. Results The combined effect of data augmentation and model complexity results in up to 10\% variation in prediction accuracy. Notably, when affine transformation are applied separately, the model achieves higher accuracy, regardless the chosen architecture. Across all strategies, the model accuracy exhibits a concave behavior as the number of convolutional layers increases, peaking at an intermediate value. The best model reaches excellent performance both on the internal and additional external testing set. Discussions Our work underscores the critical importance of adhering to rigorous experimental practices in the field of ML applied to healthcare. The results clearly demonstrate how data augmentation and model depth---often overlooked factors-- can dramatically impact final performance if not thoroughly investigated. This highlights both the necessity of exploring neglected modeling aspects and the need to comprehensively report all modeling choices to ensure reproducibility and facilitate meaningful comparisons across studies.},
  pmcid = {PMC11451303},
  pmid = {39371524},
  file = {/home/paris/Zotero/storage/T2VUCEWJ/Turrisi et al. - 2024 - Deep learning-based Alzheimer's disease detection reproducibility and the effect of modeling choice.pdf}
}

@article{turrisiDeepLearningbasedAlzheimers2024a,
  title = {Deep Learning-Based {{Alzheimer}}'s Disease Detection: Reproducibility and the Effect of Modeling Choices},
  shorttitle = {Deep Learning-Based {{Alzheimer}}'s Disease Detection},
  author = {Turrisi, Rosanna and Verri, Alessandro and Barla, Annalisa},
  year = 2024,
  month = sep,
  journal = {Frontiers in Computational Neuroscience},
  volume = {18},
  pages = {1360095},
  issn = {1662-5188},
  doi = {10.3389/fncom.2024.1360095},
  urldate = {2026-01-14},
  abstract = {Introduction Machine Learning (ML) has emerged as a promising approach in healthcare, outperforming traditional statistical techniques. However, to establish ML as a reliable tool in clinical practice, adherence to best practices in data handling, and modeling design and assessment is crucial. In this work, we summarize and strictly adhere to such practices to ensure reproducible and reliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection, a challenging problem in healthcare. Additionally, we investigate the impact of modeling choices, including different data augmentation techniques and model complexity, on overall performance. Methods We utilize Magnetic Resonance Imaging (MRI) data from the ADNI corpus to address a binary classification problem using 3D Convolutional Neural Networks (CNNs). Data processing and modeling are specifically tailored to address data scarcity and minimize computational overhead. Within this framework, we train 15 predictive models, considering three different data augmentation strategies and five distinct 3D CNN architectures with varying convolutional layers counts. The augmentation strategies involve affine transformations, such as zoom, shift, and rotation, applied either concurrently or separately. Results The combined effect of data augmentation and model complexity results in up to 10\% variation in prediction accuracy. Notably, when affine transformation are applied separately, the model achieves higher accuracy, regardless the chosen architecture. Across all strategies, the model accuracy exhibits a concave behavior as the number of convolutional layers increases, peaking at an intermediate value. The best model reaches excellent performance both on the internal and additional external testing set. Discussions Our work underscores the critical importance of adhering to rigorous experimental practices in the field of ML applied to healthcare. The results clearly demonstrate how data augmentation and model depth---often overlooked factors-- can dramatically impact final performance if not thoroughly investigated. This highlights both the necessity of exploring neglected modeling aspects and the need to comprehensively report all modeling choices to ensure reproducibility and facilitate meaningful comparisons across studies.},
  pmcid = {PMC11451303},
  pmid = {39371524},
  file = {/home/paris/Zotero/storage/YIB5QEVP/Turrisi et al. - 2024 - Deep learning-based Alzheimer's disease detection reproducibility and the effect of modeling choice.pdf}
}

@article{tustisonN4ITKImprovedN32010,
  title = {{{N4ITK}}: Improved {{N3}} Bias Correction},
  shorttitle = {{{N4ITK}}},
  author = {Tustison, Nicholas J. and Avants, Brian B. and Cook, Philip A. and Zheng, Yuanjie and Egan, Alexander and Yushkevich, Paul A. and Gee, James C.},
  year = 2010,
  month = jun,
  journal = {IEEE transactions on medical imaging},
  volume = {29},
  number = {6},
  pages = {1310--1320},
  issn = {1558-254X},
  doi = {10.1109/TMI.2010.2046908},
  abstract = {A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as "N4ITK," available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized (3)He lung image data, and 9.4T postmortem hippocampus data.},
  langid = {english},
  pmcid = {PMC3071855},
  pmid = {20378467},
  keywords = {Algorithms,Artifacts,Brain,Humans,Image Enhancement,Image Interpretation Computer-Assisted,Magnetic Resonance Imaging,Reproducibility of Results,Sensitivity and Specificity},
  file = {/home/paris/gdrive/Zotero/Thesis/Section 4/Bias Field Correction/Tustison et al. - 2010 - N4ITK improved N3 bias correction.pdf}
}

@article{ullahRobustEndtoEndDeep2022,
  title = {A {{Robust End-to-End Deep Learning-Based Approach}} for {{Effective}} and {{Reliable BTD Using MR Images}}},
  author = {Ullah, Naeem and Khan, Mohammad Sohail and Khan, Javed Ali and Choi, Ahyoung and Anwar, Muhammad Shahid},
  year = 2022,
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {19},
  pages = {7575},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s22197575},
  urldate = {2025-06-24},
  abstract = {Detection of a brain tumor in the early stages is critical for clinical practice and survival rate. Brain tumors arise in multiple shapes, sizes, and features with various treatment options. Tumor detection manually is challenging, time-consuming, and prone to error. Magnetic resonance imaging (MRI) scans are mostly used for tumor detection due to their non-invasive properties and also avoid painful biopsy. MRI scanning of one patient's brain generates many 3D images from multiple directions, making the manual detection of tumors very difficult, error-prone, and time-consuming. Therefore, there is a considerable need for autonomous diagnostics tools to detect brain tumors accurately. In this research, we have presented a novel TumorResnet deep learning (DL) model for brain detection, i.e., binary classification. The TumorResNet model employs 20 convolution layers with a leaky ReLU (LReLU) activation function for feature map activation to compute the most distinctive deep features. Finally, three fully connected classification layers are used to classify brain tumors MRI into normal and tumorous. The performance of the proposed TumorResNet architecture is evaluated on a standard Kaggle brain tumor MRI dataset for brain tumor detection (BTD), which contains brain tumor and normal MR images. The proposed model achieved a good accuracy of 99.33\% for BTD. These experimental results, including the cross-dataset setting, validate the superiority of the TumorResNet model over the contemporary frameworks. This study offers an automated BTD method that aids in the early diagnosis of brain cancers. This procedure has a substantial impact on improving treatment options and patient survival.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {brain tumor detection,deep learning,MRI,TumorResNet},
  file = {/home/paris/gdrive/Zotero/Ullah et al. - 2022 - A Robust End-to-End Deep Learning-Based Approach for Effective and Reliable BTD Using MR Images.pdf}
}

@article{vaderaMethodsPruningDeep2022,
  title = {Methods for {{Pruning Deep Neural Networks}}},
  author = {Vadera, Sunil and Ameen, Salem},
  year = 2022,
  journal = {IEEE Access},
  volume = {10},
  pages = {63280--63300},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3182659},
  urldate = {2025-10-16},
  abstract = {This paper presents a survey of methods for pruning deep neural networks. It begins by categorising over 150 studies based on the underlying approach used and then focuses on three categories: methods that use magnitude based pruning, methods that utilise clustering to identify redundancy, and methods that use sensitivity analysis to assess the effect of pruning. Some of the key influencing studies within these categories are presented to highlight the underlying approaches and results achieved. Most studies present results which are distributed in the literature as new architectures, algorithms and data sets have developed with time, making comparison across different studied difficult. The paper therefore provides a resource for the community that can be used to quickly compare the results from many different methods on a variety of data sets, and a range of architectures, including AlexNet, ResNet, DenseNet and VGG. The resource is illustrated by comparing the results published for pruning AlexNet and ResNet50 on ImageNet and ResNet56 and VGG16 on the CIFAR10 data to reveal which pruning methods work well in terms of retaining accuracy whilst achieving good compression rates. The paper concludes by identifying some research gaps and promising directions for future research.},
  keywords = {Computer architecture,Deep learning,neural networks,Neural networks,Prediction algorithms,pruning deep networks,Quantization (signal),Sensitivity analysis,Weight measurement},
  file = {/home/paris/Zotero/storage/J86JC4RR/Vadera and Ameen - 2022 - Methods for Pruning Deep Neural Networks.pdf}
}

@misc{VBMAnticipatesRate,
  title = {{{VBM}} Anticipates the Rate of Progression of {{Alzheimer}} Disease \textbar{} {{Neurology}}},
  urldate = {2025-07-25},
  howpublished = {https://www.neurology.org/doi/abs/10.1212/01.wnl.0000303960.01039.43}
}

@article{velazquezRandomForestModel,
  title = {Random Forest Model for Feature-Based {{Alzheimer}}'s Disease Conversion Prediction from Early Mild Cognitive Impairment Subjects},
  author = {Velazquez, Matthew and Lee, Yugyung},
  abstract = {Alzheimer's Disease (AD) conversion prediction from the mild cognitive impairment (MCI) stage has been a difficult challenge. This study focuses on providing an individualized MCI to AD conversion prediction using a balanced random forest model that leverages clinical data. In order to do this, 383 Early Mild Cognitive Impairment (EMCI) patients were gathered from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Of these patients, 49 would eventually convert to AD (EMCI C), whereas the remaining 335 did not convert (EMCI NC). All of these patients were split into training and testing data sets with 95 patients reserved for testing. Nine clinical features were selected, comprised of a mix of demographic, brain volume, and cognitive testing variables. Oversampling was then performed in order to balance the initially imbalanced classes. Our results showed that a random forest model was effective (93.6\% accuracy) at predicting the conversion of EMCI patients to AD based on these clinical features.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Velazquez and Lee - Random forest model for feature-based Alzheimer’s disease conversion prediction from early mild cogn.pdf}
}

@article{venugopalanMultimodalDeepLearning2021,
  title = {Multimodal Deep Learning Models for Early Detection of {{Alzheimer}}'s Disease Stage},
  author = {Venugopalan, Janani and Tong, Li and Hassanzadeh, Hamid Reza and Wang, May D.},
  year = 2021,
  journal = {Scientific reports},
  volume = {11},
  number = {1},
  pages = {3254},
  publisher = {Nature Publishing Group UK London},
  urldate = {2024-11-16},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Venugopalan et al. - 2021 - Multimodal deep learning models for early detection of Alzheimer’s disease stage.pdf}
}

@misc{villalobosScalingLawsLiterature2023,
  title = {Scaling Laws Literature Review},
  author = {Villalobos, Pablo},
  year = 2023,
  month = jan,
  journal = {Epoch AI},
  urldate = {2025-10-02},
  abstract = {I have collected a database of scaling laws for different tasks and architectures, and reviewed dozens of papers in the scaling law literature.},
  howpublished = {https://epoch.ai/blog/scaling-laws-literature-review},
  langid = {english},
  file = {/home/paris/Zotero/storage/NPUMFF8S/scaling-laws-literature-review.html}
}

@article{villemagneAmyloidDepositionNeurodegeneration2013,
  title = {Amyloid {$\beta$} Deposition, Neurodegeneration, and Cognitive Decline in Sporadic {{Alzheimer}}'s Disease: A Prospective Cohort Study},
  shorttitle = {Amyloid {$\beta$} Deposition, Neurodegeneration, and Cognitive Decline in Sporadic {{Alzheimer}}'s Disease},
  author = {Villemagne, Victor L. and Burnham, Samantha and Bourgeat, Pierrick and Brown, Belinda and Ellis, Kathryn A. and Salvado, Olivier and Szoeke, Cassandra and Macaulay, S. Lance and Martins, Ralph and Maruff, Paul},
  year = 2013,
  journal = {The Lancet Neurology},
  volume = {12},
  number = {4},
  pages = {357--367},
  publisher = {Elsevier},
  urldate = {2024-12-13}
}

@misc{VisionTransformerArchitecture,
  title = {Vision Transformer Architecture and Applications in Digital Health: A Tutorial and Survey - {{PMC}}},
  urldate = {2025-08-20},
  howpublished = {https://pmc.ncbi.nlm.nih.gov/articles/PMC10333157/}
}

@misc{VoxelbasedMorphometryAlzheimers,
  title = {Voxel-Based Morphometry in {{Alzheimer}}'s Disease: {{Expert Review}} of {{Neurotherapeutics}}: {{Vol}} 8, {{No}} 11},
  urldate = {2025-07-18},
  howpublished = {https://www.tandfonline.com/doi/abs/10.1586/14737175.8.11.1691}
}

@misc{VoxelbasedMorphometryDeep,
  title = {Voxel-Based Morphometry and a Deep Learning Model for the Diagnosis of Early {{Alzheimer}}'s Disease Based on Cerebral Gray Matter Changes \textbar{} {{Cerebral Cortex}} \textbar{} {{Oxford Academic}}},
  urldate = {2025-07-25},
  howpublished = {https://academic.oup.com/cercor/article/33/3/754/6550297?login=false},
  file = {/home/paris/Zotero/storage/4YKILB2E/6550297.html}
}

@article{waliComprehensiveSurveyExplainable2020,
  title = {A {{Comprehensive Survey}} on {{Explainable Artificial Intelligence}}: {{Methods}}, {{Challenges}}, and {{Future Directions}}},
  shorttitle = {A {{Comprehensive Survey}} on {{Explainable Artificial Intelligence}}},
  author = {Wali, Karthik},
  year = 2020,
  month = dec,
  journal = {IJSAT - International Journal on Science and Technology},
  volume = {11},
  number = {4},
  publisher = {{International Research Publication and Journals}},
  issn = {2229-7677},
  doi = {10.71097/IJSAT.v11.i4.6697},
  urldate = {2025-10-27},
  copyright = {Creative Commons Attribution-ShareAlike 4.0 International License},
  file = {/home/paris/Zotero/storage/GB4LYSXI/Wali - 2020 - A Comprehensive Survey on Explainable Artificial Intelligence Methods, Challenges, and Future Direc.pdf}
}

@article{wangApplicationsGenerativeAdversarial2023,
  title = {Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience},
  author = {Wang, Rongguang and Bashyam, Vishnu and Yang, Zhijian and Yu, Fanyang and Tassopoulou, Vasiliki and Chintapalli, Sai Spandana and Skampardoni, Ioanna and Sreepada, Lasya P. and Sahoo, Dushyant and Nikita, Konstantina and Abdulkadir, Ahmed and Wen, Junhao and Davatzikos, Christos},
  year = 2023,
  month = apr,
  journal = {NeuroImage},
  volume = {269},
  pages = {119898},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2023.119898},
  urldate = {2025-08-20},
  abstract = {Generative adversarial networks (GANs) are one powerful type of deep learning models that have been successfully utilized in numerous fields. They belong to the broader family of generative methods, which learn to generate realistic data with a probabilistic model by learning distributions from real samples. In the clinical context, GANs have shown enhanced capabilities in capturing spatially complex, nonlinear, and potentially subtle disease effects compared to traditional generative methods. This review critically appraises the existing literature on the applications of GANs in imaging studies of various neurological conditions, including Alzheimer's disease, brain tumors, brain aging, and multiple sclerosis. We provide an intuitive explanation of various GAN methods for each application and further discuss the main challenges, open questions, and promising future directions of leveraging GANs in neuroimaging. We aim to bridge the gap between advanced deep learning methods and neurology research by highlighting how GANs can be leveraged to support clinical decision making and contribute to a better understanding of the structural and functional patterns of brain diseases.},
  pmcid = {PMC9992336},
  pmid = {36702211},
  file = {/home/paris/gdrive/Zotero/Wang et al. - 2023 - Applications of generative adversarial networks in neuroimaging and clinical neuroscience.pdf}
}

@article{wangDeepLearningReveals2025,
  title = {Deep Learning Reveals Pathology-Confirmed Neuroimaging Signatures in {{Alzheimer}}'s, Vascular and {{Lewy}} Body Dementias},
  author = {Wang, Di and Honnorat, Nicolas and Toledo, Jon B and Li, Karl and Charisis, Sokratis and Rashid, Tanweer and Benet Nirmala, Anoop and Brandigampala, Sachintha Ransara and Mojtabai, Mariam and Seshadri, Sudha and Habes, Mohamad and {the Alzheimer's Disease Neuroimaging Initiative}},
  year = 2025,
  month = jun,
  journal = {Brain},
  volume = {148},
  number = {6},
  pages = {1963--1977},
  issn = {0006-8950},
  doi = {10.1093/brain/awae388},
  urldate = {2026-01-14},
  abstract = {Concurrent neurodegenerative and vascular pathologies pose a diagnostic challenge in the clinical setting, with histopathology remaining the definitive modality for dementia-type diagnosis. To address this clinical challenge, we introduce a neuropathology-based, data-driven, multi-label deep-learning framework to identify and quantify in vivo biomarkers for Alzheimer's disease (AD), vascular dementia (VD) and Lewy body dementia (LBD) using antemortem T1-weighted MRI scans of 423 demented and 361 control participants from National Alzheimer's Coordinating Center and Alzheimer's Disease Neuroimaging Initiative datasets. Based on the best-performing deep-learning model, explainable heat maps were extracted to visualize disease patterns, and the novel Deep Signature of Pathology Atrophy REcognition (DeepSPARE) indices were developed, where a higher DeepSPARE score indicates more brain alterations associated with that specific pathology.A substantial discrepancy in clinical and neuropathological diagnosis was observed in the demented patients: 71\% had more than one pathology, but 67\% were diagnosed clinically as AD only. Based on these neuropathological diagnoses and leveraging cross-validation principles, the deep-learning model achieved the best performance, with a balanced accuracy of 0.844, 0.839 and 0.623 for AD, VD and LBD, respectively, and was used to generate the explainable deep-learning heat maps and DeepSPARE indices.The explainable deep-learning heat maps revealed distinct neuroimaging brain alteration patterns for each pathology: (i) the AD heat map highlighted bilateral hippocampal regions; (ii) the VD heat map emphasized white matter regions; and (iii) the LBD heat map exposed occipital alterations. The DeepSPARE indices were validated by examining their associations with cognitive testing and neuropathological and neuroimaging measures using linear mixed-effects models. The DeepSPARE-AD index was associated with Mini-Mental State Examination, the Trail Making Test B, memory, hippocampal volume, Braak stages, Consortium to Establish a Registry for Alzheimer's Disease (CERAD) scores and Thal phases [false-discovery rate (FDR)-adjusted P \&lt; 0.05]. The DeepSPARE-VD index was associated with white matter hyperintensity volume and cerebral amyloid angiopathy (FDR-adjusted P \&lt; 0.001), and the DeepSPARE-LBD index was associated with Lewy body stages (FDR-adjusted P \&lt; 0.05).The findings were replicated in an out-of-sample Alzheimer's Disease Neuroimaging Initiative dataset by testing associations with cognitive, imaging, plasma and CSF measures. CSF and plasma tau phosphorylated at threonine-181 (pTau181) were significantly associated with DeepSPARE-AD in the AD and mild cognitive impairment amyloid-{$\beta$} positive (AD/MCI{$A\beta$}+) group (FDR-adjusted P \&lt; 0.001), and CSF {$\alpha$}-synuclein was associated solely with DeepSPARE-LBD (FDR-adjusted P = 0.036).Overall, these findings demonstrate the advantages of our innovative deep-learning framework in detecting antemortem neuroimaging signatures linked to different pathologies. The newly deep-learning-derived DeepSPARE indices are precise, pathology-sensitive and single-valued non-invasive neuroimaging metrics, bridging the traditional widely available in vivo T1 imaging with histopathology.},
  file = {/home/paris/Zotero/storage/YQ439LZ3/Wang et al. - 2025 - Deep learning reveals pathology-confirmed neuroimaging signatures in Alzheimer’s, vascular and Lewy.pdf}
}

@article{wangInterpretable2D3D,
  title = {Interpretable {{2D}} and {{3D Convolutional Neural Networks}} for {{Alzheimer}}'s {{Disease}} in {{Brain Scans}}},
  author = {Wang, Michael},
  abstract = {Alzheimer's disease is an incurable brain disorder as well as the 6th leading cause of death in the USA[1] . Magnetic Resonance Imaging(MRI) is a technique used to form pictures of anatomy within the body, and can be used for brain scans. In this project, I implemented multiple 2D and 3D models in order to try and detect Alzheimer's from MRI scans, and implemented a paper called Grad-CAM[2] in order to determine what led to the diagnosis.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Wang - Interpretable 2D and 3D Convolutional Neural Networks for Alzheimer’s Disease in Brain Scans.pdf}
}

@inproceedings{wangLightMoDADLightweightDiagnosis2023,
  title = {{{LightMoDAD}}: {{A Lightweight Diagnosis Network}} for {{Alzheimer}}'s {{Disease}} with {{Small-Scale Multi-Modal Data}}},
  shorttitle = {{{LightMoDAD}}},
  booktitle = {2023 {{China Automation Congress}} ({{CAC}})},
  author = {Wang, Guangming and Bai, Zhengyao and Xu, Yuee and Song, Shuai and Chen, Muyuan and Chen, Haojie},
  year = 2023,
  month = nov,
  pages = {5334--5339},
  issn = {2688-0938},
  doi = {10.1109/CAC59555.2023.10451828},
  urldate = {2025-10-24},
  abstract = {Alzheimer's Disease (AD) is a chronic neurodegenerative disease without effective medications or supplemental treatment. Early and accurate diagnosis of AD is crucial for effective treatment and patient management. However, AD diagnosis model training is often suffered from small datasets. This paper proposes a lightweight AD diagnosis network trained by using small multi-modal datasets. First, multimodal medical images are produced by fusing structural information from magnetic resonance imaging (MRI) of AD patients with brain activity information from positron emission tomography (PET) images. Then, a lightweight neural network is constructed by integrating convolutional neural networks (CNNs) with transformer networks to extract essential features and classify Alzheimer's disease images. Meanwhile, transfer learning makes the AD diagnosis model less dependent on data. Our model achieves promising results in terms of accuracy, sensitivity, and specificity using a small subset from the Alzheimer's Disease Neuroimaging Initiative (ADNI) public dataset.},
  keywords = {Alzheimer's disease,Brain modeling,Data models,deep learning,Feature extraction,lightweight neural network,Magnetic resonance imaging,multimodal medical images,Training,transfer learning,Transfer learning},
  file = {/home/paris/Zotero/storage/4SC89X9I/10451828.html}
}

@article{wangUnderstandingMachineLearning2024,
  title = {Understanding Machine Learning Applications in Dementia Research and Clinical Practice: A Review for Biomedical Scientists and Clinicians},
  shorttitle = {Understanding Machine Learning Applications in Dementia Research and Clinical Practice},
  author = {Wang, Yihan and Liu, Shu and Spiteri, Alanna G. and Huynh, Andrew Liem Hieu and Chu, Chenyin and Masters, Colin L. and Goudey, Benjamin and Pan, Yijun and Jin, Liang},
  year = 2024,
  month = aug,
  journal = {Alzheimer's Research \& Therapy},
  volume = {16},
  pages = {175},
  issn = {1758-9193},
  doi = {10.1186/s13195-024-01540-6},
  urldate = {2025-10-14},
  abstract = {Several (inter)national longitudinal dementia observational datasets encompassing demographic information, neuroimaging, biomarkers, neuropsychological evaluations, and muti-omics data, have ushered in a new era of potential for integrating machine learning (ML) into dementia research and clinical practice. ML, with its proficiency in handling multi-modal and high-dimensional data, has emerged as an innovative technique to facilitate early diagnosis, differential diagnosis, and to predict onset and progression of mild cognitive impairment and dementia. In this review, we evaluate current and potential applications of ML, including its history in dementia research, how it compares to traditional statistics, the types of datasets it uses and the~general workflow. Moreover, we identify the technical barriers and challenges of ML implementations in clinical practice. Overall, this review provides a comprehensive understanding of ML with non-technical explanations for broader accessibility to biomedical scientists and clinicians.},
  pmcid = {PMC11293066},
  pmid = {39085973},
  file = {/home/paris/Zotero/storage/W5FW53NS/Wang et al. - 2024 - Understanding machine learning applications in dementia research and clinical practice a review for.pdf}
}

@article{weinerAlzheimersDiseaseNeuroimaging2013,
  title = {The {{Alzheimer}}'s {{Disease Neuroimaging Initiative}}: A Review of Papers Published since Its Inception},
  shorttitle = {The {{Alzheimer}}'s {{Disease Neuroimaging Initiative}}},
  author = {Weiner, Michael W. and Veitch, Dallas P. and Aisen, Paul S. and Beckett, Laurel A. and Cairns, Nigel J. and Green, Robert C. and Harvey, Danielle and Jack, Clifford R. and Jagust, William and Liu, Enchi},
  year = 2013,
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  number = {5},
  pages = {e111--e194},
  publisher = {Elsevier},
  urldate = {2024-11-09},
  file = {/home/paris/gdrive/Zotero/Thesis/Introduction_Contextual_Background/Weiner et al. - 2013 - The Alzheimer's Disease Neuroimaging Initiative a review of papers published since its inception.pdf}
}

@inproceedings{weisenfeldNormalizationJointImageintensity2004,
  title = {Normalization of Joint Image-Intensity Statistics in {{MRI}} Using the {{Kullback-Leibler}} Divergence},
  booktitle = {2004 2nd {{IEEE International Symposium}} on {{Biomedical Imaging}}: {{Nano}} to {{Macro}} ({{IEEE Cat No}}. {{04EX821}})},
  author = {Weisenfeld, Neil L. and Warfteld, S. K.},
  year = 2004,
  pages = {101--104},
  publisher = {IEEE},
  urldate = {2025-06-20}
}

@article{weizenbaumComputerPowerHuman1976,
  title = {Computer Power and Human Reason: {{From}} Judgment to Calculation.},
  shorttitle = {Computer Power and Human Reason},
  author = {Weizenbaum, Joseph},
  year = 1976,
  publisher = {WH Freeman \& Co},
  urldate = {2025-09-10},
  file = {/home/paris/Zotero/storage/ARWT2MJE/Weizenbaum - 1976 - Computer power and human reason From judgment to calculation.}
}

@article{wenConvolutionalNeuralNetworks2020,
  title = {Convolutional Neural Networks for Classification of {{Alzheimer}}'s Disease: {{Overview}} and Reproducible Evaluation},
  shorttitle = {Convolutional Neural Networks for Classification of {{Alzheimer}}'s Disease},
  author = {Wen, Junhao and {Thibeau-Sutre}, Elina and {Diaz-Melo}, Mauricio and {Samper-Gonz{\'a}lez}, Jorge and Routier, Alexandre and Bottani, Simona and Dormont, Didier and Durrleman, Stanley and Burgos, Ninon and Colliot, Olivier},
  year = 2020,
  month = jul,
  journal = {Medical Image Analysis},
  volume = {63},
  pages = {101694},
  issn = {1361-8415},
  doi = {10.1016/j.media.2020.101694},
  urldate = {2026-01-14},
  abstract = {Numerous machine learning (ML) approaches have been proposed for automatic classification of Alzheimer's disease (AD) from brain imaging data. In particular, over 30 papers have proposed to use convolutional neural networks (CNN) for AD classification from anatomical MRI. However, the classification performance is difficult to compare across studies due to variations in components such as participant selection, image preprocessing or validation procedure. Moreover, these studies are hardly reproducible because their frameworks are not publicly accessible and because implementation details are lacking. Lastly, some of these papers may report a biased performance due to inadequate or unclear validation or model selection procedures. In the present work, we aim to address these limitations through three main contributions. First, we performed a systematic literature review. We identified four main types of approaches: i) 2D slice-level, ii) 3D patch-level, iii) ROI-based and iv) 3D subject-level CNN. Moreover, we found that more than half of the surveyed papers may have suffered from data leakage and thus reported biased performance. Our second contribution is the extension of our open-source framework for classification of AD using CNN and T1-weighted MRI. The framework comprises previously developed tools to automatically convert ADNI, AIBL and OASIS data into the BIDS standard, and a modular set of image preprocessing procedures, classification architectures and evaluation procedures dedicated to deep learning. Finally, we used this framework to rigorously compare different CNN architectures. The data was split into training/validation/test sets at the very beginning and only the training/validation sets were used for model selection. To avoid any overfitting, the test sets were left untouched until the end of the peer-review process. Overall, the different 3D approaches (3D-subject, 3D-ROI, 3D-patch) achieved similar performances while that of the 2D slice approach was lower. Of note, the different CNN approaches did not perform better than a SVM with voxel-based features. The different approaches generalized well to similar populations but not to datasets with different inclusion criteria or demographical characteristics. All the code of the framework and the experiments is publicly available: general-purpose tools have been integrated into the Clinica software (www.clinica.run) and the paper-specific code is available at: https://github.com/aramis-lab/AD-DL.},
  keywords = {Alzheimer's disease classification Magnetic resonance imaging,Convolutional neural network Reproducibility},
  file = {/home/paris/Zotero/storage/PPS9KL6N/Wen et al. - 2020 - Convolutional neural networks for classification of Alzheimer's disease Overview and reproducible e.pdf}
}

@misc{wengAutoencoderBetaVAE2018,
  title = {From {{Autoencoder}} to {{Beta-VAE}}},
  author = {Weng, Lilian},
  year = 2018,
  month = aug,
  urldate = {2025-06-22},
  abstract = {[Updated on 2019-07-18: add a section on VQ-VAE \& VQ-VAE-2.] [Updated on 2019-07-26: add a section on TD-VAE.] Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for Variational Autoencoder, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding. Such a low-dimensional representation can be used as en embedding vector in various applications (i.e. search), help data compression, or reveal the underlying data generative factors.},
  chapter = {posts},
  howpublished = {https://lilianweng.github.io/posts/2018-08-12-vae/},
  langid = {english}
}

@misc{WhyLanguageModels2025,
  title = {Why Language Models Hallucinate},
  year = 2025,
  month = aug,
  urldate = {2025-09-08},
  abstract = {OpenAI's new research explains why language models hallucinate. The findings show how improved evaluations can enhance AI reliability, honesty, and safety.},
  howpublished = {https://openai.com/index/why-language-models-hallucinate/},
  langid = {american},
  file = {/home/paris/Zotero/storage/KUYNPM7Q/why-language-models-hallucinate.html}
}

@article{wuEnhancingBoneRadiology2025,
  title = {Enhancing Bone Radiology Images Classification through Appropriate Preprocessing: A Deep Learning and Explainable Artificial Intelligence Approach},
  shorttitle = {Enhancing Bone Radiology Images Classification through Appropriate Preprocessing},
  author = {Wu, Yaoyang and Fong, Simon and Yu, Jiahui},
  year = 2025,
  month = mar,
  journal = {Quantitative Imaging in Medicine and Surgery},
  volume = {15},
  number = {3},
  pages = {2529546--2522546},
  publisher = {AME Publishing Company},
  issn = {2223-4306, 2223-4292},
  doi = {10.21037/qims-24-1745},
  urldate = {2025-06-24},
  abstract = {Enhancing bone radiology images classification through appropriate preprocessing: a deep learning and explainable artificial intelligence approach},
  langid = {english}
}

@article{xuComprehensiveReviewSynergy2024,
  title = {A {{Comprehensive Review}} on {{Synergy}} of {{Multi-Modal Data}} and {{AI Technologies}} in {{Medical Diagnosis}}},
  author = {Xu, Xi and Li, Jianqiang and Zhu, Zhichao and Zhao, Linna and Wang, Huina and Song, Changwei and Chen, Yining and Zhao, Qing and Yang, Jijiang and Pei, Yan},
  year = 2024,
  month = feb,
  journal = {Bioengineering},
  volume = {11},
  number = {3},
  pages = {219},
  issn = {2306-5354},
  doi = {10.3390/bioengineering11030219},
  urldate = {2025-10-24},
  abstract = {Disease diagnosis represents a critical and arduous endeavor within the medical field. Artificial intelligence (AI) techniques, spanning from machine learning and deep learning to large model paradigms, stand poised to significantly augment physicians in rendering more evidence-based decisions, thus presenting a pioneering solution for clinical practice. Traditionally, the amalgamation of diverse medical data modalities (e.g., image, text, speech, genetic data, physiological signals) is imperative to facilitate a comprehensive disease analysis, a topic of burgeoning interest among both researchers and clinicians in recent times. Hence, there exists a pressing need to synthesize the latest strides in multi-modal data and AI technologies in the realm of medical diagnosis. In this paper, we narrow our focus to five specific disorders (Alzheimer's disease, breast cancer, depression, heart disease, epilepsy), elucidating advanced endeavors in their diagnosis and treatment through the lens of artificial intelligence. Our survey not only delineates detailed diagnostic methodologies across varying modalities but also underscores commonly utilized public datasets, the intricacies of feature engineering, prevalent classification models, and envisaged challenges for future endeavors. In essence, our research endeavors to contribute to the advancement of diagnostic methodologies, furnishing invaluable insights for clinical decision making.},
  pmcid = {PMC10967767},
  pmid = {38534493},
  file = {/home/paris/Zotero/storage/UBFFFH7R/Xu et al. - 2024 - A Comprehensive Review on Synergy of Multi-Modal Data and AI Technologies in Medical Diagnosis.pdf}
}

@inproceedings{xuExplainableAIBrief2019,
  title = {Explainable {{AI}}: {{A Brief Survey}} on {{History}}, {{Research Areas}}, {{Approaches}} and {{Challenges}}},
  shorttitle = {Explainable {{AI}}},
  booktitle = {Natural {{Language Processing}} and {{Chinese Computing}}},
  author = {Xu, Feiyu and Uszkoreit, Hans and Du, Yangzhou and Fan, Wei and Zhao, Dongyan and Zhu, Jun},
  editor = {Tang, Jie and Kan, Min-Yen and Zhao, Dongyan and Li, Sujian and Zan, Hongying},
  year = 2019,
  pages = {563--574},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-32236-6_51},
  abstract = {Deep learning has made significant contribution to the recent progress in artificial intelligence. In comparison to traditional machine learning methods such as decision trees and support vector machines, deep learning methods have achieved substantial improvement in various prediction tasks. However, deep neural networks (DNNs) are comparably weak in explaining their inference processes and final results, and they are typically treated as a black-box by both developers and users. Some people even consider DNNs (deep neural networks) in the current stage rather as alchemy, than as real science. In many real-world applications such as business decision, process optimization, medical diagnosis and investment recommendation, explainability and transparency of our AI systems become particularly essential for their users, for the people who are affected by AI decisions, and furthermore, for the researchers and developers who create the AI solutions. In recent years, the explainability and explainable AI have received increasing attention by both research community and industry. This paper first introduces the history of Explainable AI, starting from expert systems and traditional machine learning approaches to the latest progress in the context of modern deep learning, and then describes the major research areas and the state-of-art approaches in recent years. The paper ends with a discussion on the challenges and future directions.},
  isbn = {978-3-030-32236-6},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Xu et al. - 2019 - Explainable AI A Brief Survey on History, Research Areas, Approaches and Challenges 1.pdf;/home/paris/gdrive/Zotero/Xu et al. - 2019 - Explainable AI A Brief Survey on History, Research Areas, Approaches and Challenges.pdf}
}

@article{xuReviewApplicationThreedimensional2023,
  title = {A Review of the Application of Three-Dimensional Convolutional Neural Networks for the Diagnosis of {{Alzheimer}}'s Disease Using Neuroimaging},
  author = {Xu, Xinze and Lin, Lan and Sun, Shen and Wu, Shuicai},
  year = 2023,
  month = aug,
  journal = {Reviews in the Neurosciences},
  volume = {34},
  number = {6},
  pages = {649--670},
  publisher = {De Gruyter},
  issn = {2191-0200},
  doi = {10.1515/revneuro-2022-0122},
  urldate = {2025-08-19},
  abstract = {Alzheimer's disease (AD) is a degenerative disorder that leads to progressive, irreversible cognitive decline. To obtain an accurate and timely diagnosis and detect AD at an early stage, numerous approaches based on convolutional neural networks (CNNs) using neuroimaging data have been proposed. Because 3D CNNs can extract more~spatial discrimination information than 2D CNNs, they have~emerged as a promising research direction in the diagnosis of AD. The aim of this article is to present the~current state of~the art in the diagnosis of AD using 3D CNN~models and~neuroimaging modalities, focusing on the 3D CNN architectures and classification methods used, and to highlight potential future research topics. To give the reader a better overview of the content mentioned in this review, we briefly introduce the commonly used imaging datasets and the fundamentals of CNN architectures. Then we carefully analyzed the existing studies on AD diagnosis, which are divided into two levels according to their inputs: 3D subject-level CNNs and 3D patch-level CNNs, highlighting their contributions and significance in the field. In addition, this review discusses the key findings and challenges from the studies and highlights the lessons learned as a roadmap for future research. Finally, we summarize the paper by presenting some major findings, identifying open research challenges, and pointing out future research directions.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {Alzheimer's disease,computer-aided diagnosis,convolution neural network,deep learning}
}

@article{xuStainNormalizationHistopathological2025,
  title = {Stain {{Normalization}} of {{Histopathological Images Based}} on {{Deep Learning}}: {{A Review}}},
  shorttitle = {Stain {{Normalization}} of {{Histopathological Images Based}} on {{Deep Learning}}},
  author = {Xu, Chuanyun and Sun, Yisha and Zhang, Yang and Liu, Tianqi and Wang, Xiao and Hu, Die and Huang, Shuaiye and Li, Junjie and Zhang, Fanghong and Li, Gang},
  year = 2025,
  journal = {Diagnostics},
  volume = {15},
  number = {8},
  pages = {1032},
  publisher = {MDPI},
  urldate = {2025-06-23},
  file = {/home/paris/gdrive/Zotero/Xu et al. - 2025 - Stain Normalization of Histopathological Images Based on Deep Learning A Review.pdf;/home/paris/Zotero/storage/UBH84H8T/1032.html}
}

@article{yannlecunDeepLearning2015,
  title = {Deep Learning},
  author = {{Yann LeCun} and LeCun, Yann and {Yoshua Bengio} and Bengio, Yoshua and {Geoffrey E. Hinton} and Hinton, Geoffrey E.},
  year = 2015,
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  doi = {10.1038/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  annotation = {MAG ID: 2919115771}
}

@misc{yaoMachineLearningLimited2021,
  title = {Machine Learning with Limited Data},
  author = {Yao, Fupin},
  year = 2021,
  month = jan,
  number = {arXiv:2101.11461},
  eprint = {2101.11461},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2101.11461},
  urldate = {2025-10-14},
  abstract = {Thanks to the availability of powerful computing resources, big data and deep learning algorithms, we have made great progress on computer vision in the last few years. Computer vision systems begin to surpass humans in some tasks, such as object recognition, object detection, face recognition and pose estimation. Lots of computer vision algorithms have been deployed to real world applications and started to improve our life quality. However, big data and labels are not always available. Sometimes we only have very limited labeled data, such as medical images which requires experts to label them. In this paper, we study few shot image classification, in which we only have very few labeled data. Machine learning with little data is a big challenge. To tackle this challenge, we propose two methods and test their effectiveness thoroughly. One method is to augment image features by mixing the style of these images. The second method is applying spatial attention to explore the relations between patches of images. We also find that domain shift is a critical issue in few shot learning when the training domain and testing domain are different. So we propose a more realistic cross-domain few-shot learning with unlabeled data setting, in which some unlabeled data is available in the target domain. We propose two methods in this setting. Our first method transfers the style information of the unlabeled target dataset to the samples in the source dataset and trains a model with stylized images and original images. Our second method proposes a unified framework to fully utilize all the data. Both of our methods surpass the baseline method by a large margin.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/paris/Zotero/storage/MBVW3DLS/Yao - 2021 - Machine learning with limited data.pdf;/home/paris/Zotero/storage/IYACCW2I/2101.html}
}

@article{yiGenerativeAdversarialNetwork2019,
  title = {Generative Adversarial Network in Medical Imaging: {{A}} Review},
  shorttitle = {Generative Adversarial Network in Medical Imaging},
  author = {Yi, Xin and Walia, Ekta and Babyn, Paul},
  year = 2019,
  month = dec,
  journal = {Medical Image Analysis},
  volume = {58},
  pages = {101552},
  issn = {1361-8415},
  doi = {10.1016/j.media.2019.101552},
  urldate = {2025-11-04},
  abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
  keywords = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review},
  file = {/home/paris/Zotero/storage/5JRHZUEV/Yi et al. - 2019 - Generative adversarial network in medical imaging A review.pdf;/home/paris/Zotero/storage/IWWRX9Z4/S1361841518308430.html}
}

@article{yoonDomainGeneralizationMedical2024,
  title = {Domain {{Generalization}} for {{Medical Image Analysis}}: {{A Review}}},
  shorttitle = {Domain {{Generalization}} for {{Medical Image Analysis}}},
  author = {Yoon, Jee Seok and Oh, Kwanseok and Shin, Yooseung and Mazurowski, Maciej A. and Suk, Heung-Il},
  year = 2024,
  month = oct,
  journal = {Proceedings of the IEEE},
  volume = {112},
  number = {10},
  eprint = {2310.08598},
  primaryclass = {eess},
  pages = {1583--1609},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2024.3507831},
  urldate = {2025-06-04},
  abstract = {Medical image analysis (MedIA) has become an essential tool in medicine and healthcare, aiding in disease diagnosis, prognosis, and treatment planning, and recent successes in deep learning (DL) have made significant contributions to its advances. However, deploying DL models for MedIA in real-world situations remains challenging due to their failure to generalize across the distributional gap between training and testing samples - a problem known as domain shift. Researchers have dedicated their efforts to developing various DL methods to adapt and perform robustly on unknown and out-of-distribution (OOD) data distributions. This article comprehensively reviews domain generalization (DG) studies specifically tailored for MedIA. We provide a holistic view of how DG techniques interact within the broader MedIA system, going beyond methodologies to consider the operational implications on the entire MedIA workflow. Specifically, we categorize DG methods into data-level, feature-level, model-level, and analysis-level methods. We show how those methods can be used in various stages of the MedIA workflow with DL equipped from data acquisition to model prediction and analysis. Furthermore, we critically analyze the strengths and weaknesses of various methods, unveiling future research opportunities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {GSCC: 0000009 2025-06-15T15:40:31.844Z 0},
  file = {/home/paris/Zotero/storage/AR3HBRPC/Yoon et al. - 2024 - Domain Generalization for Medical Image Analysis A Review.pdf;/home/paris/Zotero/storage/WTE25NYK/2310.html}
}

@article{youngDataLeakageDeep2025,
  title = {Data {{Leakage}} in {{Deep Learning}} for {{Alzheimer}}'s {{Disease Diagnosis}}: {{A Scoping Review}} of {{Methodological Rigor}} and {{Performance Inflation}}},
  shorttitle = {Data {{Leakage}} in {{Deep Learning}} for {{Alzheimer}}'s {{Disease Diagnosis}}},
  author = {Young, Vanessa M. and Gates, Samantha and Garcia, Layla Y. and Salardini, Arash},
  year = 2025,
  month = sep,
  journal = {Diagnostics},
  volume = {15},
  number = {18},
  pages = {2348},
  issn = {2075-4418},
  doi = {10.3390/diagnostics15182348},
  urldate = {2026-01-14},
  abstract = {Background: Deep-learning models for Alzheimer's disease (AD) diagnosis frequently report revolutionary accuracies exceeding 95\% yet consistently fail in clinical translation. This scoping review investigates whether methodological flaws, particularly data leakage, systematically inflates performance metrics, and examines the broader landscape of validation practices that impact clinical readiness. Methods: We conducted a scoping review following PRISMA-ScR guidelines, with protocol pre-registered in the Open Science Framework (OSF osf.io/2s6e9). We searched PubMed, Scopus, and CINAHL databases through May 2025 for studies employing deep learning for AD diagnosis. We developed a novel three-tier risk stratification framework to assess data leakage potential and systematically extracted data on validation practices, interpretability methods, and performance metrics. Results: From 2368 identified records, 44 studies met inclusion criteria, with 90.9\% published between 2020--2023. We identified a striking inverse relationship between methodological rigor and reported accuracy. Studies with confirmed subject-wise data splitting reported accuracies of 66--90\%, while those with high data leakage risk claimed 95--99\% accuracy. Direct comparison within a single study demonstrated a 28-percentage point accuracy drop (from 94\% to 66\%) when proper validation was implemented. Only 15.9\% of studies performed external validation, and 79.5\% failed to control for confounders. While interpretability methods like Gradient-weighted Class Activation Mapping (Grad-CAM) were used in 18.2\% of studies, clinical validation of these explanations remained largely absent. Encouragingly, high-risk methodologies decreased from 66.7\% (2016--2019) to 9.5\% (2022--2023). Conclusions: Data leakage and associated methodological flaws create a pervasive illusion of near-perfect performance in AD deep-learning research. True accuracy ranges from 66--90\% when properly validated---comparable to existing clinical methods but far from revolutionary. The disconnect between technical implementation of interpretability methods and their clinical validation represents an additional barrier. These findings reveal fundamental challenges that must be addressed through adoption of a ``methodological triad'': proper data splitting, external validation, and confounder control.},
  pmcid = {PMC12468286},
  pmid = {41008719},
  file = {/home/paris/Zotero/storage/PLCPBZ3X/Young et al. - 2025 - Data Leakage in Deep Learning for Alzheimer’s Disease Diagnosis A Scoping Review of Methodological.pdf}
}

@article{youngUncoveringHeterogeneityTemporal2018,
  title = {Uncovering the Heterogeneity and Temporal Complexity of Neurodegenerative Diseases with {{Subtype}} and {{Stage Inference}}},
  author = {Young, Alexandra L. and Marinescu, Razvan V. and Oxtoby, Neil P. and Bocchetta, Martina and Yong, Keir and Firth, Nicholas C. and Cash, David M. and Thomas, David L. and Dick, Katrina M. and Cardoso, Jorge and {van Swieten}, John and Borroni, Barbara and Galimberti, Daniela and Masellis, Mario and Tartaglia, Maria Carmela and Rowe, James B. and Graff, Caroline and Tagliavini, Fabrizio and Frisoni, Giovanni B. and Laforce, Robert and Finger, Elizabeth and {de Mendon{\c c}a}, Alexandre and Sorbi, Sandro and Warren, Jason D. and Crutch, Sebastian and Fox, Nick C. and Ourselin, Sebastien and Schott, Jonathan M. and Rohrer, Jonathan D. and Alexander, Daniel C.},
  year = 2018,
  month = oct,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {4273},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05892-0},
  urldate = {2026-01-14},
  abstract = {The heterogeneity of neurodegenerative diseases is a key confound to disease understanding and treatment development, as study cohorts typically include multiple phenotypes on distinct disease trajectories. Here we introduce a machine-learning technique---Subtype and Stage Inference (SuStaIn)---able to uncover data-driven disease phenotypes with distinct temporal progression patterns, from widely available cross-sectional patient studies. Results from imaging studies in two neurodegenerative diseases reveal subgroups and their distinct trajectories of regional neurodegeneration. In genetic frontotemporal dementia, SuStaIn identifies genotypes from imaging alone, validating its ability to identify subtypes; further the technique reveals within-genotype heterogeneity. In Alzheimer's disease, SuStaIn uncovers three subtypes, uniquely characterising their temporal complexity. SuStaIn provides fine-grained patient stratification, which substantially enhances the ability to predict conversion between diagnostic categories over standard models that ignore subtype (p\,=\,7.18\,\texttimes\,10-4) or temporal stage (p\,=\,3.96\,\texttimes\,10-5). SuStaIn offers new promise for enabling disease subtype discovery and precision medicine.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Computer science,Neurodegenerative diseases},
  file = {/home/paris/Zotero/storage/ASAJHF97/Young et al. - 2018 - Uncovering the heterogeneity and temporal complexity of neurodegenerative diseases with Subtype and.pdf}
}

@article{yuDeepLearningDenoising2019,
  title = {Deep Learning for Denoising},
  author = {Yu, Siwei and Ma, Jianwei and Wang, Wenlong},
  year = 2019,
  month = nov,
  journal = {GEOPHYSICS},
  volume = {84},
  number = {6},
  pages = {V333-V350},
  issn = {0016-8033, 1942-2156},
  doi = {10.1190/geo2018-0668.1},
  urldate = {2025-07-01},
  abstract = {Compared with traditional seismic noise attenuation algorithms that depend on signal models and their corresponding prior assumptions, removing noise with a deep neural network is trained based on a large training set in which the inputs are the raw data sets and the corresponding outputs are the desired clean data. After the completion of training, the deep-learning (DL) method achieves adaptive denoising with no requirements of (1)~accurate modelings of the signal and noise or (2)~optimal parameters tuning. We call this intelligent denoising. We have used a convolutional neural network (CNN) as the basic tool for DL. In random and linear noise attenuation, the training set is generated with artificially added noise. In the multiple attenuation step, the training set is generated with the acoustic wave equation. The stochastic gradient descent is used to solve the optimal parameters for the CNN. The runtime of DL on a graphics processing unit for denoising has the same order as the [Formula: see text]-[Formula: see text] deconvolution method. Synthetic and field results indicate the potential applications of DL in automatic attenuation of random noise (with unknown variance), linear noise, and multiples.},
  langid = {english},
  file = {/home/paris/gdrive/Zotero/Yu et al. - 2019 - Deep learning for denoising.pdf}
}

@misc{zhangaMultimodalGraphNeural2023,
  title = {Multi-Modal {{Graph Neural Network}} for {{Early Diagnosis}} of {{Alzheimer}}'s {{Disease}} from {{sMRI}} and {{PET Scans}}},
  author = {Zhanga, Yanteng and He, Xiaohai and Chan, Yi Hao and Teng, Qizhi and Rajapakse, Jagath C.},
  year = 2023,
  month = jul,
  number = {arXiv:2307.16366},
  eprint = {2307.16366},
  primaryclass = {eess},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.16366},
  urldate = {2025-10-24},
  abstract = {In recent years, deep learning models have been applied to neuroimaging data for early diagnosis of Alzheimer's disease (AD). Structural magnetic resonance imaging (sMRI) and positron emission tomography (PET) images provide structural and functional information about the brain, respectively. Combining these features leads to improved performance than using a single modality alone in building predictive models for AD diagnosis. However, current multi-modal approaches in deep learning, based on sMRI and PET, are mostly limited to convolutional neural networks, which do not facilitate integration of both image and phenotypic information of subjects. We propose to use graph neural networks (GNN) that are designed to deal with problems in non-Euclidean domains. In this study, we demonstrate how brain networks can be created from sMRI or PET images and be used in a population graph framework that can combine phenotypic information with imaging features of these brain networks. Then, we present a multi-modal GNN framework where each modality has its own branch of GNN and a technique is proposed to combine the multi-modal data at both the level of node vectors and adjacency matrices. Finally, we perform late fusion to combine the preliminary decisions made in each branch and produce a final prediction. As multi-modality data becomes available, multi-source and multi-modal is the trend of AD diagnosis. We conducted explorative experiments based on multi-modal imaging data combined with non-imaging phenotypic information for AD diagnosis and analyzed the impact of phenotypic information on diagnostic performance. Results from experiments demonstrated that our proposed multi-modal approach improves performance for AD diagnosis, and this study also provides technical reference and support the need for multivariate multi-modal diagnosis methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/paris/Zotero/storage/3DT5LXYV/Zhanga et al. - 2023 - Multi-modal Graph Neural Network for Early Diagnosis of Alzheimer's Disease from sMRI and PET Scans.pdf;/home/paris/Zotero/storage/GUAFYWFZ/2307.html}
}

@misc{zhangInterpretingCNNKnowledge2017,
  title = {Interpreting {{CNN Knowledge}} via an {{Explanatory Graph}}},
  author = {Zhang, Quanshi and Cao, Ruiming and Shi, Feng and Wu, Ying Nian and Zhu, Song-Chun},
  year = 2017,
  month = nov,
  number = {arXiv:1708.01785},
  eprint = {1708.01785},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1708.01785},
  urldate = {2025-09-02},
  abstract = {This paper learns a graphical model, namely an explanatory graph, which reveals the knowledge hierarchy hidden inside a pre-trained CNN. Considering that each filter in a conv-layer of a pre-trained CNN usually represents a mixture of object parts, we propose a simple yet efficient method to automatically disentangles different part patterns from each filter, and construct an explanatory graph. In the explanatory graph, each node represents a part pattern, and each edge encodes co-activation relationships and spatial relationships between patterns. More importantly, we learn the explanatory graph for a pre-trained CNN in an unsupervised manner, i.e., without a need of annotating object parts. Experiments show that each graph node consistently represents the same object part through different images. We transfer part patterns in the explanatory graph to the task of part localization, and our method significantly outperforms other approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/paris/gdrive/Zotero/Zhang et al. - 2017 - Interpreting CNN Knowledge via an Explanatory Graph.pdf;/home/paris/Zotero/storage/JH6S8W7V/1708.html}
}

@article{zhaoConventionalMachineLearning2023,
  title = {Conventional Machine Learning and Deep Learning in {{Alzheimer}}'s Disease Diagnosis Using Neuroimaging: {{A}} Review},
  shorttitle = {Conventional Machine Learning and Deep Learning in {{Alzheimer}}'s Disease Diagnosis Using Neuroimaging},
  author = {Zhao, Zhen and Chuah, Joon Huang and Lai, Khin Wee and Chow, Chee-Onn and Gochoo, Munkhjargal and Dhanalakshmi, Samiappan and Wang, Na and Bao, Wei and Wu, Xiang},
  year = 2023,
  month = feb,
  journal = {Frontiers in Computational Neuroscience},
  volume = {17},
  pages = {1038636},
  issn = {1662-5188},
  doi = {10.3389/fncom.2023.1038636},
  urldate = {2025-08-19},
  abstract = {Alzheimer's disease (AD) is a neurodegenerative disorder that causes memory degradation and cognitive function impairment in elderly people. The irreversible and devastating cognitive decline brings large burdens on patients and society. So far, there is no effective treatment that can cure AD, but the process of early-stage AD can slow down. Early and accurate detection is critical for treatment. In recent years, deep-learning-based approaches have achieved great success in Alzheimer's disease diagnosis. The main objective of this paper is to review some popular conventional machine learning methods used for the classification and prediction of AD using Magnetic Resonance Imaging (MRI). The methods reviewed in this paper include support vector machine (SVM), random forest (RF), convolutional neural network (CNN), autoencoder, deep learning, and transformer. This paper also reviews pervasively used feature extractors and different types of input forms of convolutional neural network. At last, this review discusses challenges such as class imbalance and data leakage. It also discusses the trade-offs and suggestions about pre-processing techniques, deep learning, conventional machine learning methods, new techniques, and input type selection.},
  pmcid = {PMC9939698},
  pmid = {36814932},
  file = {/home/paris/gdrive/Zotero/Zhao et al. - 2023 - Conventional machine learning and deep learning in Alzheimer's disease diagnosis using neuroimaging.pdf}
}

@article{zhouDeepLearningMethods2023,
  title = {Deep Learning Methods for Medical Image Fusion: {{A}} Review},
  shorttitle = {Deep Learning Methods for Medical Image Fusion},
  author = {Zhou, Tao and Cheng, QianRu and Lu, HuiLing and Li, Qi and Zhang, XiangXiang and Qiu, Shi},
  year = 2023,
  month = jun,
  journal = {Computers in Biology and Medicine},
  volume = {160},
  pages = {106959},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2023.106959},
  urldate = {2025-06-24},
  abstract = {The image fusion methods based on deep learning has become a research hotspot in the field of computer vision in recent years. This paper reviews these methods from five aspects: Firstly, the principle and advantages of image fusion methods based on deep learning are expounded; Secondly, the image fusion methods are summarized in two aspects: End-to-End and Non-End-to-End, according to the different tasks of deep learning in the feature processing stage, the non-end-to-end image fusion methods are divided into two categories: deep learning for decision mapping and deep learning for feature extraction. According to the different types of the networks, the end-to-end image fusion methods are divided into three categories: image fusion methods based on Convolutional Neural Network, Generative Adversarial Network, and Encoder-Decoder Network; Thirdly, the application of the image fusion methods based on deep learning in medical image field is summarized from two aspects: method and data set; Fourthly, evaluation metrics commonly used in the field of medical image fusion are sorted out from 14 aspects; Fifthly, the main challenges faced by the medical image fusion are discussed from two aspects: data sets and fusion methods. And the future development direction is prospected. This paper systematically summarizes the image fusion methods based on the deep learning, which has a positive guiding significance for the in-depth study of multi modal medical images.},
  keywords = {Convolutional neural network,Deep learning,Encoder-decoder network,Generative adversarial network,Medical image fusion}
}

@article{zhouEnhancingMagneticResonance2021,
  title = {Enhancing Magnetic Resonance Imaging-Driven {{Alzheimer}}'s Disease Classification Performance Using Generative Adversarial Learning},
  author = {Zhou, Xiao and Qiu, Shangran and Joshi, Prajakta S. and Xue, Chonghua and Killiany, Ronald J. and Mian, Asim Z. and Chin, Sang P. and Au, Rhoda and Kolachalama, Vijaya B.},
  year = 2021,
  month = mar,
  journal = {Alzheimer's Research \& Therapy},
  volume = {13},
  pages = {60},
  issn = {1758-9193},
  doi = {10.1186/s13195-021-00797-5},
  urldate = {2025-08-20},
  abstract = {Background Generative adversarial networks (GAN) can produce images of improved quality but their ability to augment image-based classification is not fully explored. We evaluated if a modified GAN can learn from magnetic resonance imaging (MRI) scans of multiple magnetic field strengths to enhance Alzheimer's disease (AD) classification performance. Methods T1-weighted brain MRI scans from 151 participants of the Alzheimer's Disease Neuroimaging Initiative (ADNI), who underwent both 1.5-Tesla (1.5-T) and 3-Tesla imaging at the same time were selected to construct a GAN model. This model was trained along with a three-dimensional fully convolutional network (FCN) using the generated images (3T*) as inputs to predict AD status. Quality of the generated images was evaluated using signal to noise ratio (SNR), Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE) and Natural Image Quality Evaluator (NIQE). Cases~from the Australian Imaging, Biomarker \& Lifestyle Flagship Study of Ageing (AIBL, n\,=\,107) and the National Alzheimer's Coordinating Center (NACC, n\,=\,565) were~used for model validation. Results The 3T*-based FCN classifier performed better than the FCN model trained using the 1.5-T scans. Specifically, the mean area under curve increased from 0.907 to 0.932, from 0.934 to 0.940, and from 0.870 to 0.907 on the ADNI test, AIBL, and NACC datasets, respectively. Additionally, we found that the mean quality of the generated (3T*) images was consistently higher than the 1.5-T images, as measured using SNR, BRISQUE, and NIQE on the validation datasets. Conclusion This study demonstrates a proof of principle that GAN frameworks can be constructed to augment AD classification performance and improve image quality. Supplementary Information The online version contains supplementary material available at 10.1186/s13195-021-00797-5.},
  pmcid = {PMC7958452},
  pmid = {33715635},
  file = {/home/paris/gdrive/Zotero/Zhou et al. - 2021 - Enhancing magnetic resonance imaging-driven Alzheimer’s disease classification performance using gen.pdf}
}

@article{zwanenburgImageBiomarkerStandardization2020,
  title = {The {{Image Biomarker Standardization Initiative}}: {{Standardized Quantitative Radiomics}} for {{High-Throughput Image-based Phenotyping}}},
  shorttitle = {The {{Image Biomarker Standardization Initiative}}},
  author = {Zwanenburg, Alex and Valli{\`e}res, Martin and Abdalah, Mahmoud A. and Aerts, Hugo J. W. L. and Andrearczyk, Vincent and Apte, Aditya and Ashrafinia, Saeed and Bakas, Spyridon and Beukinga, Roelof J. and Boellaard, Ronald and Bogowicz, Marta and Boldrini, Luca and Buvat, Ir{\`e}ne and Cook, Gary J. R. and Davatzikos, Christos and Depeursinge, Adrien and Desseroit, Marie-Charlotte and Dinapoli, Nicola and Dinh, Cuong Viet and Echegaray, Sebastian and El Naqa, Issam and Fedorov, Andriy Y. and Gatta, Roberto and Gillies, Robert J. and Goh, Vicky and G{\"o}tz, Michael and Guckenberger, Matthias and Ha, Sung Min and Hatt, Mathieu and Isensee, Fabian and Lambin, Philippe and Leger, Stefan and Leijenaar, Ralph T. H. and Lenkowicz, Jacopo and Lippert, Fiona and Losneg{\aa}rd, Are and {Maier-Hein}, Klaus H. and Morin, Olivier and M{\"u}ller, Henning and Napel, Sandy and Nioche, Christophe and Orlhac, Fanny and Pati, Sarthak and Pfaehler, Elisabeth A. G. and Rahmim, Arman and Rao, Arvind U. K. and Scherer, Jonas and Siddique, Muhammad Musib and Sijtsema, Nanna M. and Socarras Fernandez, Jairo and Spezi, Emiliano and Steenbakkers, Roel J. H. M. and {Tanadini-Lang}, Stephanie and Thorwarth, Daniela and Troost, Esther G. C. and Upadhaya, Taman and Valentini, Vincenzo and {van Dijk}, Lisanne V. and {van Griethuysen}, Joost and {van Velden}, Floris H. P. and Whybra, Philip and Richter, Christian and L{\"o}ck, Steffen},
  year = 2020,
  month = may,
  journal = {Radiology},
  volume = {295},
  number = {2},
  pages = {328--338},
  issn = {1527-1315},
  doi = {10.1148/radiol.2020191145},
  abstract = {Background Radiomic features may quantify characteristics present in medical imaging. However, the lack of standardized definitions and validated reference values have hampered clinical use. Purpose To standardize a set of 174 radiomic features. Materials and Methods Radiomic features were assessed in three phases. In phase I, 487 features were derived from the basic set of 174 features. Twenty-five research teams with unique radiomics software implementations computed feature values directly from a digital phantom, without any additional image processing. In phase II, 15 teams computed values for 1347 derived features using a CT image of a patient with lung cancer and predefined image processing configurations. In both phases, consensus among the teams on the validity of tentative reference values was measured through the frequency of the modal value and classified as follows: less than three matches, weak; three to five matches, moderate; six to nine matches, strong; 10 or more matches, very strong. In the final phase (phase III), a public data set of multimodality images (CT, fluorine 18 fluorodeoxyglucose PET, and T1-weighted MRI) from 51 patients with soft-tissue sarcoma was used to prospectively assess reproducibility of standardized features. Results Consensus on reference values was initially weak for 232 of 302 features (76.8\%) at phase I and 703 of 1075 features (65.4\%) at phase II. At the final iteration, weak consensus remained for only two of 487 features (0.4\%) at phase I and 19 of 1347 features (1.4\%) at phase II. Strong or better consensus was achieved for 463 of 487 features (95.1\%) at phase I and 1220 of 1347 features (90.6\%) at phase II. Overall, 169 of 174 features were standardized in the first two phases. In the final validation phase (phase III), most of the 169 standardized features could be excellently reproduced (166 with CT; 164 with PET; and 164 with MRI). Conclusion A set of 169 radiomics features was standardized, which enabled verification and calibration of different radiomics software. \copyright{} RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Kuhl and Truhn in this issue.},
  langid = {english},
  pmcid = {PMC7193906},
  pmid = {32154773},
  keywords = {Biomarkers,Calibration,Fluorodeoxyglucose F18,Humans,Image Processing Computer-Assisted,Lung Neoplasms,Magnetic Resonance Imaging,Phantoms Imaging,Phenotype,Positron-Emission Tomography,Radiopharmaceuticals,Reproducibility of Results,Sarcoma,Software,Tomography X-Ray Computed},
  file = {/home/paris/gdrive/Zotero/Thesis/Section 4/Phantom Standardization/Zwanenburg et al. - 2020 - The Image Biomarker Standardization Initiative Standardized Quantitative Radiomics for High-Through.pdf}
}
